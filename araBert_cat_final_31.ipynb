{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTdhD3kWthvg",
        "outputId": "fa5f744f-bf43-4925-9f98-0725168837b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 67.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting farasapy\n",
            "  Downloading farasapy-0.0.14-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (2022.12.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy) (1.24.3)\n",
            "Installing collected packages: farasapy\n",
            "Successfully installed farasapy-0.0.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting arabert\n",
            "  Downloading arabert-1.0.1-py3-none-any.whl (179 kB)\n",
            "\u001b[K     |████████████████████████████████| 179 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting emoji==1.4.2\n",
            "  Downloading emoji-1.4.2.tar.gz (184 kB)\n",
            "\u001b[K     |████████████████████████████████| 184 kB 72.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: farasapy in /usr/local/lib/python3.8/dist-packages (from arabert) (0.0.14)\n",
            "Requirement already satisfied: PyArabic in /usr/local/lib/python3.8/dist-packages (from arabert) (0.6.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from farasapy->arabert) (2.23.0)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from PyArabic->arabert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->farasapy->arabert) (1.24.3)\n",
            "Building wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186469 sha256=fea3608ff2a52163107c87e5ebfe528f2ec76694af17cc6e0088f70b45daa156\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/4d/3c/cada364d4ea0026deee7208dee1e61bcebd20aa2ae5dc154ba\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji, arabert\n",
            "Successfully installed arabert-1.0.1 emoji-1.4.2\n",
            "Cloning into 'arabert'...\n",
            "remote: Enumerating objects: 600, done.\u001b[K\n",
            "remote: Counting objects: 100% (65/65), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 600 (delta 38), reused 45 (delta 30), pack-reused 535\u001b[K\n",
            "Receiving objects: 100% (600/600), 9.14 MiB | 25.86 MiB/s, done.\n",
            "Resolving deltas: 100% (339/339), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install farasapy\n",
        "!pip install pyarabic\n",
        "!pip install arabert\n",
        "!git clone https://github.com/aub-mind/arabert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T_XUVZViLLr",
        "outputId": "46bf03b9-3c9c-4ca8-bf9a-86d8e1545251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.8/dist-packages (1.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "00tImzUPcdAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "bd3fb2e9-0fa9-4229-d695-340b4653ca7a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f5985fc7970e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0marabert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArabertPreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O3gA8JUWGPw",
        "outputId": "a6873d92-da51-4659-ee03-add9be791030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RrfhcS-cWGTH"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8KTjc7-lrC4c"
      },
      "outputs": [],
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv02-twitter\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ocy6RcQQbpwY"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_TmsWIbdrC4f"
      },
      "outputs": [],
      "source": [
        "arabert_prep = ArabertPreprocessor(model_name=model_name, keep_emojis=True)\n",
        "df_train['text']=df_train['text'].apply(arabert_prep.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-qZJtQXrC4h"
      },
      "outputs": [],
      "source": [
        "possible_labels = df_train.category.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nfb4J0yDXRi",
        "outputId": "366f2cba-2b1c-4e74-a394-656b282aad95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['celebrity' 'info_news' 'personal' 'unrelated' 'plan' 'requests' 'others'\n",
            " 'rumors' 'advice' 'restrictions']\n"
          ]
        }
      ],
      "source": [
        "print(possible_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FfRa2NcErC4j"
      },
      "outputs": [],
      "source": [
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JRnHapMvrC4l"
      },
      "outputs": [],
      "source": [
        "df_train.category = df_train['category'].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4s1n77_B9vK",
        "outputId": "3e26828d-3e04-4db2-813f-321c57b43cfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'celebrity': 0, 'info_news': 1, 'personal': 2, 'unrelated': 3, 'plan': 4, 'requests': 5, 'others': 6, 'rumors': 7, 'advice': 8, 'restrictions': 9}\n"
          ]
        }
      ],
      "source": [
        "print(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF1Y4rwtc7UR",
        "outputId": "9df0fda3-325a-44d8-c7b9-e51886a580e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6988\n",
            "6988\n"
          ]
        }
      ],
      "source": [
        "y_train=df_train.category.values\n",
        "print(len(y_train))\n",
        "x_train=df_train.text.values\n",
        "print(len(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "30hKqG6_bpyv"
      },
      "outputs": [],
      "source": [
        "df_val = pd.read_csv(\"dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B7ZI1BsOrC4n"
      },
      "outputs": [],
      "source": [
        "arabert_prep = ArabertPreprocessor(model_name=model_name, keep_emojis=True)\n",
        "df_val['text']=df_val['text'].apply(arabert_prep.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1h7jqt3RrC4p"
      },
      "outputs": [],
      "source": [
        "df_val.category = df_val['category'].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpr6gqOJdKau",
        "outputId": "8e61ef59-2ba0-489b-bfa6-430ed01c0e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "y_val=df_val.category.values\n",
        "print(len(y_val))\n",
        "x_val=df_val.text.values\n",
        "print(len(x_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxtfcoo0fqOk"
      },
      "source": [
        "# BERT CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFA0bbFfeVd7",
        "outputId": "fb2a330f-af5e-433f-d09c-2c2441ddf8a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 34.2 ms, sys: 938 µs, total: 35.1 ms\n",
            "Wall time: 37.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \"\"\"Bert Model for Classification Tasks.\n",
        "    \"\"\"\n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        @param    bert: a BertModel object\n",
        "        @param    classifier: a torch.nn.Module classifier\n",
        "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        # # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
        "        # D_in = 256 if version == \"mini\" else 768\n",
        "        # H, D_out = 50, 2\n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        #----------- classifier ---------\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768,50),    #768 bert output => linear input\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(50, 10) # no of classes\n",
        "        )\n",
        "\n",
        "        # Freeze the BERT model\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute logits.\n",
        "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
        "                      information with shape (batch_size, max_length)\n",
        "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
        "                      num_labels)\n",
        "        \"\"\"\n",
        "          # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
        "                              \n",
        "          \n",
        "          # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "          # Feed input to classifier to compute logits\n",
        "          # feed el hidden layer embedding to the classifier layer\n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkYqh_rjCyR"
      },
      "source": [
        "# get input IDs and attention masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yaC23SBDjP5_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "f079b9aabfc54a2d9da91cbd6678361a",
            "bd4bbadd09e344bf90dc4567cc5f946b",
            "fb48ef6671c74f67a34fcb3da094e1ce",
            "2a09fc26549b4da6aa5b899e85d3826a",
            "ee54ab8e42544feea77a8db4cd37109b",
            "7a717385613f45f68abfd025c415f260",
            "971c04d3f41049f38b5246fe86e31685",
            "96cbd10ccc4a4bcdb4310a8b4cd6358e",
            "b2310e92832a479ca6b5260fc4effb64",
            "14c4a73a02994a2d9084ce5fc14f4cb5",
            "bb3b861b86b149c19c8c008115c80dcb",
            "98a2cdf7da7e4cfdb15a075652ec9c0c",
            "d3267213023a473db8eff1828d75d7f4",
            "2e19d525ee46449a86e2b1aa3675fd1e",
            "80e9356ce9564699b08fc480006943a0",
            "bd3695ad5bb8415d84b17a8edfe58972",
            "92519dd8da544ba69746bb67419a9e7f",
            "e22af4577f0a4765908c8a49cf903941",
            "526de3fc8c7746be8550b621593bafb5",
            "50784f07b76a442fa9cb1dba4b4bd38a",
            "c13c8f30ff804c1bbde787f3cf535ea9",
            "2f8cc8213cf14d1db8f4505f11a59f13",
            "36bc91f2005743d69a80e6157a4c99ff",
            "c6958b56a1a74bb695bc7f110418345e",
            "6c1925ede8d048f187a6f47a838cc1c1",
            "1514e16d2ca641e1beb7c9aa65f1704e",
            "8e23ff7692444784a3ddef5cecfa4e0c",
            "762eaf394f204e16a2c7df74cffba6e0",
            "1d102db3656d4e19bbb8e3c8c4fabcc6",
            "548b0dc0b8a948febd15dd7090a5223d",
            "d2493dbb29eb46ef936c51b17670a038",
            "c92ca1fdbc524c67b0240be94323b1bc",
            "a041cfc0ab314db69628ec516d37c2f9",
            "7deaed33b7cb48898579f1437f4a0b6e",
            "d3af3d0dc88b4fdd90a4c526f0ce5c3f",
            "5e52bda9804b4b09bf5fed09d8569e6d",
            "cf3844b6013046c7b0d60e7776d772d0",
            "90e315649767403399a119010787f535",
            "e8aa708713f94de0bf1d851b071693fa",
            "590713f9bd6c438188fc683e4a5f102e",
            "e07d2f64d5044c32bdc169e2446ecc56",
            "a0d4e8b4672c4517ade72882d01ec701",
            "49fb78add5384e2d97c145e4ae108a4c",
            "6c183756eba64b64a998fc7642512199"
          ]
        },
        "outputId": "6e6e67cb-373d-41d8-ff2e-9da3192abcce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/476 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f079b9aabfc54a2d9da91cbd6678361a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/751k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98a2cdf7da7e4cfdb15a075652ec9c0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36bc91f2005743d69a80e6157a4c99ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7deaed33b7cb48898579f1437f4a0b6e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VtYaJAnOjGeN"
      },
      "outputs": [],
      "source": [
        "def getIDs_attention(data):\n",
        "  # Create empty lists to store outputs\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  #tokenizer = AutoTokenizer.from_pretrained(model_name) if version == \"mini\" else AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "  # For every sentence...\n",
        "  for i,sent in enumerate(data):\n",
        "      # `encode_plus` will:\n",
        "      #    (1) Tokenize the sentence\n",
        "      #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
        "      #    (3) Truncate/Pad sentence to max length\n",
        "      #    (4) Map tokens to their IDs\n",
        "      #    (5) Create attention mask\n",
        "      #    (6) Return a dictionary of outputs\n",
        "      encoded_sent = tokenizer.encode_plus(\n",
        "          text=sent,  # Preprocess sentence\n",
        "          add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "          max_length=64,                  # Max length to truncate/pad\n",
        "          padding='max_length',        # Pad sentence to max length\n",
        "          #return_tensors='pt',           # Return PyTorch tensor\n",
        "          return_attention_mask=True,     # Return attention mask\n",
        "          truncation = True \n",
        "          )\n",
        "      \n",
        "      # Add the outputs to the lists\n",
        "      input_ids.append(encoded_sent.get('input_ids'))\n",
        "      attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "    # Convert lists to tensors\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "  return input_ids, attention_masks\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7_er5ccMk8Dy"
      },
      "outputs": [],
      "source": [
        "# get ids and mask attentions for train and val data to feed them to the model\n",
        "train_inputs, train_masks = getIDs_attention(x_train)\n",
        "val_inputs, val_masks = getIDs_attention(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCJU9la9qeUF",
        "outputId": "d34209e4-442d-4cc1-9c1e-9774337ee156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6988\n"
          ]
        }
      ],
      "source": [
        "print(len(train_masks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbrlme8otxFX",
        "outputId": "ea540573-28f7-4e7d-999e-4220c3243dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6988\n",
            "6988\n",
            "6988\n",
            "6988\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert other data types to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoader for our training set\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "print(len(train_data))\n",
        "print(len(train_inputs))\n",
        "print(len(train_masks))\n",
        "print(len(train_labels))\n",
        "\n",
        "# Create the DataLoader for our validation set\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sldCHNGLn03M"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QdLWTC-cnxLH"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.optim import SparseAdam, Adam\n",
        "def initialize_model(epochs=4, version=\"mini\"):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=True)\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # Create the optimizer\n",
        "    optimizer = AdamW(params=list(bert_classifier.parameters()),\n",
        "                      lr=0.001,    # Default learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    #Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer ,scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6sAt0AZKnxND"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, optimizer,scheduler,train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    # Start training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "             \n",
        "           \n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "          \n",
        "            # Zero out any previously calculated gradients\n",
        "            \n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "      \n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if evaluation == True:\n",
        "            # After the completion of each training epoch, measure the model's performance\n",
        "            # on our validation set.\n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5VEy7SOoXG6"
      },
      "source": [
        "# evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "oqcclEMCnxQf"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv7jR_kqogkx"
      },
      "source": [
        "# Initialize and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "41613c3775c14759afda77ea40a6a49f",
            "348ee06b7fd04c61bf7795369bb321a5",
            "49efc39a1c174bbcab499c4e16b641b0",
            "2f8d65b5f46c42f2aeb8987433ad31f9",
            "9180ff03abda4e6abd23a5bb86871558",
            "25caea55340c438c80f5e11d1045ff22",
            "fd8829e2ca6c4be191b585b112aa1d95",
            "7dd81c092c344c87b21b68772652be78",
            "fc84ade92d7a4af1b3fa8e560126ba60",
            "77ec49ae08e945809ced977251eb11f8",
            "c212e6bc07124fe18ffc681bb0bb983f",
            "38f7ea3cbfe341be8ed5b0d72cae84bb",
            "e9b5734445824bcc90022d271612101e",
            "f1dc5989a1144ad19cdc217f6a222d0d",
            "7291306e5462484ea96d0ced311d956e",
            "143e04876dd8421c83b77a4166cf4061",
            "42e19a5ad21f47e4883c87f57f1d5615",
            "162b1a48f8874230babd3e535e4592e2",
            "9b70a53009a646768b9e0439093c0e17",
            "7d658798003b49969d2413e39be48ddb",
            "d1cb80395f8c46f4951f04acbaefc041",
            "59860533e65d4c48beb7ef06a8314393"
          ]
        },
        "id": "bqLTHlKVuBMr",
        "outputId": "88bd667a-6d4c-4dd2-fcb1-2e216df324d6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/667 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41613c3775c14759afda77ea40a6a49f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/541M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38f7ea3cbfe341be8ed5b0d72cae84bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   1.776091   |     -      |     -     |   4.17   \n",
            "   1    |   40    |   1.531064   |     -      |     -     |   1.17   \n",
            "   1    |   60    |   1.436248   |     -      |     -     |   1.17   \n",
            "   1    |   80    |   1.378839   |     -      |     -     |   1.18   \n",
            "   1    |   100   |   1.219503   |     -      |     -     |   1.19   \n",
            "   1    |   120   |   1.178691   |     -      |     -     |   1.21   \n",
            "   1    |   140   |   1.192443   |     -      |     -     |   1.22   \n",
            "   1    |   160   |   1.218920   |     -      |     -     |   1.22   \n",
            "   1    |   180   |   1.232029   |     -      |     -     |   1.22   \n",
            "   1    |   200   |   1.191621   |     -      |     -     |   1.21   \n",
            "   1    |   220   |   1.061597   |     -      |     -     |   1.21   \n",
            "   1    |   240   |   1.252441   |     -      |     -     |   1.20   \n",
            "   1    |   260   |   1.221219   |     -      |     -     |   1.22   \n",
            "   1    |   280   |   1.232861   |     -      |     -     |   1.22   \n",
            "   1    |   300   |   1.282084   |     -      |     -     |   1.22   \n",
            "   1    |   320   |   1.212082   |     -      |     -     |   1.22   \n",
            "   1    |   340   |   1.147254   |     -      |     -     |   1.22   \n",
            "   1    |   360   |   1.130437   |     -      |     -     |   1.22   \n",
            "   1    |   380   |   1.140667   |     -      |     -     |   1.22   \n",
            "   1    |   400   |   1.099910   |     -      |     -     |   1.23   \n",
            "   1    |   420   |   1.156421   |     -      |     -     |   1.22   \n",
            "   1    |   436   |   1.011683   |     -      |     -     |   0.97   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   1.244420   |  0.982366  |   69.25   |   33.21  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   1.241686   |     -      |     -     |   1.31   \n",
            "   2    |   40    |   1.124950   |     -      |     -     |   1.27   \n",
            "   2    |   60    |   1.236110   |     -      |     -     |   1.26   \n",
            "   2    |   80    |   1.132450   |     -      |     -     |   1.28   \n",
            "   2    |   100   |   1.108916   |     -      |     -     |   1.28   \n",
            "   2    |   120   |   1.037052   |     -      |     -     |   1.29   \n",
            "   2    |   140   |   1.125855   |     -      |     -     |   1.31   \n",
            "   2    |   160   |   1.129151   |     -      |     -     |   1.30   \n",
            "   2    |   180   |   1.149151   |     -      |     -     |   1.32   \n",
            "   2    |   200   |   1.085452   |     -      |     -     |   1.32   \n",
            "   2    |   220   |   1.027496   |     -      |     -     |   1.33   \n",
            "   2    |   240   |   1.165120   |     -      |     -     |   1.33   \n",
            "   2    |   260   |   1.165301   |     -      |     -     |   1.31   \n",
            "   2    |   280   |   1.117583   |     -      |     -     |   1.35   \n",
            "   2    |   300   |   1.182956   |     -      |     -     |   1.37   \n",
            "   2    |   320   |   1.161647   |     -      |     -     |   1.35   \n",
            "   2    |   340   |   1.024961   |     -      |     -     |   1.35   \n",
            "   2    |   360   |   1.096034   |     -      |     -     |   1.35   \n",
            "   2    |   380   |   1.053617   |     -      |     -     |   1.34   \n",
            "   2    |   400   |   1.058307   |     -      |     -     |   1.34   \n",
            "   2    |   420   |   1.137859   |     -      |     -     |   1.35   \n",
            "   2    |   436   |   0.982906   |     -      |     -     |   1.07   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   1.117165   |  0.945767  |   69.74   |   32.89  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   1.150176   |     -      |     -     |   1.39   \n",
            "   3    |   40    |   1.064638   |     -      |     -     |   1.31   \n",
            "   3    |   60    |   1.159133   |     -      |     -     |   1.31   \n",
            "   3    |   80    |   1.149128   |     -      |     -     |   1.30   \n",
            "   3    |   100   |   1.106021   |     -      |     -     |   1.29   \n",
            "   3    |   120   |   1.004682   |     -      |     -     |   1.28   \n",
            "   3    |   140   |   1.086876   |     -      |     -     |   1.29   \n",
            "   3    |   160   |   1.115327   |     -      |     -     |   1.28   \n",
            "   3    |   180   |   1.066167   |     -      |     -     |   1.28   \n",
            "   3    |   200   |   1.061180   |     -      |     -     |   1.27   \n",
            "   3    |   220   |   0.968273   |     -      |     -     |   1.26   \n",
            "   3    |   240   |   1.177047   |     -      |     -     |   1.27   \n",
            "   3    |   260   |   1.079195   |     -      |     -     |   1.27   \n",
            "   3    |   280   |   1.031098   |     -      |     -     |   1.27   \n",
            "   3    |   300   |   1.144401   |     -      |     -     |   1.25   \n",
            "   3    |   320   |   1.137793   |     -      |     -     |   1.25   \n",
            "   3    |   340   |   1.032482   |     -      |     -     |   1.24   \n",
            "   3    |   360   |   1.030632   |     -      |     -     |   1.22   \n",
            "   3    |   380   |   1.015009   |     -      |     -     |   1.22   \n",
            "   3    |   400   |   1.021527   |     -      |     -     |   1.24   \n",
            "   3    |   420   |   1.096991   |     -      |     -     |   1.23   \n",
            "   3    |   436   |   0.995049   |     -      |     -     |   0.98   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   1.077864   |  0.944630  |   69.74   |   31.52  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   1.115250   |     -      |     -     |   1.29   \n",
            "   4    |   40    |   1.056530   |     -      |     -     |   1.22   \n",
            "   4    |   60    |   1.147984   |     -      |     -     |   1.22   \n",
            "   4    |   80    |   1.074540   |     -      |     -     |   1.22   \n",
            "   4    |   100   |   0.996043   |     -      |     -     |   1.22   \n",
            "   4    |   120   |   0.976924   |     -      |     -     |   1.23   \n",
            "   4    |   140   |   0.992162   |     -      |     -     |   1.24   \n",
            "   4    |   160   |   1.038744   |     -      |     -     |   1.24   \n",
            "   4    |   180   |   1.061017   |     -      |     -     |   1.24   \n",
            "   4    |   200   |   1.089166   |     -      |     -     |   1.22   \n",
            "   4    |   220   |   0.930531   |     -      |     -     |   1.24   \n",
            "   4    |   240   |   1.186939   |     -      |     -     |   1.24   \n",
            "   4    |   260   |   1.063243   |     -      |     -     |   1.25   \n",
            "   4    |   280   |   1.023695   |     -      |     -     |   1.25   \n",
            "   4    |   300   |   1.144556   |     -      |     -     |   1.26   \n",
            "   4    |   320   |   1.078457   |     -      |     -     |   1.26   \n",
            "   4    |   340   |   0.993505   |     -      |     -     |   1.26   \n",
            "   4    |   360   |   1.052010   |     -      |     -     |   1.26   \n",
            "   4    |   380   |   0.975861   |     -      |     -     |   1.27   \n",
            "   4    |   400   |   1.004867   |     -      |     -     |   1.26   \n",
            "   4    |   420   |   1.071962   |     -      |     -     |   1.28   \n",
            "   4    |   436   |   0.917037   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   1.046379   |  0.939233  |   69.94   |   31.15  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   1.097963   |     -      |     -     |   1.35   \n",
            "   5    |   40    |   1.027228   |     -      |     -     |   1.28   \n",
            "   5    |   60    |   1.151420   |     -      |     -     |   1.29   \n",
            "   5    |   80    |   1.052120   |     -      |     -     |   1.29   \n",
            "   5    |   100   |   1.053246   |     -      |     -     |   1.30   \n",
            "   5    |   120   |   1.028405   |     -      |     -     |   1.29   \n",
            "   5    |   140   |   1.023221   |     -      |     -     |   1.29   \n",
            "   5    |   160   |   1.035277   |     -      |     -     |   1.29   \n",
            "   5    |   180   |   1.072569   |     -      |     -     |   1.28   \n",
            "   5    |   200   |   1.024233   |     -      |     -     |   1.28   \n",
            "   5    |   220   |   0.900644   |     -      |     -     |   1.28   \n",
            "   5    |   240   |   1.108736   |     -      |     -     |   1.28   \n",
            "   5    |   260   |   1.054364   |     -      |     -     |   1.28   \n",
            "   5    |   280   |   1.008881   |     -      |     -     |   1.29   \n",
            "   5    |   300   |   1.116075   |     -      |     -     |   1.29   \n",
            "   5    |   320   |   1.060514   |     -      |     -     |   1.28   \n",
            "   5    |   340   |   0.969262   |     -      |     -     |   1.28   \n",
            "   5    |   360   |   1.001305   |     -      |     -     |   1.27   \n",
            "   5    |   380   |   0.950893   |     -      |     -     |   1.27   \n",
            "   5    |   400   |   0.934438   |     -      |     -     |   1.26   \n",
            "   5    |   420   |   1.026438   |     -      |     -     |   1.26   \n",
            "   5    |   436   |   0.883979   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "   5    |    -    |   1.027886   |  0.926931  |   70.04   |   31.93  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   1.170509   |     -      |     -     |   1.33   \n",
            "   6    |   40    |   1.031229   |     -      |     -     |   1.26   \n",
            "   6    |   60    |   1.083212   |     -      |     -     |   1.26   \n",
            "   6    |   80    |   1.042808   |     -      |     -     |   1.26   \n",
            "   6    |   100   |   0.968669   |     -      |     -     |   1.26   \n",
            "   6    |   120   |   0.921901   |     -      |     -     |   1.26   \n",
            "   6    |   140   |   0.981215   |     -      |     -     |   1.26   \n",
            "   6    |   160   |   0.973318   |     -      |     -     |   1.27   \n",
            "   6    |   180   |   1.040829   |     -      |     -     |   1.27   \n",
            "   6    |   200   |   1.026845   |     -      |     -     |   1.26   \n",
            "   6    |   220   |   0.949120   |     -      |     -     |   1.26   \n",
            "   6    |   240   |   1.093583   |     -      |     -     |   1.28   \n",
            "   6    |   260   |   1.045427   |     -      |     -     |   1.26   \n",
            "   6    |   280   |   1.000427   |     -      |     -     |   1.26   \n",
            "   6    |   300   |   1.100022   |     -      |     -     |   1.26   \n",
            "   6    |   320   |   1.047518   |     -      |     -     |   1.26   \n",
            "   6    |   340   |   0.890306   |     -      |     -     |   1.26   \n",
            "   6    |   360   |   0.989124   |     -      |     -     |   1.26   \n",
            "   6    |   380   |   0.987312   |     -      |     -     |   1.26   \n",
            "   6    |   400   |   0.985815   |     -      |     -     |   1.26   \n",
            "   6    |   420   |   1.005921   |     -      |     -     |   1.27   \n",
            "   6    |   436   |   0.829471   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "   6    |    -    |   1.009483   |  0.953462  |   70.73   |   31.50  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   1.073783   |     -      |     -     |   1.30   \n",
            "   7    |   40    |   1.031613   |     -      |     -     |   1.26   \n",
            "   7    |   60    |   1.097029   |     -      |     -     |   1.24   \n",
            "   7    |   80    |   1.028752   |     -      |     -     |   1.26   \n",
            "   7    |   100   |   1.013144   |     -      |     -     |   1.26   \n",
            "   7    |   120   |   0.952305   |     -      |     -     |   1.26   \n",
            "   7    |   140   |   0.982211   |     -      |     -     |   1.24   \n",
            "   7    |   160   |   0.987494   |     -      |     -     |   1.27   \n",
            "   7    |   180   |   0.986667   |     -      |     -     |   1.27   \n",
            "   7    |   200   |   1.060947   |     -      |     -     |   1.27   \n",
            "   7    |   220   |   0.908168   |     -      |     -     |   1.26   \n",
            "   7    |   240   |   1.090802   |     -      |     -     |   1.25   \n",
            "   7    |   260   |   1.014931   |     -      |     -     |   1.26   \n",
            "   7    |   280   |   0.942885   |     -      |     -     |   1.25   \n",
            "   7    |   300   |   1.105536   |     -      |     -     |   1.26   \n",
            "   7    |   320   |   1.019991   |     -      |     -     |   1.26   \n",
            "   7    |   340   |   0.955238   |     -      |     -     |   1.28   \n",
            "   7    |   360   |   0.985094   |     -      |     -     |   1.26   \n",
            "   7    |   380   |   0.979619   |     -      |     -     |   1.26   \n",
            "   7    |   400   |   0.944737   |     -      |     -     |   1.28   \n",
            "   7    |   420   |   1.052454   |     -      |     -     |   1.26   \n",
            "   7    |   436   |   0.891911   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "   7    |    -    |   1.005978   |  0.909326  |   70.73   |   31.42  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   1.102997   |     -      |     -     |   1.32   \n",
            "   8    |   40    |   1.002766   |     -      |     -     |   1.26   \n",
            "   8    |   60    |   1.044782   |     -      |     -     |   1.26   \n",
            "   8    |   80    |   1.050582   |     -      |     -     |   1.25   \n",
            "   8    |   100   |   0.970250   |     -      |     -     |   1.26   \n",
            "   8    |   120   |   0.924303   |     -      |     -     |   1.26   \n",
            "   8    |   140   |   0.959998   |     -      |     -     |   1.27   \n",
            "   8    |   160   |   0.999761   |     -      |     -     |   1.27   \n",
            "   8    |   180   |   0.949912   |     -      |     -     |   1.27   \n",
            "   8    |   200   |   0.928771   |     -      |     -     |   1.28   \n",
            "   8    |   220   |   0.890187   |     -      |     -     |   1.27   \n",
            "   8    |   240   |   1.051407   |     -      |     -     |   1.26   \n",
            "   8    |   260   |   1.059980   |     -      |     -     |   1.26   \n",
            "   8    |   280   |   0.985860   |     -      |     -     |   1.27   \n",
            "   8    |   300   |   1.118320   |     -      |     -     |   1.26   \n",
            "   8    |   320   |   1.058725   |     -      |     -     |   1.26   \n",
            "   8    |   340   |   0.881332   |     -      |     -     |   1.26   \n",
            "   8    |   360   |   1.000025   |     -      |     -     |   1.26   \n",
            "   8    |   380   |   0.932362   |     -      |     -     |   1.27   \n",
            "   8    |   400   |   0.918364   |     -      |     -     |   1.28   \n",
            "   8    |   420   |   1.058459   |     -      |     -     |   1.26   \n",
            "   8    |   436   |   0.930249   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "   8    |    -    |   0.992608   |  0.912189  |   70.44   |   31.56  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   9    |   20    |   1.115599   |     -      |     -     |   1.35   \n",
            "   9    |   40    |   0.940934   |     -      |     -     |   1.26   \n",
            "   9    |   60    |   1.056837   |     -      |     -     |   1.28   \n",
            "   9    |   80    |   1.024760   |     -      |     -     |   1.27   \n",
            "   9    |   100   |   0.973062   |     -      |     -     |   1.27   \n",
            "   9    |   120   |   0.939993   |     -      |     -     |   1.28   \n",
            "   9    |   140   |   0.966305   |     -      |     -     |   1.29   \n",
            "   9    |   160   |   0.988087   |     -      |     -     |   1.27   \n",
            "   9    |   180   |   1.011518   |     -      |     -     |   1.27   \n",
            "   9    |   200   |   0.993120   |     -      |     -     |   1.28   \n",
            "   9    |   220   |   0.825037   |     -      |     -     |   1.28   \n",
            "   9    |   240   |   1.114574   |     -      |     -     |   1.29   \n",
            "   9    |   260   |   1.027742   |     -      |     -     |   1.26   \n",
            "   9    |   280   |   0.952278   |     -      |     -     |   1.27   \n",
            "   9    |   300   |   1.046927   |     -      |     -     |   1.27   \n",
            "   9    |   320   |   1.056380   |     -      |     -     |   1.28   \n",
            "   9    |   340   |   0.947573   |     -      |     -     |   1.28   \n",
            "   9    |   360   |   1.043926   |     -      |     -     |   1.27   \n",
            "   9    |   380   |   0.912670   |     -      |     -     |   1.28   \n",
            "   9    |   400   |   0.954816   |     -      |     -     |   1.27   \n",
            "   9    |   420   |   1.001550   |     -      |     -     |   1.26   \n",
            "   9    |   436   |   0.862682   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "   9    |    -    |   0.990371   |  0.929376  |   70.34   |   31.76  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  10    |   20    |   1.060801   |     -      |     -     |   1.34   \n",
            "  10    |   40    |   0.968048   |     -      |     -     |   1.26   \n",
            "  10    |   60    |   1.081492   |     -      |     -     |   1.28   \n",
            "  10    |   80    |   1.009195   |     -      |     -     |   1.28   \n",
            "  10    |   100   |   1.003214   |     -      |     -     |   1.28   \n",
            "  10    |   120   |   0.913705   |     -      |     -     |   1.28   \n",
            "  10    |   140   |   0.946663   |     -      |     -     |   1.28   \n",
            "  10    |   160   |   0.957862   |     -      |     -     |   1.26   \n",
            "  10    |   180   |   0.983624   |     -      |     -     |   1.28   \n",
            "  10    |   200   |   1.008162   |     -      |     -     |   1.28   \n",
            "  10    |   220   |   0.883899   |     -      |     -     |   1.27   \n",
            "  10    |   240   |   1.057595   |     -      |     -     |   1.27   \n",
            "  10    |   260   |   0.947647   |     -      |     -     |   1.26   \n",
            "  10    |   280   |   0.954079   |     -      |     -     |   1.26   \n",
            "  10    |   300   |   1.138729   |     -      |     -     |   1.27   \n",
            "  10    |   320   |   1.045765   |     -      |     -     |   1.26   \n",
            "  10    |   340   |   0.964070   |     -      |     -     |   1.26   \n",
            "  10    |   360   |   0.947137   |     -      |     -     |   1.28   \n",
            "  10    |   380   |   0.913448   |     -      |     -     |   1.26   \n",
            "  10    |   400   |   0.945778   |     -      |     -     |   1.27   \n",
            "  10    |   420   |   1.004564   |     -      |     -     |   1.28   \n",
            "  10    |   436   |   0.837673   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  10    |    -    |   0.982090   |  0.924307  |   70.54   |   31.72  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  11    |   20    |   1.057604   |     -      |     -     |   1.35   \n",
            "  11    |   40    |   0.990656   |     -      |     -     |   1.27   \n",
            "  11    |   60    |   1.024140   |     -      |     -     |   1.26   \n",
            "  11    |   80    |   1.023759   |     -      |     -     |   1.26   \n",
            "  11    |   100   |   0.916033   |     -      |     -     |   1.26   \n",
            "  11    |   120   |   0.853585   |     -      |     -     |   1.26   \n",
            "  11    |   140   |   0.880037   |     -      |     -     |   1.28   \n",
            "  11    |   160   |   0.948515   |     -      |     -     |   1.26   \n",
            "  11    |   180   |   0.976693   |     -      |     -     |   1.27   \n",
            "  11    |   200   |   0.983018   |     -      |     -     |   1.27   \n",
            "  11    |   220   |   0.864898   |     -      |     -     |   1.28   \n",
            "  11    |   240   |   1.039014   |     -      |     -     |   1.28   \n",
            "  11    |   260   |   1.001975   |     -      |     -     |   1.27   \n",
            "  11    |   280   |   0.976817   |     -      |     -     |   1.27   \n",
            "  11    |   300   |   1.077373   |     -      |     -     |   1.27   \n",
            "  11    |   320   |   1.006480   |     -      |     -     |   1.26   \n",
            "  11    |   340   |   0.929972   |     -      |     -     |   1.26   \n",
            "  11    |   360   |   0.988510   |     -      |     -     |   1.26   \n",
            "  11    |   380   |   0.935505   |     -      |     -     |   1.24   \n",
            "  11    |   400   |   0.869720   |     -      |     -     |   1.28   \n",
            "  11    |   420   |   0.983100   |     -      |     -     |   1.25   \n",
            "  11    |   436   |   0.901095   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  11    |    -    |   0.965728   |  0.917516  |   70.83   |   31.57  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  12    |   20    |   1.007772   |     -      |     -     |   1.32   \n",
            "  12    |   40    |   0.982860   |     -      |     -     |   1.26   \n",
            "  12    |   60    |   1.105586   |     -      |     -     |   1.26   \n",
            "  12    |   80    |   1.005137   |     -      |     -     |   1.28   \n",
            "  12    |   100   |   0.980563   |     -      |     -     |   1.26   \n",
            "  12    |   120   |   0.962260   |     -      |     -     |   1.26   \n",
            "  12    |   140   |   0.917664   |     -      |     -     |   1.26   \n",
            "  12    |   160   |   0.949648   |     -      |     -     |   1.26   \n",
            "  12    |   180   |   0.945016   |     -      |     -     |   1.26   \n",
            "  12    |   200   |   0.941411   |     -      |     -     |   1.26   \n",
            "  12    |   220   |   0.868960   |     -      |     -     |   1.26   \n",
            "  12    |   240   |   0.990758   |     -      |     -     |   1.26   \n",
            "  12    |   260   |   0.997964   |     -      |     -     |   1.27   \n",
            "  12    |   280   |   0.976478   |     -      |     -     |   1.26   \n",
            "  12    |   300   |   1.050577   |     -      |     -     |   1.27   \n",
            "  12    |   320   |   1.032039   |     -      |     -     |   1.27   \n",
            "  12    |   340   |   0.900068   |     -      |     -     |   1.26   \n",
            "  12    |   360   |   0.953611   |     -      |     -     |   1.26   \n",
            "  12    |   380   |   0.916930   |     -      |     -     |   1.26   \n",
            "  12    |   400   |   0.971998   |     -      |     -     |   1.26   \n",
            "  12    |   420   |   0.986395   |     -      |     -     |   1.26   \n",
            "  12    |   436   |   0.878798   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  12    |    -    |   0.970120   |  0.926173  |   70.54   |   31.48  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  13    |   20    |   1.029878   |     -      |     -     |   1.33   \n",
            "  13    |   40    |   0.932218   |     -      |     -     |   1.26   \n",
            "  13    |   60    |   1.020952   |     -      |     -     |   1.26   \n",
            "  13    |   80    |   1.004310   |     -      |     -     |   1.26   \n",
            "  13    |   100   |   0.970161   |     -      |     -     |   1.24   \n",
            "  13    |   120   |   0.844161   |     -      |     -     |   1.28   \n",
            "  13    |   140   |   0.933526   |     -      |     -     |   1.25   \n",
            "  13    |   160   |   0.934573   |     -      |     -     |   1.26   \n",
            "  13    |   180   |   0.979162   |     -      |     -     |   1.26   \n",
            "  13    |   200   |   0.957719   |     -      |     -     |   1.26   \n",
            "  13    |   220   |   0.854280   |     -      |     -     |   1.26   \n",
            "  13    |   240   |   1.047216   |     -      |     -     |   1.26   \n",
            "  13    |   260   |   0.961121   |     -      |     -     |   1.26   \n",
            "  13    |   280   |   0.922719   |     -      |     -     |   1.26   \n",
            "  13    |   300   |   1.012246   |     -      |     -     |   1.25   \n",
            "  13    |   320   |   0.992135   |     -      |     -     |   1.27   \n",
            "  13    |   340   |   0.896965   |     -      |     -     |   1.26   \n",
            "  13    |   360   |   0.935113   |     -      |     -     |   1.26   \n",
            "  13    |   380   |   0.936359   |     -      |     -     |   1.26   \n",
            "  13    |   400   |   0.958642   |     -      |     -     |   1.26   \n",
            "  13    |   420   |   1.003666   |     -      |     -     |   1.26   \n",
            "  13    |   436   |   0.828810   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  13    |    -    |   0.953852   |  0.934895  |   70.83   |   31.43  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  14    |   20    |   1.045158   |     -      |     -     |   1.33   \n",
            "  14    |   40    |   0.966358   |     -      |     -     |   1.26   \n",
            "  14    |   60    |   1.041363   |     -      |     -     |   1.26   \n",
            "  14    |   80    |   0.986090   |     -      |     -     |   1.24   \n",
            "  14    |   100   |   0.932722   |     -      |     -     |   1.26   \n",
            "  14    |   120   |   0.932637   |     -      |     -     |   1.26   \n",
            "  14    |   140   |   0.943016   |     -      |     -     |   1.26   \n",
            "  14    |   160   |   0.974458   |     -      |     -     |   1.26   \n",
            "  14    |   180   |   0.979952   |     -      |     -     |   1.26   \n",
            "  14    |   200   |   0.960200   |     -      |     -     |   1.26   \n",
            "  14    |   220   |   0.898194   |     -      |     -     |   1.27   \n",
            "  14    |   240   |   1.076157   |     -      |     -     |   1.25   \n",
            "  14    |   260   |   0.967313   |     -      |     -     |   1.26   \n",
            "  14    |   280   |   0.924044   |     -      |     -     |   1.24   \n",
            "  14    |   300   |   1.025874   |     -      |     -     |   1.27   \n",
            "  14    |   320   |   0.989262   |     -      |     -     |   1.26   \n",
            "  14    |   340   |   0.858794   |     -      |     -     |   1.27   \n",
            "  14    |   360   |   0.929613   |     -      |     -     |   1.26   \n",
            "  14    |   380   |   0.874320   |     -      |     -     |   1.26   \n",
            "  14    |   400   |   0.949207   |     -      |     -     |   1.26   \n",
            "  14    |   420   |   0.976647   |     -      |     -     |   1.26   \n",
            "  14    |   436   |   0.865999   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  14    |    -    |   0.960020   |  0.922346  |   70.54   |   31.44  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  15    |   20    |   1.046625   |     -      |     -     |   1.34   \n",
            "  15    |   40    |   0.973056   |     -      |     -     |   1.26   \n",
            "  15    |   60    |   1.015784   |     -      |     -     |   1.27   \n",
            "  15    |   80    |   0.974141   |     -      |     -     |   1.24   \n",
            "  15    |   100   |   0.913031   |     -      |     -     |   1.24   \n",
            "  15    |   120   |   0.902051   |     -      |     -     |   1.27   \n",
            "  15    |   140   |   0.879034   |     -      |     -     |   1.27   \n",
            "  15    |   160   |   0.994297   |     -      |     -     |   1.26   \n",
            "  15    |   180   |   0.955008   |     -      |     -     |   1.26   \n",
            "  15    |   200   |   0.983370   |     -      |     -     |   1.26   \n",
            "  15    |   220   |   0.807666   |     -      |     -     |   1.26   \n",
            "  15    |   240   |   1.040138   |     -      |     -     |   1.28   \n",
            "  15    |   260   |   0.970675   |     -      |     -     |   1.28   \n",
            "  15    |   280   |   0.936447   |     -      |     -     |   1.28   \n",
            "  15    |   300   |   1.061534   |     -      |     -     |   1.26   \n",
            "  15    |   320   |   0.998264   |     -      |     -     |   1.26   \n",
            "  15    |   340   |   0.852264   |     -      |     -     |   1.27   \n",
            "  15    |   360   |   0.979311   |     -      |     -     |   1.26   \n",
            "  15    |   380   |   0.875357   |     -      |     -     |   1.26   \n",
            "  15    |   400   |   0.879648   |     -      |     -     |   1.26   \n",
            "  15    |   420   |   0.964528   |     -      |     -     |   1.27   \n",
            "  15    |   436   |   0.912218   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  15    |    -    |   0.951228   |  0.923078  |   70.24   |   31.56  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  16    |   20    |   1.035657   |     -      |     -     |   1.33   \n",
            "  16    |   40    |   0.965774   |     -      |     -     |   1.26   \n",
            "  16    |   60    |   1.035674   |     -      |     -     |   1.28   \n",
            "  16    |   80    |   0.986916   |     -      |     -     |   1.27   \n",
            "  16    |   100   |   0.937121   |     -      |     -     |   1.28   \n",
            "  16    |   120   |   0.947678   |     -      |     -     |   1.27   \n",
            "  16    |   140   |   0.898113   |     -      |     -     |   1.28   \n",
            "  16    |   160   |   0.941026   |     -      |     -     |   1.26   \n",
            "  16    |   180   |   0.971895   |     -      |     -     |   1.26   \n",
            "  16    |   200   |   0.942681   |     -      |     -     |   1.28   \n",
            "  16    |   220   |   0.877979   |     -      |     -     |   1.28   \n",
            "  16    |   240   |   1.005810   |     -      |     -     |   1.27   \n",
            "  16    |   260   |   0.942312   |     -      |     -     |   1.27   \n",
            "  16    |   280   |   0.915828   |     -      |     -     |   1.27   \n",
            "  16    |   300   |   1.039446   |     -      |     -     |   1.26   \n",
            "  16    |   320   |   1.019634   |     -      |     -     |   1.27   \n",
            "  16    |   340   |   0.872952   |     -      |     -     |   1.27   \n",
            "  16    |   360   |   0.899423   |     -      |     -     |   1.26   \n",
            "  16    |   380   |   0.866061   |     -      |     -     |   1.27   \n",
            "  16    |   400   |   0.898310   |     -      |     -     |   1.28   \n",
            "  16    |   420   |   0.976407   |     -      |     -     |   1.27   \n",
            "  16    |   436   |   0.846627   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  16    |    -    |   0.947633   |  0.918067  |   70.83   |   31.69  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  17    |   20    |   0.991398   |     -      |     -     |   1.34   \n",
            "  17    |   40    |   0.954337   |     -      |     -     |   1.28   \n",
            "  17    |   60    |   1.072472   |     -      |     -     |   1.26   \n",
            "  17    |   80    |   0.978460   |     -      |     -     |   1.28   \n",
            "  17    |   100   |   0.939263   |     -      |     -     |   1.28   \n",
            "  17    |   120   |   0.898944   |     -      |     -     |   1.28   \n",
            "  17    |   140   |   0.894554   |     -      |     -     |   1.28   \n",
            "  17    |   160   |   0.919726   |     -      |     -     |   1.28   \n",
            "  17    |   180   |   0.917207   |     -      |     -     |   1.28   \n",
            "  17    |   200   |   0.936459   |     -      |     -     |   1.27   \n",
            "  17    |   220   |   0.842241   |     -      |     -     |   1.26   \n",
            "  17    |   240   |   0.994000   |     -      |     -     |   1.27   \n",
            "  17    |   260   |   0.976819   |     -      |     -     |   1.27   \n",
            "  17    |   280   |   0.886352   |     -      |     -     |   1.26   \n",
            "  17    |   300   |   1.053423   |     -      |     -     |   1.28   \n",
            "  17    |   320   |   1.024939   |     -      |     -     |   1.28   \n",
            "  17    |   340   |   0.890338   |     -      |     -     |   1.28   \n",
            "  17    |   360   |   0.913367   |     -      |     -     |   1.28   \n",
            "  17    |   380   |   0.866797   |     -      |     -     |   1.27   \n",
            "  17    |   400   |   0.919563   |     -      |     -     |   1.27   \n",
            "  17    |   420   |   0.965759   |     -      |     -     |   1.28   \n",
            "  17    |   436   |   0.854913   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  17    |    -    |   0.941415   |  0.927008  |   70.83   |   31.78  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  18    |   20    |   1.027790   |     -      |     -     |   1.34   \n",
            "  18    |   40    |   0.938081   |     -      |     -     |   1.29   \n",
            "  18    |   60    |   1.039228   |     -      |     -     |   1.28   \n",
            "  18    |   80    |   0.945094   |     -      |     -     |   1.28   \n",
            "  18    |   100   |   0.905944   |     -      |     -     |   1.28   \n",
            "  18    |   120   |   0.888083   |     -      |     -     |   1.28   \n",
            "  18    |   140   |   0.887411   |     -      |     -     |   1.28   \n",
            "  18    |   160   |   0.847085   |     -      |     -     |   1.27   \n",
            "  18    |   180   |   0.941502   |     -      |     -     |   1.28   \n",
            "  18    |   200   |   0.954356   |     -      |     -     |   1.28   \n",
            "  18    |   220   |   0.822002   |     -      |     -     |   1.28   \n",
            "  18    |   240   |   1.027115   |     -      |     -     |   1.28   \n",
            "  18    |   260   |   0.972601   |     -      |     -     |   1.28   \n",
            "  18    |   280   |   0.952833   |     -      |     -     |   1.28   \n",
            "  18    |   300   |   1.027181   |     -      |     -     |   1.26   \n",
            "  18    |   320   |   0.970251   |     -      |     -     |   1.28   \n",
            "  18    |   340   |   0.848486   |     -      |     -     |   1.28   \n",
            "  18    |   360   |   0.987308   |     -      |     -     |   1.27   \n",
            "  18    |   380   |   0.876923   |     -      |     -     |   1.27   \n",
            "  18    |   400   |   0.860940   |     -      |     -     |   1.27   \n",
            "  18    |   420   |   0.972367   |     -      |     -     |   1.29   \n",
            "  18    |   436   |   0.849734   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  18    |    -    |   0.934726   |  0.929167  |   70.83   |   31.89  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  19    |   20    |   1.023560   |     -      |     -     |   1.35   \n",
            "  19    |   40    |   0.900397   |     -      |     -     |   1.29   \n",
            "  19    |   60    |   1.065741   |     -      |     -     |   1.29   \n",
            "  19    |   80    |   0.959069   |     -      |     -     |   1.26   \n",
            "  19    |   100   |   0.901776   |     -      |     -     |   1.27   \n",
            "  19    |   120   |   0.847155   |     -      |     -     |   1.28   \n",
            "  19    |   140   |   0.911923   |     -      |     -     |   1.28   \n",
            "  19    |   160   |   0.900483   |     -      |     -     |   1.29   \n",
            "  19    |   180   |   0.903292   |     -      |     -     |   1.28   \n",
            "  19    |   200   |   0.962328   |     -      |     -     |   1.29   \n",
            "  19    |   220   |   0.839705   |     -      |     -     |   1.28   \n",
            "  19    |   240   |   1.013183   |     -      |     -     |   1.28   \n",
            "  19    |   260   |   1.004499   |     -      |     -     |   1.28   \n",
            "  19    |   280   |   0.933689   |     -      |     -     |   1.28   \n",
            "  19    |   300   |   1.035270   |     -      |     -     |   1.28   \n",
            "  19    |   320   |   1.000140   |     -      |     -     |   1.28   \n",
            "  19    |   340   |   0.869207   |     -      |     -     |   1.28   \n",
            "  19    |   360   |   0.947184   |     -      |     -     |   1.28   \n",
            "  19    |   380   |   0.865392   |     -      |     -     |   1.29   \n",
            "  19    |   400   |   0.887030   |     -      |     -     |   1.29   \n",
            "  19    |   420   |   0.933456   |     -      |     -     |   1.28   \n",
            "  19    |   436   |   0.852563   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  19    |    -    |   0.935364   |  0.934276  |   70.63   |   31.95  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  20    |   20    |   1.024795   |     -      |     -     |   1.34   \n",
            "  20    |   40    |   0.946471   |     -      |     -     |   1.28   \n",
            "  20    |   60    |   0.998087   |     -      |     -     |   1.26   \n",
            "  20    |   80    |   0.984180   |     -      |     -     |   1.28   \n",
            "  20    |   100   |   0.915572   |     -      |     -     |   1.28   \n",
            "  20    |   120   |   0.864221   |     -      |     -     |   1.28   \n",
            "  20    |   140   |   0.881719   |     -      |     -     |   1.28   \n",
            "  20    |   160   |   0.962776   |     -      |     -     |   1.28   \n",
            "  20    |   180   |   0.931395   |     -      |     -     |   1.27   \n",
            "  20    |   200   |   0.920265   |     -      |     -     |   1.27   \n",
            "  20    |   220   |   0.831947   |     -      |     -     |   1.28   \n",
            "  20    |   240   |   1.024142   |     -      |     -     |   1.27   \n",
            "  20    |   260   |   0.960496   |     -      |     -     |   1.28   \n",
            "  20    |   280   |   0.903536   |     -      |     -     |   1.27   \n",
            "  20    |   300   |   0.990049   |     -      |     -     |   1.26   \n",
            "  20    |   320   |   0.971902   |     -      |     -     |   1.28   \n",
            "  20    |   340   |   0.860083   |     -      |     -     |   1.28   \n",
            "  20    |   360   |   0.854423   |     -      |     -     |   1.26   \n",
            "  20    |   380   |   0.843903   |     -      |     -     |   1.26   \n",
            "  20    |   400   |   0.856818   |     -      |     -     |   1.26   \n",
            "  20    |   420   |   0.918400   |     -      |     -     |   1.26   \n",
            "  20    |   436   |   0.805431   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  20    |    -    |   0.921774   |  0.946447  |   70.83   |   31.75  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  21    |   20    |   1.046026   |     -      |     -     |   1.34   \n",
            "  21    |   40    |   0.923478   |     -      |     -     |   1.28   \n",
            "  21    |   60    |   1.080509   |     -      |     -     |   1.27   \n",
            "  21    |   80    |   0.953245   |     -      |     -     |   1.28   \n",
            "  21    |   100   |   0.948483   |     -      |     -     |   1.26   \n",
            "  21    |   120   |   0.878655   |     -      |     -     |   1.26   \n",
            "  21    |   140   |   0.864605   |     -      |     -     |   1.28   \n",
            "  21    |   160   |   0.897607   |     -      |     -     |   1.26   \n",
            "  21    |   180   |   0.863871   |     -      |     -     |   1.26   \n",
            "  21    |   200   |   0.933785   |     -      |     -     |   1.28   \n",
            "  21    |   220   |   0.846859   |     -      |     -     |   1.26   \n",
            "  21    |   240   |   1.052906   |     -      |     -     |   1.28   \n",
            "  21    |   260   |   0.931067   |     -      |     -     |   1.27   \n",
            "  21    |   280   |   0.895041   |     -      |     -     |   1.26   \n",
            "  21    |   300   |   0.998394   |     -      |     -     |   1.28   \n",
            "  21    |   320   |   1.006108   |     -      |     -     |   1.28   \n",
            "  21    |   340   |   0.858462   |     -      |     -     |   1.27   \n",
            "  21    |   360   |   0.939670   |     -      |     -     |   1.28   \n",
            "  21    |   380   |   0.833523   |     -      |     -     |   1.26   \n",
            "  21    |   400   |   0.831185   |     -      |     -     |   1.28   \n",
            "  21    |   420   |   0.957166   |     -      |     -     |   1.27   \n",
            "  21    |   436   |   0.801858   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  21    |    -    |   0.926061   |  0.946226  |   70.14   |   31.69  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  22    |   20    |   0.988987   |     -      |     -     |   1.33   \n",
            "  22    |   40    |   0.929558   |     -      |     -     |   1.28   \n",
            "  22    |   60    |   1.099429   |     -      |     -     |   1.26   \n",
            "  22    |   80    |   0.972639   |     -      |     -     |   1.27   \n",
            "  22    |   100   |   0.911341   |     -      |     -     |   1.27   \n",
            "  22    |   120   |   0.922852   |     -      |     -     |   1.27   \n",
            "  22    |   140   |   0.833412   |     -      |     -     |   1.27   \n",
            "  22    |   160   |   0.933503   |     -      |     -     |   1.27   \n",
            "  22    |   180   |   0.965671   |     -      |     -     |   1.27   \n",
            "  22    |   200   |   0.941335   |     -      |     -     |   1.26   \n",
            "  22    |   220   |   0.843441   |     -      |     -     |   1.26   \n",
            "  22    |   240   |   1.027633   |     -      |     -     |   1.28   \n",
            "  22    |   260   |   0.954203   |     -      |     -     |   1.28   \n",
            "  22    |   280   |   0.886509   |     -      |     -     |   1.28   \n",
            "  22    |   300   |   1.056904   |     -      |     -     |   1.26   \n",
            "  22    |   320   |   0.970488   |     -      |     -     |   1.26   \n",
            "  22    |   340   |   0.893795   |     -      |     -     |   1.28   \n",
            "  22    |   360   |   0.922565   |     -      |     -     |   1.27   \n",
            "  22    |   380   |   0.869983   |     -      |     -     |   1.27   \n",
            "  22    |   400   |   0.876506   |     -      |     -     |   1.26   \n",
            "  22    |   420   |   0.985587   |     -      |     -     |   1.27   \n",
            "  22    |   436   |   0.872888   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  22    |    -    |   0.939776   |  0.935673  |   70.04   |   31.66  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  23    |   20    |   1.010651   |     -      |     -     |   1.34   \n",
            "  23    |   40    |   0.956997   |     -      |     -     |   1.26   \n",
            "  23    |   60    |   1.039137   |     -      |     -     |   1.26   \n",
            "  23    |   80    |   0.939316   |     -      |     -     |   1.27   \n",
            "  23    |   100   |   0.909339   |     -      |     -     |   1.27   \n",
            "  23    |   120   |   0.835216   |     -      |     -     |   1.28   \n",
            "  23    |   140   |   0.917685   |     -      |     -     |   1.26   \n",
            "  23    |   160   |   0.887860   |     -      |     -     |   1.26   \n",
            "  23    |   180   |   0.907874   |     -      |     -     |   1.26   \n",
            "  23    |   200   |   0.934960   |     -      |     -     |   1.27   \n",
            "  23    |   220   |   0.873241   |     -      |     -     |   1.28   \n",
            "  23    |   240   |   1.044064   |     -      |     -     |   1.28   \n",
            "  23    |   260   |   0.932976   |     -      |     -     |   1.27   \n",
            "  23    |   280   |   0.888123   |     -      |     -     |   1.26   \n",
            "  23    |   300   |   0.949478   |     -      |     -     |   1.26   \n",
            "  23    |   320   |   0.958614   |     -      |     -     |   1.28   \n",
            "  23    |   340   |   0.826299   |     -      |     -     |   1.26   \n",
            "  23    |   360   |   0.903278   |     -      |     -     |   1.26   \n",
            "  23    |   380   |   0.883348   |     -      |     -     |   1.28   \n",
            "  23    |   400   |   0.855082   |     -      |     -     |   1.26   \n",
            "  23    |   420   |   0.914028   |     -      |     -     |   1.27   \n",
            "  23    |   436   |   0.811048   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  23    |    -    |   0.918395   |  0.950511  |   71.03   |   31.62  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  24    |   20    |   1.038588   |     -      |     -     |   1.33   \n",
            "  24    |   40    |   0.931325   |     -      |     -     |   1.25   \n",
            "  24    |   60    |   0.987694   |     -      |     -     |   1.27   \n",
            "  24    |   80    |   0.985355   |     -      |     -     |   1.26   \n",
            "  24    |   100   |   0.881355   |     -      |     -     |   1.27   \n",
            "  24    |   120   |   0.807623   |     -      |     -     |   1.27   \n",
            "  24    |   140   |   0.953681   |     -      |     -     |   1.26   \n",
            "  24    |   160   |   0.926252   |     -      |     -     |   1.27   \n",
            "  24    |   180   |   0.902719   |     -      |     -     |   1.28   \n",
            "  24    |   200   |   0.876833   |     -      |     -     |   1.26   \n",
            "  24    |   220   |   0.818937   |     -      |     -     |   1.26   \n",
            "  24    |   240   |   1.077625   |     -      |     -     |   1.27   \n",
            "  24    |   260   |   0.920675   |     -      |     -     |   1.28   \n",
            "  24    |   280   |   0.892403   |     -      |     -     |   1.27   \n",
            "  24    |   300   |   1.019065   |     -      |     -     |   1.27   \n",
            "  24    |   320   |   0.942985   |     -      |     -     |   1.28   \n",
            "  24    |   340   |   0.798420   |     -      |     -     |   1.26   \n",
            "  24    |   360   |   0.921371   |     -      |     -     |   1.26   \n",
            "  24    |   380   |   0.870321   |     -      |     -     |   1.27   \n",
            "  24    |   400   |   0.870178   |     -      |     -     |   1.27   \n",
            "  24    |   420   |   0.940905   |     -      |     -     |   1.26   \n",
            "  24    |   436   |   0.824333   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  24    |    -    |   0.918797   |  0.940446  |   70.34   |   31.60  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  25    |   20    |   0.970342   |     -      |     -     |   1.33   \n",
            "  25    |   40    |   0.858807   |     -      |     -     |   1.28   \n",
            "  25    |   60    |   1.024887   |     -      |     -     |   1.27   \n",
            "  25    |   80    |   0.980403   |     -      |     -     |   1.27   \n",
            "  25    |   100   |   0.874141   |     -      |     -     |   1.28   \n",
            "  25    |   120   |   0.870420   |     -      |     -     |   1.27   \n",
            "  25    |   140   |   0.937793   |     -      |     -     |   1.26   \n",
            "  25    |   160   |   0.914701   |     -      |     -     |   1.27   \n",
            "  25    |   180   |   0.926525   |     -      |     -     |   1.27   \n",
            "  25    |   200   |   0.888452   |     -      |     -     |   1.26   \n",
            "  25    |   220   |   0.777570   |     -      |     -     |   1.26   \n",
            "  25    |   240   |   1.000267   |     -      |     -     |   1.27   \n",
            "  25    |   260   |   0.923788   |     -      |     -     |   1.27   \n",
            "  25    |   280   |   0.879696   |     -      |     -     |   1.27   \n",
            "  25    |   300   |   1.013746   |     -      |     -     |   1.27   \n",
            "  25    |   320   |   0.915764   |     -      |     -     |   1.27   \n",
            "  25    |   340   |   0.848987   |     -      |     -     |   1.28   \n",
            "  25    |   360   |   0.895321   |     -      |     -     |   1.27   \n",
            "  25    |   380   |   0.856929   |     -      |     -     |   1.26   \n",
            "  25    |   400   |   0.921021   |     -      |     -     |   1.27   \n",
            "  25    |   420   |   0.947383   |     -      |     -     |   1.28   \n",
            "  25    |   436   |   0.818606   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  25    |    -    |   0.912144   |  0.937535  |   70.44   |   31.67  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  26    |   20    |   0.976003   |     -      |     -     |   1.34   \n",
            "  26    |   40    |   0.939606   |     -      |     -     |   1.28   \n",
            "  26    |   60    |   0.983244   |     -      |     -     |   1.28   \n",
            "  26    |   80    |   0.954531   |     -      |     -     |   1.27   \n",
            "  26    |   100   |   0.930300   |     -      |     -     |   1.26   \n",
            "  26    |   120   |   0.836411   |     -      |     -     |   1.28   \n",
            "  26    |   140   |   0.888469   |     -      |     -     |   1.27   \n",
            "  26    |   160   |   0.869360   |     -      |     -     |   1.26   \n",
            "  26    |   180   |   0.907626   |     -      |     -     |   1.26   \n",
            "  26    |   200   |   0.926090   |     -      |     -     |   1.26   \n",
            "  26    |   220   |   0.797149   |     -      |     -     |   1.29   \n",
            "  26    |   240   |   0.961826   |     -      |     -     |   1.27   \n",
            "  26    |   260   |   0.863427   |     -      |     -     |   1.27   \n",
            "  26    |   280   |   0.910417   |     -      |     -     |   1.28   \n",
            "  26    |   300   |   0.986676   |     -      |     -     |   1.27   \n",
            "  26    |   320   |   0.940959   |     -      |     -     |   1.28   \n",
            "  26    |   340   |   0.832650   |     -      |     -     |   1.26   \n",
            "  26    |   360   |   0.883849   |     -      |     -     |   1.28   \n",
            "  26    |   380   |   0.870918   |     -      |     -     |   1.29   \n",
            "  26    |   400   |   0.852276   |     -      |     -     |   1.27   \n",
            "  26    |   420   |   0.963774   |     -      |     -     |   1.29   \n",
            "  26    |   436   |   0.813850   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  26    |    -    |   0.905054   |  0.943513  |   70.93   |   31.77  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  27    |   20    |   0.928200   |     -      |     -     |   1.34   \n",
            "  27    |   40    |   0.917035   |     -      |     -     |   1.26   \n",
            "  27    |   60    |   1.018482   |     -      |     -     |   1.27   \n",
            "  27    |   80    |   0.982801   |     -      |     -     |   1.28   \n",
            "  27    |   100   |   0.846437   |     -      |     -     |   1.27   \n",
            "  27    |   120   |   0.854899   |     -      |     -     |   1.27   \n",
            "  27    |   140   |   0.830316   |     -      |     -     |   1.29   \n",
            "  27    |   160   |   0.867512   |     -      |     -     |   1.27   \n",
            "  27    |   180   |   0.956738   |     -      |     -     |   1.27   \n",
            "  27    |   200   |   0.903968   |     -      |     -     |   1.28   \n",
            "  27    |   220   |   0.856042   |     -      |     -     |   1.26   \n",
            "  27    |   240   |   0.999364   |     -      |     -     |   1.26   \n",
            "  27    |   260   |   0.918300   |     -      |     -     |   1.26   \n",
            "  27    |   280   |   0.883611   |     -      |     -     |   1.28   \n",
            "  27    |   300   |   0.973221   |     -      |     -     |   1.26   \n",
            "  27    |   320   |   0.950449   |     -      |     -     |   1.28   \n",
            "  27    |   340   |   0.789642   |     -      |     -     |   1.27   \n",
            "  27    |   360   |   0.907083   |     -      |     -     |   1.27   \n",
            "  27    |   380   |   0.849158   |     -      |     -     |   1.28   \n",
            "  27    |   400   |   0.861330   |     -      |     -     |   1.27   \n",
            "  27    |   420   |   0.889183   |     -      |     -     |   1.26   \n",
            "  27    |   436   |   0.761710   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  27    |    -    |   0.898835   |  0.951145  |   69.94   |   31.71  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  28    |   20    |   0.998476   |     -      |     -     |   1.33   \n",
            "  28    |   40    |   0.873744   |     -      |     -     |   1.28   \n",
            "  28    |   60    |   1.015476   |     -      |     -     |   1.27   \n",
            "  28    |   80    |   0.951876   |     -      |     -     |   1.26   \n",
            "  28    |   100   |   0.870411   |     -      |     -     |   1.26   \n",
            "  28    |   120   |   0.817987   |     -      |     -     |   1.28   \n",
            "  28    |   140   |   0.874651   |     -      |     -     |   1.27   \n",
            "  28    |   160   |   0.880335   |     -      |     -     |   1.28   \n",
            "  28    |   180   |   0.875151   |     -      |     -     |   1.28   \n",
            "  28    |   200   |   0.949780   |     -      |     -     |   1.27   \n",
            "  28    |   220   |   0.816305   |     -      |     -     |   1.27   \n",
            "  28    |   240   |   0.955170   |     -      |     -     |   1.27   \n",
            "  28    |   260   |   0.915623   |     -      |     -     |   1.28   \n",
            "  28    |   280   |   0.884888   |     -      |     -     |   1.26   \n",
            "  28    |   300   |   0.925449   |     -      |     -     |   1.26   \n",
            "  28    |   320   |   0.960293   |     -      |     -     |   1.26   \n",
            "  28    |   340   |   0.807520   |     -      |     -     |   1.27   \n",
            "  28    |   360   |   0.878217   |     -      |     -     |   1.27   \n",
            "  28    |   380   |   0.789963   |     -      |     -     |   1.26   \n",
            "  28    |   400   |   0.828890   |     -      |     -     |   1.27   \n",
            "  28    |   420   |   0.901484   |     -      |     -     |   1.24   \n",
            "  28    |   436   |   0.775468   |     -      |     -     |   0.98   \n",
            "----------------------------------------------------------------------\n",
            "  28    |    -    |   0.889794   |  0.965821  |   70.24   |   31.63  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  29    |   20    |   0.957816   |     -      |     -     |   1.33   \n",
            "  29    |   40    |   0.903955   |     -      |     -     |   1.26   \n",
            "  29    |   60    |   0.994307   |     -      |     -     |   1.27   \n",
            "  29    |   80    |   0.911942   |     -      |     -     |   1.27   \n",
            "  29    |   100   |   0.926276   |     -      |     -     |   1.27   \n",
            "  29    |   120   |   0.791612   |     -      |     -     |   1.30   \n",
            "  29    |   140   |   0.884695   |     -      |     -     |   1.26   \n",
            "  29    |   160   |   0.896018   |     -      |     -     |   1.27   \n",
            "  29    |   180   |   0.906758   |     -      |     -     |   1.33   \n",
            "  29    |   200   |   0.946568   |     -      |     -     |   1.29   \n",
            "  29    |   220   |   0.809124   |     -      |     -     |   1.27   \n",
            "  29    |   240   |   0.989782   |     -      |     -     |   1.26   \n",
            "  29    |   260   |   0.899358   |     -      |     -     |   1.26   \n",
            "  29    |   280   |   0.886948   |     -      |     -     |   1.24   \n",
            "  29    |   300   |   0.948202   |     -      |     -     |   1.27   \n",
            "  29    |   320   |   0.954848   |     -      |     -     |   1.26   \n",
            "  29    |   340   |   0.823885   |     -      |     -     |   1.26   \n",
            "  29    |   360   |   0.894418   |     -      |     -     |   1.25   \n",
            "  29    |   380   |   0.836201   |     -      |     -     |   1.25   \n",
            "  29    |   400   |   0.897250   |     -      |     -     |   1.25   \n",
            "  29    |   420   |   0.892552   |     -      |     -     |   1.27   \n",
            "  29    |   436   |   0.757156   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  29    |    -    |   0.897306   |  0.970271  |   70.73   |   31.63  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  30    |   20    |   0.955348   |     -      |     -     |   1.34   \n",
            "  30    |   40    |   0.959228   |     -      |     -     |   1.26   \n",
            "  30    |   60    |   0.997853   |     -      |     -     |   1.28   \n",
            "  30    |   80    |   1.001199   |     -      |     -     |   1.34   \n",
            "  30    |   100   |   0.909376   |     -      |     -     |   1.25   \n",
            "  30    |   120   |   0.765730   |     -      |     -     |   1.26   \n",
            "  30    |   140   |   0.930003   |     -      |     -     |   1.26   \n",
            "  30    |   160   |   0.913409   |     -      |     -     |   1.27   \n",
            "  30    |   180   |   0.953103   |     -      |     -     |   1.35   \n",
            "  30    |   200   |   0.900002   |     -      |     -     |   1.30   \n",
            "  30    |   220   |   0.833419   |     -      |     -     |   1.28   \n",
            "  30    |   240   |   1.045446   |     -      |     -     |   1.26   \n",
            "  30    |   260   |   0.891519   |     -      |     -     |   1.26   \n",
            "  30    |   280   |   0.870135   |     -      |     -     |   1.28   \n",
            "  30    |   300   |   0.961822   |     -      |     -     |   1.28   \n",
            "  30    |   320   |   0.946308   |     -      |     -     |   1.27   \n",
            "  30    |   340   |   0.761432   |     -      |     -     |   1.28   \n",
            "  30    |   360   |   0.852218   |     -      |     -     |   1.28   \n",
            "  30    |   380   |   0.826379   |     -      |     -     |   1.29   \n",
            "  30    |   400   |   0.876428   |     -      |     -     |   1.27   \n",
            "  30    |   420   |   0.937913   |     -      |     -     |   1.26   \n",
            "  30    |   436   |   0.813682   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  30    |    -    |   0.905583   |  0.957647  |   71.53   |   31.89  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  31    |   20    |   0.924717   |     -      |     -     |   1.35   \n",
            "  31    |   40    |   0.894413   |     -      |     -     |   1.28   \n",
            "  31    |   60    |   1.021792   |     -      |     -     |   1.28   \n",
            "  31    |   80    |   0.925105   |     -      |     -     |   1.28   \n",
            "  31    |   100   |   0.874899   |     -      |     -     |   1.29   \n",
            "  31    |   120   |   0.819019   |     -      |     -     |   1.27   \n",
            "  31    |   140   |   0.844073   |     -      |     -     |   1.27   \n",
            "  31    |   160   |   0.868369   |     -      |     -     |   1.26   \n",
            "  31    |   180   |   0.908542   |     -      |     -     |   1.28   \n",
            "  31    |   200   |   0.892037   |     -      |     -     |   1.28   \n",
            "  31    |   220   |   0.824018   |     -      |     -     |   1.27   \n",
            "  31    |   240   |   0.974119   |     -      |     -     |   1.28   \n",
            "  31    |   260   |   0.949455   |     -      |     -     |   1.26   \n",
            "  31    |   280   |   0.878664   |     -      |     -     |   1.28   \n",
            "  31    |   300   |   0.970953   |     -      |     -     |   1.28   \n",
            "  31    |   320   |   0.892969   |     -      |     -     |   1.27   \n",
            "  31    |   340   |   0.797073   |     -      |     -     |   1.28   \n",
            "  31    |   360   |   0.919705   |     -      |     -     |   1.28   \n",
            "  31    |   380   |   0.820714   |     -      |     -     |   1.26   \n",
            "  31    |   400   |   0.808136   |     -      |     -     |   1.27   \n",
            "  31    |   420   |   0.917499   |     -      |     -     |   1.27   \n",
            "  31    |   436   |   0.777145   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  31    |    -    |   0.887607   |  0.970170  |   70.44   |   31.81  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  32    |   20    |   0.992457   |     -      |     -     |   1.33   \n",
            "  32    |   40    |   0.869791   |     -      |     -     |   1.29   \n",
            "  32    |   60    |   0.959996   |     -      |     -     |   1.28   \n",
            "  32    |   80    |   0.949246   |     -      |     -     |   1.28   \n",
            "  32    |   100   |   0.910439   |     -      |     -     |   1.28   \n",
            "  32    |   120   |   0.779090   |     -      |     -     |   1.28   \n",
            "  32    |   140   |   0.812285   |     -      |     -     |   1.28   \n",
            "  32    |   160   |   0.874187   |     -      |     -     |   1.29   \n",
            "  32    |   180   |   0.861085   |     -      |     -     |   1.28   \n",
            "  32    |   200   |   0.931919   |     -      |     -     |   1.27   \n",
            "  32    |   220   |   0.809267   |     -      |     -     |   1.28   \n",
            "  32    |   240   |   0.992802   |     -      |     -     |   1.29   \n",
            "  32    |   260   |   0.897701   |     -      |     -     |   1.32   \n",
            "  32    |   280   |   0.781457   |     -      |     -     |   1.28   \n",
            "  32    |   300   |   0.945418   |     -      |     -     |   1.26   \n",
            "  32    |   320   |   0.957081   |     -      |     -     |   1.28   \n",
            "  32    |   340   |   0.864718   |     -      |     -     |   1.28   \n",
            "  32    |   360   |   0.879525   |     -      |     -     |   1.28   \n",
            "  32    |   380   |   0.805694   |     -      |     -     |   1.27   \n",
            "  32    |   400   |   0.846731   |     -      |     -     |   1.28   \n",
            "  32    |   420   |   0.907676   |     -      |     -     |   1.28   \n",
            "  32    |   436   |   0.755661   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  32    |    -    |   0.882504   |  0.962739  |   70.63   |   31.95  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  33    |   20    |   0.943674   |     -      |     -     |   1.34   \n",
            "  33    |   40    |   0.918474   |     -      |     -     |   1.28   \n",
            "  33    |   60    |   0.921298   |     -      |     -     |   1.28   \n",
            "  33    |   80    |   0.935627   |     -      |     -     |   1.29   \n",
            "  33    |   100   |   0.872623   |     -      |     -     |   1.28   \n",
            "  33    |   120   |   0.837623   |     -      |     -     |   1.28   \n",
            "  33    |   140   |   0.834536   |     -      |     -     |   1.28   \n",
            "  33    |   160   |   0.864321   |     -      |     -     |   1.28   \n",
            "  33    |   180   |   0.824392   |     -      |     -     |   1.29   \n",
            "  33    |   200   |   0.876929   |     -      |     -     |   1.27   \n",
            "  33    |   220   |   0.769403   |     -      |     -     |   1.28   \n",
            "  33    |   240   |   0.931004   |     -      |     -     |   1.28   \n",
            "  33    |   260   |   0.908777   |     -      |     -     |   1.28   \n",
            "  33    |   280   |   0.875025   |     -      |     -     |   1.28   \n",
            "  33    |   300   |   0.930640   |     -      |     -     |   1.28   \n",
            "  33    |   320   |   0.888336   |     -      |     -     |   1.28   \n",
            "  33    |   340   |   0.810429   |     -      |     -     |   1.30   \n",
            "  33    |   360   |   0.825132   |     -      |     -     |   1.27   \n",
            "  33    |   380   |   0.817785   |     -      |     -     |   1.29   \n",
            "  33    |   400   |   0.891726   |     -      |     -     |   1.28   \n",
            "  33    |   420   |   0.893215   |     -      |     -     |   1.28   \n",
            "  33    |   436   |   0.805995   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  33    |    -    |   0.872446   |  0.945068  |   70.54   |   31.95  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  34    |   20    |   0.964831   |     -      |     -     |   1.34   \n",
            "  34    |   40    |   0.883114   |     -      |     -     |   1.28   \n",
            "  34    |   60    |   1.014956   |     -      |     -     |   1.28   \n",
            "  34    |   80    |   0.918722   |     -      |     -     |   1.28   \n",
            "  34    |   100   |   0.873359   |     -      |     -     |   1.27   \n",
            "  34    |   120   |   0.824567   |     -      |     -     |   1.29   \n",
            "  34    |   140   |   0.806039   |     -      |     -     |   1.28   \n",
            "  34    |   160   |   0.853721   |     -      |     -     |   1.28   \n",
            "  34    |   180   |   0.869568   |     -      |     -     |   1.29   \n",
            "  34    |   200   |   0.844814   |     -      |     -     |   1.28   \n",
            "  34    |   220   |   0.834553   |     -      |     -     |   1.29   \n",
            "  34    |   240   |   1.017614   |     -      |     -     |   1.28   \n",
            "  34    |   260   |   0.891215   |     -      |     -     |   1.28   \n",
            "  34    |   280   |   0.882319   |     -      |     -     |   1.28   \n",
            "  34    |   300   |   0.962025   |     -      |     -     |   1.28   \n",
            "  34    |   320   |   0.900789   |     -      |     -     |   1.29   \n",
            "  34    |   340   |   0.832657   |     -      |     -     |   1.29   \n",
            "  34    |   360   |   0.911682   |     -      |     -     |   1.28   \n",
            "  34    |   380   |   0.826776   |     -      |     -     |   1.29   \n",
            "  34    |   400   |   0.859653   |     -      |     -     |   1.27   \n",
            "  34    |   420   |   0.859486   |     -      |     -     |   1.26   \n",
            "  34    |   436   |   0.750151   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  34    |    -    |   0.882418   |  0.959334  |   70.73   |   31.92  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  35    |   20    |   0.942699   |     -      |     -     |   1.31   \n",
            "  35    |   40    |   0.897376   |     -      |     -     |   1.26   \n",
            "  35    |   60    |   1.011716   |     -      |     -     |   1.27   \n",
            "  35    |   80    |   0.996061   |     -      |     -     |   1.26   \n",
            "  35    |   100   |   0.801189   |     -      |     -     |   1.25   \n",
            "  35    |   120   |   0.834412   |     -      |     -     |   1.25   \n",
            "  35    |   140   |   0.890970   |     -      |     -     |   1.25   \n",
            "  35    |   160   |   0.881931   |     -      |     -     |   1.26   \n",
            "  35    |   180   |   0.908155   |     -      |     -     |   1.25   \n",
            "  35    |   200   |   0.895676   |     -      |     -     |   1.26   \n",
            "  35    |   220   |   0.786092   |     -      |     -     |   1.28   \n",
            "  35    |   240   |   0.961483   |     -      |     -     |   1.25   \n",
            "  35    |   260   |   0.951131   |     -      |     -     |   1.27   \n",
            "  35    |   280   |   0.876508   |     -      |     -     |   1.26   \n",
            "  35    |   300   |   0.918382   |     -      |     -     |   1.26   \n",
            "  35    |   320   |   0.928251   |     -      |     -     |   1.25   \n",
            "  35    |   340   |   0.858996   |     -      |     -     |   1.26   \n",
            "  35    |   360   |   0.860960   |     -      |     -     |   1.26   \n",
            "  35    |   380   |   0.820704   |     -      |     -     |   1.26   \n",
            "  35    |   400   |   0.801191   |     -      |     -     |   1.27   \n",
            "  35    |   420   |   0.864314   |     -      |     -     |   1.26   \n",
            "  35    |   436   |   0.792591   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  35    |    -    |   0.886472   |  0.958954  |   70.54   |   31.43  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  36    |   20    |   0.979215   |     -      |     -     |   1.32   \n",
            "  36    |   40    |   0.915368   |     -      |     -     |   1.26   \n",
            "  36    |   60    |   1.003847   |     -      |     -     |   1.26   \n",
            "  36    |   80    |   0.922304   |     -      |     -     |   1.26   \n",
            "  36    |   100   |   0.831145   |     -      |     -     |   1.26   \n",
            "  36    |   120   |   0.797165   |     -      |     -     |   1.26   \n",
            "  36    |   140   |   0.876531   |     -      |     -     |   1.27   \n",
            "  36    |   160   |   0.872270   |     -      |     -     |   1.27   \n",
            "  36    |   180   |   0.904088   |     -      |     -     |   1.26   \n",
            "  36    |   200   |   0.835611   |     -      |     -     |   1.26   \n",
            "  36    |   220   |   0.773497   |     -      |     -     |   1.26   \n",
            "  36    |   240   |   0.916848   |     -      |     -     |   1.28   \n",
            "  36    |   260   |   0.901650   |     -      |     -     |   1.26   \n",
            "  36    |   280   |   0.869815   |     -      |     -     |   1.27   \n",
            "  36    |   300   |   0.996861   |     -      |     -     |   1.27   \n",
            "  36    |   320   |   0.889904   |     -      |     -     |   1.28   \n",
            "  36    |   340   |   0.785216   |     -      |     -     |   1.28   \n",
            "  36    |   360   |   0.884079   |     -      |     -     |   1.28   \n",
            "  36    |   380   |   0.770123   |     -      |     -     |   1.28   \n",
            "  36    |   400   |   0.837199   |     -      |     -     |   1.28   \n",
            "  36    |   420   |   0.835775   |     -      |     -     |   1.26   \n",
            "  36    |   436   |   0.764320   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  36    |    -    |   0.872262   |  0.964681  |   70.54   |   31.61  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  37    |   20    |   0.972123   |     -      |     -     |   1.35   \n",
            "  37    |   40    |   0.829727   |     -      |     -     |   1.26   \n",
            "  37    |   60    |   0.943176   |     -      |     -     |   1.26   \n",
            "  37    |   80    |   0.936694   |     -      |     -     |   1.27   \n",
            "  37    |   100   |   0.832510   |     -      |     -     |   1.26   \n",
            "  37    |   120   |   0.812886   |     -      |     -     |   1.28   \n",
            "  37    |   140   |   0.832236   |     -      |     -     |   1.27   \n",
            "  37    |   160   |   0.803034   |     -      |     -     |   1.28   \n",
            "  37    |   180   |   0.851095   |     -      |     -     |   1.28   \n",
            "  37    |   200   |   0.898083   |     -      |     -     |   1.28   \n",
            "  37    |   220   |   0.799234   |     -      |     -     |   1.29   \n",
            "  37    |   240   |   1.001284   |     -      |     -     |   1.28   \n",
            "  37    |   260   |   0.884859   |     -      |     -     |   1.28   \n",
            "  37    |   280   |   0.851759   |     -      |     -     |   1.28   \n",
            "  37    |   300   |   0.953043   |     -      |     -     |   1.27   \n",
            "  37    |   320   |   0.915816   |     -      |     -     |   1.28   \n",
            "  37    |   340   |   0.836837   |     -      |     -     |   1.29   \n",
            "  37    |   360   |   0.884363   |     -      |     -     |   1.28   \n",
            "  37    |   380   |   0.816922   |     -      |     -     |   1.28   \n",
            "  37    |   400   |   0.823068   |     -      |     -     |   1.28   \n",
            "  37    |   420   |   0.927323   |     -      |     -     |   1.28   \n",
            "  37    |   436   |   0.743697   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  37    |    -    |   0.871837   |  0.966042  |   70.63   |   31.86  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  38    |   20    |   0.921000   |     -      |     -     |   1.34   \n",
            "  38    |   40    |   0.883448   |     -      |     -     |   1.28   \n",
            "  38    |   60    |   0.995700   |     -      |     -     |   1.28   \n",
            "  38    |   80    |   0.859618   |     -      |     -     |   1.28   \n",
            "  38    |   100   |   0.833050   |     -      |     -     |   1.28   \n",
            "  38    |   120   |   0.798407   |     -      |     -     |   1.28   \n",
            "  38    |   140   |   0.832923   |     -      |     -     |   1.28   \n",
            "  38    |   160   |   0.822443   |     -      |     -     |   1.27   \n",
            "  38    |   180   |   0.951025   |     -      |     -     |   1.28   \n",
            "  38    |   200   |   0.873569   |     -      |     -     |   1.28   \n",
            "  38    |   220   |   0.816360   |     -      |     -     |   1.27   \n",
            "  38    |   240   |   0.933214   |     -      |     -     |   1.27   \n",
            "  38    |   260   |   0.987249   |     -      |     -     |   1.26   \n",
            "  38    |   280   |   0.877903   |     -      |     -     |   1.27   \n",
            "  38    |   300   |   0.954442   |     -      |     -     |   1.28   \n",
            "  38    |   320   |   0.917614   |     -      |     -     |   1.27   \n",
            "  38    |   340   |   0.814864   |     -      |     -     |   1.27   \n",
            "  38    |   360   |   0.904311   |     -      |     -     |   1.25   \n",
            "  38    |   380   |   0.800637   |     -      |     -     |   1.27   \n",
            "  38    |   400   |   0.803234   |     -      |     -     |   1.28   \n",
            "  38    |   420   |   0.855519   |     -      |     -     |   1.26   \n",
            "  38    |   436   |   0.773354   |     -      |     -     |   0.97   \n",
            "----------------------------------------------------------------------\n",
            "  38    |    -    |   0.874200   |  0.973193  |   70.24   |   31.64  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  39    |   20    |   0.905293   |     -      |     -     |   1.33   \n",
            "  39    |   40    |   0.828224   |     -      |     -     |   1.26   \n",
            "  39    |   60    |   0.966591   |     -      |     -     |   1.27   \n",
            "  39    |   80    |   0.914250   |     -      |     -     |   1.25   \n",
            "  39    |   100   |   0.858554   |     -      |     -     |   1.26   \n",
            "  39    |   120   |   0.835965   |     -      |     -     |   1.24   \n",
            "  39    |   140   |   0.868152   |     -      |     -     |   1.26   \n",
            "  39    |   160   |   0.848271   |     -      |     -     |   1.27   \n",
            "  39    |   180   |   0.849153   |     -      |     -     |   1.26   \n",
            "  39    |   200   |   0.847933   |     -      |     -     |   1.26   \n",
            "  39    |   220   |   0.787609   |     -      |     -     |   1.26   \n",
            "  39    |   240   |   0.914168   |     -      |     -     |   1.26   \n",
            "  39    |   260   |   0.908707   |     -      |     -     |   1.26   \n",
            "  39    |   280   |   0.891802   |     -      |     -     |   1.28   \n",
            "  39    |   300   |   0.961330   |     -      |     -     |   1.26   \n",
            "  39    |   320   |   0.906747   |     -      |     -     |   1.24   \n",
            "  39    |   340   |   0.810690   |     -      |     -     |   1.26   \n",
            "  39    |   360   |   0.835402   |     -      |     -     |   1.26   \n",
            "  39    |   380   |   0.853544   |     -      |     -     |   1.26   \n",
            "  39    |   400   |   0.854628   |     -      |     -     |   1.27   \n",
            "  39    |   420   |   0.891604   |     -      |     -     |   1.26   \n",
            "  39    |   436   |   0.776166   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  39    |    -    |   0.869785   |  0.975308  |   70.83   |   31.46  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  40    |   20    |   0.991283   |     -      |     -     |   1.33   \n",
            "  40    |   40    |   0.855592   |     -      |     -     |   1.26   \n",
            "  40    |   60    |   1.002072   |     -      |     -     |   1.26   \n",
            "  40    |   80    |   0.909932   |     -      |     -     |   1.24   \n",
            "  40    |   100   |   0.782221   |     -      |     -     |   1.27   \n",
            "  40    |   120   |   0.831034   |     -      |     -     |   1.28   \n",
            "  40    |   140   |   0.850365   |     -      |     -     |   1.27   \n",
            "  40    |   160   |   0.847767   |     -      |     -     |   1.25   \n",
            "  40    |   180   |   0.862178   |     -      |     -     |   1.26   \n",
            "  40    |   200   |   0.840784   |     -      |     -     |   1.26   \n",
            "  40    |   220   |   0.804113   |     -      |     -     |   1.24   \n",
            "  40    |   240   |   1.019394   |     -      |     -     |   1.26   \n",
            "  40    |   260   |   0.869042   |     -      |     -     |   1.27   \n",
            "  40    |   280   |   0.828758   |     -      |     -     |   1.26   \n",
            "  40    |   300   |   0.891294   |     -      |     -     |   1.26   \n",
            "  40    |   320   |   0.904165   |     -      |     -     |   1.26   \n",
            "  40    |   340   |   0.749873   |     -      |     -     |   1.26   \n",
            "  40    |   360   |   0.849650   |     -      |     -     |   1.27   \n",
            "  40    |   380   |   0.817321   |     -      |     -     |   1.26   \n",
            "  40    |   400   |   0.829833   |     -      |     -     |   1.28   \n",
            "  40    |   420   |   0.918375   |     -      |     -     |   1.27   \n",
            "  40    |   436   |   0.775839   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  40    |    -    |   0.866145   |  0.961228  |   69.44   |   31.47  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  41    |   20    |   0.925958   |     -      |     -     |   1.31   \n",
            "  41    |   40    |   0.898741   |     -      |     -     |   1.27   \n",
            "  41    |   60    |   0.920788   |     -      |     -     |   1.26   \n",
            "  41    |   80    |   0.905003   |     -      |     -     |   1.26   \n",
            "  41    |   100   |   0.857732   |     -      |     -     |   1.27   \n",
            "  41    |   120   |   0.807574   |     -      |     -     |   1.27   \n",
            "  41    |   140   |   0.866153   |     -      |     -     |   1.28   \n",
            "  41    |   160   |   0.838087   |     -      |     -     |   1.26   \n",
            "  41    |   180   |   0.839091   |     -      |     -     |   1.26   \n",
            "  41    |   200   |   0.903570   |     -      |     -     |   1.26   \n",
            "  41    |   220   |   0.826879   |     -      |     -     |   1.26   \n",
            "  41    |   240   |   1.000109   |     -      |     -     |   1.28   \n",
            "  41    |   260   |   0.896957   |     -      |     -     |   1.27   \n",
            "  41    |   280   |   0.829215   |     -      |     -     |   1.27   \n",
            "  41    |   300   |   1.001294   |     -      |     -     |   1.28   \n",
            "  41    |   320   |   0.862620   |     -      |     -     |   1.27   \n",
            "  41    |   340   |   0.809496   |     -      |     -     |   1.28   \n",
            "  41    |   360   |   0.849646   |     -      |     -     |   1.28   \n",
            "  41    |   380   |   0.768109   |     -      |     -     |   1.26   \n",
            "  41    |   400   |   0.807284   |     -      |     -     |   1.26   \n",
            "  41    |   420   |   0.875215   |     -      |     -     |   1.26   \n",
            "  41    |   436   |   0.734604   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  41    |    -    |   0.866064   |  0.983240  |   70.54   |   31.62  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  42    |   20    |   0.907293   |     -      |     -     |   1.33   \n",
            "  42    |   40    |   0.827256   |     -      |     -     |   1.28   \n",
            "  42    |   60    |   0.958816   |     -      |     -     |   1.28   \n",
            "  42    |   80    |   0.949726   |     -      |     -     |   1.28   \n",
            "  42    |   100   |   0.811840   |     -      |     -     |   1.26   \n",
            "  42    |   120   |   0.769793   |     -      |     -     |   1.26   \n",
            "  42    |   140   |   0.872011   |     -      |     -     |   1.27   \n",
            "  42    |   160   |   0.822847   |     -      |     -     |   1.28   \n",
            "  42    |   180   |   0.861955   |     -      |     -     |   1.27   \n",
            "  42    |   200   |   0.878878   |     -      |     -     |   1.28   \n",
            "  42    |   220   |   0.766312   |     -      |     -     |   1.26   \n",
            "  42    |   240   |   0.922222   |     -      |     -     |   1.27   \n",
            "  42    |   260   |   0.959179   |     -      |     -     |   1.27   \n",
            "  42    |   280   |   0.826325   |     -      |     -     |   1.28   \n",
            "  42    |   300   |   0.958310   |     -      |     -     |   1.28   \n",
            "  42    |   320   |   0.938951   |     -      |     -     |   1.28   \n",
            "  42    |   340   |   0.752110   |     -      |     -     |   1.26   \n",
            "  42    |   360   |   0.873540   |     -      |     -     |   1.26   \n",
            "  42    |   380   |   0.809900   |     -      |     -     |   1.28   \n",
            "  42    |   400   |   0.764818   |     -      |     -     |   1.26   \n",
            "  42    |   420   |   0.890233   |     -      |     -     |   1.26   \n",
            "  42    |   436   |   0.808301   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  42    |    -    |   0.861067   |  0.966624  |   70.63   |   31.72  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  43    |   20    |   0.944625   |     -      |     -     |   1.34   \n",
            "  43    |   40    |   0.833455   |     -      |     -     |   1.29   \n",
            "  43    |   60    |   1.024851   |     -      |     -     |   1.28   \n",
            "  43    |   80    |   0.938286   |     -      |     -     |   1.28   \n",
            "  43    |   100   |   0.853503   |     -      |     -     |   1.28   \n",
            "  43    |   120   |   0.788840   |     -      |     -     |   1.27   \n",
            "  43    |   140   |   0.855109   |     -      |     -     |   1.29   \n",
            "  43    |   160   |   0.825677   |     -      |     -     |   1.27   \n",
            "  43    |   180   |   0.894252   |     -      |     -     |   1.28   \n",
            "  43    |   200   |   0.852866   |     -      |     -     |   1.28   \n",
            "  43    |   220   |   0.804856   |     -      |     -     |   1.28   \n",
            "  43    |   240   |   0.935168   |     -      |     -     |   1.28   \n",
            "  43    |   260   |   0.889361   |     -      |     -     |   1.29   \n",
            "  43    |   280   |   0.881462   |     -      |     -     |   1.29   \n",
            "  43    |   300   |   0.949930   |     -      |     -     |   1.28   \n",
            "  43    |   320   |   0.919309   |     -      |     -     |   1.28   \n",
            "  43    |   340   |   0.813147   |     -      |     -     |   1.28   \n",
            "  43    |   360   |   0.825859   |     -      |     -     |   1.27   \n",
            "  43    |   380   |   0.821762   |     -      |     -     |   1.29   \n",
            "  43    |   400   |   0.775760   |     -      |     -     |   1.28   \n",
            "  43    |   420   |   0.838811   |     -      |     -     |   1.28   \n",
            "  43    |   436   |   0.743309   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  43    |    -    |   0.865390   |  0.972560  |   70.14   |   31.92  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  44    |   20    |   0.931094   |     -      |     -     |   1.34   \n",
            "  44    |   40    |   0.876871   |     -      |     -     |   1.29   \n",
            "  44    |   60    |   0.983487   |     -      |     -     |   1.29   \n",
            "  44    |   80    |   0.921598   |     -      |     -     |   1.28   \n",
            "  44    |   100   |   0.824932   |     -      |     -     |   1.29   \n",
            "  44    |   120   |   0.777970   |     -      |     -     |   1.29   \n",
            "  44    |   140   |   0.854422   |     -      |     -     |   1.30   \n",
            "  44    |   160   |   0.896338   |     -      |     -     |   1.27   \n",
            "  44    |   180   |   0.877680   |     -      |     -     |   1.30   \n",
            "  44    |   200   |   0.839707   |     -      |     -     |   1.28   \n",
            "  44    |   220   |   0.753772   |     -      |     -     |   1.29   \n",
            "  44    |   240   |   0.973362   |     -      |     -     |   1.28   \n",
            "  44    |   260   |   0.866458   |     -      |     -     |   1.29   \n",
            "  44    |   280   |   0.863785   |     -      |     -     |   1.28   \n",
            "  44    |   300   |   0.969313   |     -      |     -     |   1.28   \n",
            "  44    |   320   |   0.924905   |     -      |     -     |   1.28   \n",
            "  44    |   340   |   0.794366   |     -      |     -     |   1.28   \n",
            "  44    |   360   |   0.880848   |     -      |     -     |   1.26   \n",
            "  44    |   380   |   0.779411   |     -      |     -     |   1.27   \n",
            "  44    |   400   |   0.768935   |     -      |     -     |   1.27   \n",
            "  44    |   420   |   0.843344   |     -      |     -     |   1.26   \n",
            "  44    |   436   |   0.676615   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  44    |    -    |   0.859975   |  0.980733  |   70.83   |   31.87  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  45    |   20    |   0.994207   |     -      |     -     |   1.32   \n",
            "  45    |   40    |   0.881346   |     -      |     -     |   1.26   \n",
            "  45    |   60    |   0.954080   |     -      |     -     |   1.26   \n",
            "  45    |   80    |   0.865711   |     -      |     -     |   1.25   \n",
            "  45    |   100   |   0.822931   |     -      |     -     |   1.26   \n",
            "  45    |   120   |   0.806060   |     -      |     -     |   1.25   \n",
            "  45    |   140   |   0.876254   |     -      |     -     |   1.24   \n",
            "  45    |   160   |   0.843693   |     -      |     -     |   1.25   \n",
            "  45    |   180   |   0.890481   |     -      |     -     |   1.23   \n",
            "  45    |   200   |   0.840875   |     -      |     -     |   1.27   \n",
            "  45    |   220   |   0.816009   |     -      |     -     |   1.24   \n",
            "  45    |   240   |   0.936272   |     -      |     -     |   1.24   \n",
            "  45    |   260   |   0.914609   |     -      |     -     |   1.25   \n",
            "  45    |   280   |   0.802463   |     -      |     -     |   1.26   \n",
            "  45    |   300   |   0.959705   |     -      |     -     |   1.27   \n",
            "  45    |   320   |   0.930765   |     -      |     -     |   1.25   \n",
            "  45    |   340   |   0.763771   |     -      |     -     |   1.27   \n",
            "  45    |   360   |   0.776966   |     -      |     -     |   1.27   \n",
            "  45    |   380   |   0.794329   |     -      |     -     |   1.26   \n",
            "  45    |   400   |   0.843929   |     -      |     -     |   1.28   \n",
            "  45    |   420   |   0.863572   |     -      |     -     |   1.28   \n",
            "  45    |   436   |   0.745495   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  45    |    -    |   0.861516   |  0.970881  |   70.54   |   31.42  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  46    |   20    |   0.904642   |     -      |     -     |   1.35   \n",
            "  46    |   40    |   0.860339   |     -      |     -     |   1.28   \n",
            "  46    |   60    |   0.948814   |     -      |     -     |   1.28   \n",
            "  46    |   80    |   0.885595   |     -      |     -     |   1.28   \n",
            "  46    |   100   |   0.850484   |     -      |     -     |   1.28   \n",
            "  46    |   120   |   0.750709   |     -      |     -     |   1.29   \n",
            "  46    |   140   |   0.876412   |     -      |     -     |   1.27   \n",
            "  46    |   160   |   0.811501   |     -      |     -     |   1.29   \n",
            "  46    |   180   |   0.909286   |     -      |     -     |   1.28   \n",
            "  46    |   200   |   0.856109   |     -      |     -     |   1.28   \n",
            "  46    |   220   |   0.775736   |     -      |     -     |   1.28   \n",
            "  46    |   240   |   0.938935   |     -      |     -     |   1.28   \n",
            "  46    |   260   |   0.874732   |     -      |     -     |   1.28   \n",
            "  46    |   280   |   0.856021   |     -      |     -     |   1.28   \n",
            "  46    |   300   |   0.900928   |     -      |     -     |   1.28   \n",
            "  46    |   320   |   0.906766   |     -      |     -     |   1.28   \n",
            "  46    |   340   |   0.804017   |     -      |     -     |   1.29   \n",
            "  46    |   360   |   0.865482   |     -      |     -     |   1.29   \n",
            "  46    |   380   |   0.769232   |     -      |     -     |   1.29   \n",
            "  46    |   400   |   0.782274   |     -      |     -     |   1.28   \n",
            "  46    |   420   |   0.904987   |     -      |     -     |   1.29   \n",
            "  46    |   436   |   0.748653   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  46    |    -    |   0.854790   |  0.973080  |   70.44   |   32.00  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  47    |   20    |   0.922963   |     -      |     -     |   1.34   \n",
            "  47    |   40    |   0.868380   |     -      |     -     |   1.29   \n",
            "  47    |   60    |   0.968487   |     -      |     -     |   1.29   \n",
            "  47    |   80    |   0.926451   |     -      |     -     |   1.28   \n",
            "  47    |   100   |   0.853593   |     -      |     -     |   1.29   \n",
            "  47    |   120   |   0.809757   |     -      |     -     |   1.29   \n",
            "  47    |   140   |   0.860783   |     -      |     -     |   1.26   \n",
            "  47    |   160   |   0.859113   |     -      |     -     |   1.28   \n",
            "  47    |   180   |   0.924012   |     -      |     -     |   1.29   \n",
            "  47    |   200   |   0.820572   |     -      |     -     |   1.28   \n",
            "  47    |   220   |   0.786356   |     -      |     -     |   1.28   \n",
            "  47    |   240   |   0.948487   |     -      |     -     |   1.29   \n",
            "  47    |   260   |   0.901253   |     -      |     -     |   1.28   \n",
            "  47    |   280   |   0.842245   |     -      |     -     |   1.28   \n",
            "  47    |   300   |   0.907770   |     -      |     -     |   1.28   \n",
            "  47    |   320   |   0.886209   |     -      |     -     |   1.28   \n",
            "  47    |   340   |   0.753275   |     -      |     -     |   1.28   \n",
            "  47    |   360   |   0.864177   |     -      |     -     |   1.28   \n",
            "  47    |   380   |   0.794880   |     -      |     -     |   1.28   \n",
            "  47    |   400   |   0.807483   |     -      |     -     |   1.28   \n",
            "  47    |   420   |   0.918993   |     -      |     -     |   1.28   \n",
            "  47    |   436   |   0.752406   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  47    |    -    |   0.863767   |  0.980484  |   70.04   |   31.91  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  48    |   20    |   0.885148   |     -      |     -     |   1.35   \n",
            "  48    |   40    |   0.903699   |     -      |     -     |   1.29   \n",
            "  48    |   60    |   0.938652   |     -      |     -     |   1.27   \n",
            "  48    |   80    |   0.894256   |     -      |     -     |   1.28   \n",
            "  48    |   100   |   0.807664   |     -      |     -     |   1.28   \n",
            "  48    |   120   |   0.744487   |     -      |     -     |   1.27   \n",
            "  48    |   140   |   0.831648   |     -      |     -     |   1.29   \n",
            "  48    |   160   |   0.785955   |     -      |     -     |   1.27   \n",
            "  48    |   180   |   0.857653   |     -      |     -     |   1.27   \n",
            "  48    |   200   |   0.875298   |     -      |     -     |   1.29   \n",
            "  48    |   220   |   0.769113   |     -      |     -     |   1.27   \n",
            "  48    |   240   |   0.875231   |     -      |     -     |   1.29   \n",
            "  48    |   260   |   0.861849   |     -      |     -     |   1.27   \n",
            "  48    |   280   |   0.857840   |     -      |     -     |   1.26   \n",
            "  48    |   300   |   0.891082   |     -      |     -     |   1.28   \n",
            "  48    |   320   |   0.881970   |     -      |     -     |   1.29   \n",
            "  48    |   340   |   0.770410   |     -      |     -     |   1.28   \n",
            "  48    |   360   |   0.809564   |     -      |     -     |   1.29   \n",
            "  48    |   380   |   0.778311   |     -      |     -     |   1.28   \n",
            "  48    |   400   |   0.777135   |     -      |     -     |   1.28   \n",
            "  48    |   420   |   0.862252   |     -      |     -     |   1.28   \n",
            "  48    |   436   |   0.844000   |     -      |     -     |   1.02   \n",
            "----------------------------------------------------------------------\n",
            "  48    |    -    |   0.841129   |  0.977589  |   70.44   |   31.94  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  49    |   20    |   0.889767   |     -      |     -     |   1.35   \n",
            "  49    |   40    |   0.807702   |     -      |     -     |   1.28   \n",
            "  49    |   60    |   0.957770   |     -      |     -     |   1.28   \n",
            "  49    |   80    |   0.881852   |     -      |     -     |   1.30   \n",
            "  49    |   100   |   0.799909   |     -      |     -     |   1.28   \n",
            "  49    |   120   |   0.771639   |     -      |     -     |   1.28   \n",
            "  49    |   140   |   0.787946   |     -      |     -     |   1.28   \n",
            "  49    |   160   |   0.826114   |     -      |     -     |   1.28   \n",
            "  49    |   180   |   0.781255   |     -      |     -     |   1.27   \n",
            "  49    |   200   |   0.857258   |     -      |     -     |   1.28   \n",
            "  49    |   220   |   0.775047   |     -      |     -     |   1.28   \n",
            "  49    |   240   |   0.929533   |     -      |     -     |   1.28   \n",
            "  49    |   260   |   0.900243   |     -      |     -     |   1.28   \n",
            "  49    |   280   |   0.806125   |     -      |     -     |   1.26   \n",
            "  49    |   300   |   0.882063   |     -      |     -     |   1.26   \n",
            "  49    |   320   |   0.933054   |     -      |     -     |   1.26   \n",
            "  49    |   340   |   0.780281   |     -      |     -     |   1.26   \n",
            "  49    |   360   |   0.873475   |     -      |     -     |   1.27   \n",
            "  49    |   380   |   0.751889   |     -      |     -     |   1.26   \n",
            "  49    |   400   |   0.799328   |     -      |     -     |   1.26   \n",
            "  49    |   420   |   0.845982   |     -      |     -     |   1.26   \n",
            "  49    |   436   |   0.798632   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  49    |    -    |   0.838518   |  0.980197  |   70.54   |   31.72  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  50    |   20    |   0.947241   |     -      |     -     |   1.32   \n",
            "  50    |   40    |   0.844579   |     -      |     -     |   1.26   \n",
            "  50    |   60    |   0.931231   |     -      |     -     |   1.26   \n",
            "  50    |   80    |   0.903732   |     -      |     -     |   1.27   \n",
            "  50    |   100   |   0.871730   |     -      |     -     |   1.27   \n",
            "  50    |   120   |   0.821806   |     -      |     -     |   1.26   \n",
            "  50    |   140   |   0.857678   |     -      |     -     |   1.26   \n",
            "  50    |   160   |   0.807685   |     -      |     -     |   1.26   \n",
            "  50    |   180   |   0.904068   |     -      |     -     |   1.26   \n",
            "  50    |   200   |   0.850712   |     -      |     -     |   1.26   \n",
            "  50    |   220   |   0.747163   |     -      |     -     |   1.27   \n",
            "  50    |   240   |   0.942394   |     -      |     -     |   1.27   \n",
            "  50    |   260   |   0.873881   |     -      |     -     |   1.27   \n",
            "  50    |   280   |   0.823922   |     -      |     -     |   1.26   \n",
            "  50    |   300   |   0.924437   |     -      |     -     |   1.26   \n",
            "  50    |   320   |   0.916118   |     -      |     -     |   1.28   \n",
            "  50    |   340   |   0.809602   |     -      |     -     |   1.27   \n",
            "  50    |   360   |   0.856794   |     -      |     -     |   1.26   \n",
            "  50    |   380   |   0.741295   |     -      |     -     |   1.26   \n",
            "  50    |   400   |   0.780223   |     -      |     -     |   1.27   \n",
            "  50    |   420   |   0.861090   |     -      |     -     |   1.27   \n",
            "  50    |   436   |   0.788219   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  50    |    -    |   0.855621   |  0.987996  |   70.73   |   31.54  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  51    |   20    |   0.922958   |     -      |     -     |   1.33   \n",
            "  51    |   40    |   0.841345   |     -      |     -     |   1.26   \n",
            "  51    |   60    |   0.959656   |     -      |     -     |   1.28   \n",
            "  51    |   80    |   0.884702   |     -      |     -     |   1.28   \n",
            "  51    |   100   |   0.778765   |     -      |     -     |   1.28   \n",
            "  51    |   120   |   0.810058   |     -      |     -     |   1.27   \n",
            "  51    |   140   |   0.816910   |     -      |     -     |   1.27   \n",
            "  51    |   160   |   0.839774   |     -      |     -     |   1.26   \n",
            "  51    |   180   |   0.892169   |     -      |     -     |   1.28   \n",
            "  51    |   200   |   0.841869   |     -      |     -     |   1.27   \n",
            "  51    |   220   |   0.754491   |     -      |     -     |   1.26   \n",
            "  51    |   240   |   0.937499   |     -      |     -     |   1.27   \n",
            "  51    |   260   |   0.863198   |     -      |     -     |   1.28   \n",
            "  51    |   280   |   0.808008   |     -      |     -     |   1.26   \n",
            "  51    |   300   |   0.988097   |     -      |     -     |   1.28   \n",
            "  51    |   320   |   0.875388   |     -      |     -     |   1.28   \n",
            "  51    |   340   |   0.787004   |     -      |     -     |   1.26   \n",
            "  51    |   360   |   0.827942   |     -      |     -     |   1.28   \n",
            "  51    |   380   |   0.762587   |     -      |     -     |   1.28   \n",
            "  51    |   400   |   0.772682   |     -      |     -     |   1.28   \n",
            "  51    |   420   |   0.921209   |     -      |     -     |   1.28   \n",
            "  51    |   436   |   0.740637   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  51    |    -    |   0.847825   |  0.974516  |   70.63   |   31.75  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  52    |   20    |   0.945665   |     -      |     -     |   1.34   \n",
            "  52    |   40    |   0.849413   |     -      |     -     |   1.28   \n",
            "  52    |   60    |   0.941358   |     -      |     -     |   1.27   \n",
            "  52    |   80    |   0.847191   |     -      |     -     |   1.29   \n",
            "  52    |   100   |   0.777043   |     -      |     -     |   1.27   \n",
            "  52    |   120   |   0.755826   |     -      |     -     |   1.29   \n",
            "  52    |   140   |   0.833646   |     -      |     -     |   1.28   \n",
            "  52    |   160   |   0.806639   |     -      |     -     |   1.28   \n",
            "  52    |   180   |   0.819089   |     -      |     -     |   1.29   \n",
            "  52    |   200   |   0.831055   |     -      |     -     |   1.28   \n",
            "  52    |   220   |   0.817250   |     -      |     -     |   1.28   \n",
            "  52    |   240   |   0.924856   |     -      |     -     |   1.28   \n",
            "  52    |   260   |   0.876945   |     -      |     -     |   1.28   \n",
            "  52    |   280   |   0.787838   |     -      |     -     |   1.28   \n",
            "  52    |   300   |   0.976455   |     -      |     -     |   1.27   \n",
            "  52    |   320   |   0.905394   |     -      |     -     |   1.28   \n",
            "  52    |   340   |   0.788180   |     -      |     -     |   1.28   \n",
            "  52    |   360   |   0.802427   |     -      |     -     |   1.28   \n",
            "  52    |   380   |   0.780708   |     -      |     -     |   1.28   \n",
            "  52    |   400   |   0.776251   |     -      |     -     |   1.26   \n",
            "  52    |   420   |   0.830075   |     -      |     -     |   1.27   \n",
            "  52    |   436   |   0.759966   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  52    |    -    |   0.838836   |  0.992224  |   70.93   |   31.84  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  53    |   20    |   0.993081   |     -      |     -     |   1.34   \n",
            "  53    |   40    |   0.901853   |     -      |     -     |   1.27   \n",
            "  53    |   60    |   0.922678   |     -      |     -     |   1.28   \n",
            "  53    |   80    |   0.915132   |     -      |     -     |   1.26   \n",
            "  53    |   100   |   0.854099   |     -      |     -     |   1.26   \n",
            "  53    |   120   |   0.814484   |     -      |     -     |   1.26   \n",
            "  53    |   140   |   0.790703   |     -      |     -     |   1.26   \n",
            "  53    |   160   |   0.812469   |     -      |     -     |   1.27   \n",
            "  53    |   180   |   0.845874   |     -      |     -     |   1.27   \n",
            "  53    |   200   |   0.861793   |     -      |     -     |   1.28   \n",
            "  53    |   220   |   0.778832   |     -      |     -     |   1.27   \n",
            "  53    |   240   |   0.941739   |     -      |     -     |   1.26   \n",
            "  53    |   260   |   0.838135   |     -      |     -     |   1.26   \n",
            "  53    |   280   |   0.871708   |     -      |     -     |   1.29   \n",
            "  53    |   300   |   0.899750   |     -      |     -     |   1.29   \n",
            "  53    |   320   |   0.896429   |     -      |     -     |   1.27   \n",
            "  53    |   340   |   0.805732   |     -      |     -     |   1.26   \n",
            "  53    |   360   |   0.797465   |     -      |     -     |   1.26   \n",
            "  53    |   380   |   0.740970   |     -      |     -     |   1.26   \n",
            "  53    |   400   |   0.774407   |     -      |     -     |   1.27   \n",
            "  53    |   420   |   0.834768   |     -      |     -     |   1.28   \n",
            "  53    |   436   |   0.771696   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  53    |    -    |   0.849387   |  0.994619  |   70.83   |   31.66  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  54    |   20    |   0.989756   |     -      |     -     |   1.32   \n",
            "  54    |   40    |   0.874276   |     -      |     -     |   1.26   \n",
            "  54    |   60    |   0.942240   |     -      |     -     |   1.26   \n",
            "  54    |   80    |   0.889088   |     -      |     -     |   1.26   \n",
            "  54    |   100   |   0.828628   |     -      |     -     |   1.27   \n",
            "  54    |   120   |   0.812256   |     -      |     -     |   1.26   \n",
            "  54    |   140   |   0.841449   |     -      |     -     |   1.27   \n",
            "  54    |   160   |   0.794477   |     -      |     -     |   1.29   \n",
            "  54    |   180   |   0.849772   |     -      |     -     |   1.28   \n",
            "  54    |   200   |   0.830635   |     -      |     -     |   1.28   \n",
            "  54    |   220   |   0.737433   |     -      |     -     |   1.28   \n",
            "  54    |   240   |   0.926264   |     -      |     -     |   1.26   \n",
            "  54    |   260   |   0.901233   |     -      |     -     |   1.28   \n",
            "  54    |   280   |   0.823882   |     -      |     -     |   1.29   \n",
            "  54    |   300   |   0.969147   |     -      |     -     |   1.29   \n",
            "  54    |   320   |   0.905583   |     -      |     -     |   1.27   \n",
            "  54    |   340   |   0.776751   |     -      |     -     |   1.28   \n",
            "  54    |   360   |   0.829736   |     -      |     -     |   1.27   \n",
            "  54    |   380   |   0.796623   |     -      |     -     |   1.28   \n",
            "  54    |   400   |   0.775338   |     -      |     -     |   1.29   \n",
            "  54    |   420   |   0.875478   |     -      |     -     |   1.28   \n",
            "  54    |   436   |   0.728081   |     -      |     -     |   1.02   \n",
            "----------------------------------------------------------------------\n",
            "  54    |    -    |   0.851350   |  0.978768  |   70.54   |   31.81  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  55    |   20    |   0.917238   |     -      |     -     |   1.35   \n",
            "  55    |   40    |   0.867605   |     -      |     -     |   1.26   \n",
            "  55    |   60    |   0.962976   |     -      |     -     |   1.28   \n",
            "  55    |   80    |   0.874180   |     -      |     -     |   1.27   \n",
            "  55    |   100   |   0.830768   |     -      |     -     |   1.26   \n",
            "  55    |   120   |   0.774790   |     -      |     -     |   1.28   \n",
            "  55    |   140   |   0.866977   |     -      |     -     |   1.28   \n",
            "  55    |   160   |   0.816110   |     -      |     -     |   1.28   \n",
            "  55    |   180   |   0.808665   |     -      |     -     |   1.28   \n",
            "  55    |   200   |   0.854101   |     -      |     -     |   1.26   \n",
            "  55    |   220   |   0.779271   |     -      |     -     |   1.29   \n",
            "  55    |   240   |   0.971193   |     -      |     -     |   1.28   \n",
            "  55    |   260   |   0.910232   |     -      |     -     |   1.29   \n",
            "  55    |   280   |   0.813645   |     -      |     -     |   1.26   \n",
            "  55    |   300   |   0.881089   |     -      |     -     |   1.26   \n",
            "  55    |   320   |   0.925895   |     -      |     -     |   1.27   \n",
            "  55    |   340   |   0.780335   |     -      |     -     |   1.27   \n",
            "  55    |   360   |   0.843430   |     -      |     -     |   1.28   \n",
            "  55    |   380   |   0.740585   |     -      |     -     |   1.27   \n",
            "  55    |   400   |   0.737613   |     -      |     -     |   1.26   \n",
            "  55    |   420   |   0.780025   |     -      |     -     |   1.28   \n",
            "  55    |   436   |   0.786278   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  55    |    -    |   0.842636   |  0.997896  |   71.33   |   31.76  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  56    |   20    |   0.894077   |     -      |     -     |   1.33   \n",
            "  56    |   40    |   0.855903   |     -      |     -     |   1.26   \n",
            "  56    |   60    |   0.943153   |     -      |     -     |   1.26   \n",
            "  56    |   80    |   0.902096   |     -      |     -     |   1.28   \n",
            "  56    |   100   |   0.800156   |     -      |     -     |   1.26   \n",
            "  56    |   120   |   0.754276   |     -      |     -     |   1.26   \n",
            "  56    |   140   |   0.864546   |     -      |     -     |   1.26   \n",
            "  56    |   160   |   0.807004   |     -      |     -     |   1.26   \n",
            "  56    |   180   |   0.823668   |     -      |     -     |   1.27   \n",
            "  56    |   200   |   0.803004   |     -      |     -     |   1.27   \n",
            "  56    |   220   |   0.767791   |     -      |     -     |   1.27   \n",
            "  56    |   240   |   0.934056   |     -      |     -     |   1.26   \n",
            "  56    |   260   |   0.895163   |     -      |     -     |   1.27   \n",
            "  56    |   280   |   0.810697   |     -      |     -     |   1.28   \n",
            "  56    |   300   |   0.942951   |     -      |     -     |   1.27   \n",
            "  56    |   320   |   0.883343   |     -      |     -     |   1.26   \n",
            "  56    |   340   |   0.774302   |     -      |     -     |   1.27   \n",
            "  56    |   360   |   0.809298   |     -      |     -     |   1.27   \n",
            "  56    |   380   |   0.762526   |     -      |     -     |   1.26   \n",
            "  56    |   400   |   0.755576   |     -      |     -     |   1.26   \n",
            "  56    |   420   |   0.805881   |     -      |     -     |   1.26   \n",
            "  56    |   436   |   0.741566   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  56    |    -    |   0.834207   |  0.986332  |   70.54   |   31.57  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  57    |   20    |   0.929155   |     -      |     -     |   1.34   \n",
            "  57    |   40    |   0.828772   |     -      |     -     |   1.27   \n",
            "  57    |   60    |   0.902218   |     -      |     -     |   1.26   \n",
            "  57    |   80    |   0.894368   |     -      |     -     |   1.28   \n",
            "  57    |   100   |   0.887660   |     -      |     -     |   1.24   \n",
            "  57    |   120   |   0.715694   |     -      |     -     |   1.26   \n",
            "  57    |   140   |   0.842510   |     -      |     -     |   1.28   \n",
            "  57    |   160   |   0.844637   |     -      |     -     |   1.26   \n",
            "  57    |   180   |   0.818922   |     -      |     -     |   1.27   \n",
            "  57    |   200   |   0.816894   |     -      |     -     |   1.24   \n",
            "  57    |   220   |   0.783518   |     -      |     -     |   1.26   \n",
            "  57    |   240   |   0.932336   |     -      |     -     |   1.26   \n",
            "  57    |   260   |   0.857235   |     -      |     -     |   1.28   \n",
            "  57    |   280   |   0.852854   |     -      |     -     |   1.26   \n",
            "  57    |   300   |   0.931717   |     -      |     -     |   1.26   \n",
            "  57    |   320   |   0.933376   |     -      |     -     |   1.27   \n",
            "  57    |   340   |   0.755448   |     -      |     -     |   1.27   \n",
            "  57    |   360   |   0.820846   |     -      |     -     |   1.25   \n",
            "  57    |   380   |   0.725289   |     -      |     -     |   1.26   \n",
            "  57    |   400   |   0.795394   |     -      |     -     |   1.26   \n",
            "  57    |   420   |   0.839295   |     -      |     -     |   1.27   \n",
            "  57    |   436   |   0.730602   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  57    |    -    |   0.839317   |  0.986258  |   70.54   |   31.52  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  58    |   20    |   0.828614   |     -      |     -     |   1.33   \n",
            "  58    |   40    |   0.813954   |     -      |     -     |   1.25   \n",
            "  58    |   60    |   0.922004   |     -      |     -     |   1.26   \n",
            "  58    |   80    |   0.856738   |     -      |     -     |   1.27   \n",
            "  58    |   100   |   0.787824   |     -      |     -     |   1.28   \n",
            "  58    |   120   |   0.806651   |     -      |     -     |   1.26   \n",
            "  58    |   140   |   0.866536   |     -      |     -     |   1.26   \n",
            "  58    |   160   |   0.824188   |     -      |     -     |   1.26   \n",
            "  58    |   180   |   0.861828   |     -      |     -     |   1.28   \n",
            "  58    |   200   |   0.757421   |     -      |     -     |   1.26   \n",
            "  58    |   220   |   0.797735   |     -      |     -     |   1.27   \n",
            "  58    |   240   |   0.939987   |     -      |     -     |   1.27   \n",
            "  58    |   260   |   0.882572   |     -      |     -     |   1.26   \n",
            "  58    |   280   |   0.821587   |     -      |     -     |   1.26   \n",
            "  58    |   300   |   0.885827   |     -      |     -     |   1.27   \n",
            "  58    |   320   |   0.880282   |     -      |     -     |   1.26   \n",
            "  58    |   340   |   0.816504   |     -      |     -     |   1.27   \n",
            "  58    |   360   |   0.762285   |     -      |     -     |   1.26   \n",
            "  58    |   380   |   0.777920   |     -      |     -     |   1.27   \n",
            "  58    |   400   |   0.765742   |     -      |     -     |   1.28   \n",
            "  58    |   420   |   0.825809   |     -      |     -     |   1.28   \n",
            "  58    |   436   |   0.700450   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  58    |    -    |   0.827634   |  0.993663  |   70.83   |   31.57  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  59    |   20    |   0.922936   |     -      |     -     |   1.34   \n",
            "  59    |   40    |   0.843994   |     -      |     -     |   1.27   \n",
            "  59    |   60    |   0.956623   |     -      |     -     |   1.28   \n",
            "  59    |   80    |   0.833707   |     -      |     -     |   1.26   \n",
            "  59    |   100   |   0.896227   |     -      |     -     |   1.27   \n",
            "  59    |   120   |   0.718459   |     -      |     -     |   1.26   \n",
            "  59    |   140   |   0.787393   |     -      |     -     |   1.27   \n",
            "  59    |   160   |   0.763567   |     -      |     -     |   1.27   \n",
            "  59    |   180   |   0.800268   |     -      |     -     |   1.28   \n",
            "  59    |   200   |   0.820895   |     -      |     -     |   1.28   \n",
            "  59    |   220   |   0.757116   |     -      |     -     |   1.28   \n",
            "  59    |   240   |   0.884177   |     -      |     -     |   1.28   \n",
            "  59    |   260   |   0.836930   |     -      |     -     |   1.27   \n",
            "  59    |   280   |   0.838792   |     -      |     -     |   1.26   \n",
            "  59    |   300   |   0.950131   |     -      |     -     |   1.26   \n",
            "  59    |   320   |   0.912622   |     -      |     -     |   1.28   \n",
            "  59    |   340   |   0.765712   |     -      |     -     |   1.26   \n",
            "  59    |   360   |   0.829123   |     -      |     -     |   1.28   \n",
            "  59    |   380   |   0.767675   |     -      |     -     |   1.26   \n",
            "  59    |   400   |   0.761287   |     -      |     -     |   1.27   \n",
            "  59    |   420   |   0.839659   |     -      |     -     |   1.29   \n",
            "  59    |   436   |   0.769958   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  59    |    -    |   0.830636   |  0.992691  |   70.44   |   31.71  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  60    |   20    |   0.881103   |     -      |     -     |   1.35   \n",
            "  60    |   40    |   0.855945   |     -      |     -     |   1.27   \n",
            "  60    |   60    |   0.893034   |     -      |     -     |   1.26   \n",
            "  60    |   80    |   0.830401   |     -      |     -     |   1.27   \n",
            "  60    |   100   |   0.830451   |     -      |     -     |   1.27   \n",
            "  60    |   120   |   0.778374   |     -      |     -     |   1.28   \n",
            "  60    |   140   |   0.765683   |     -      |     -     |   1.27   \n",
            "  60    |   160   |   0.882923   |     -      |     -     |   1.27   \n",
            "  60    |   180   |   0.858547   |     -      |     -     |   1.28   \n",
            "  60    |   200   |   0.862024   |     -      |     -     |   1.29   \n",
            "  60    |   220   |   0.723115   |     -      |     -     |   1.29   \n",
            "  60    |   240   |   0.903930   |     -      |     -     |   1.28   \n",
            "  60    |   260   |   0.864151   |     -      |     -     |   1.28   \n",
            "  60    |   280   |   0.747673   |     -      |     -     |   1.29   \n",
            "  60    |   300   |   0.918541   |     -      |     -     |   1.29   \n",
            "  60    |   320   |   0.936819   |     -      |     -     |   1.28   \n",
            "  60    |   340   |   0.726558   |     -      |     -     |   1.28   \n",
            "  60    |   360   |   0.839959   |     -      |     -     |   1.29   \n",
            "  60    |   380   |   0.788544   |     -      |     -     |   1.29   \n",
            "  60    |   400   |   0.737756   |     -      |     -     |   1.28   \n",
            "  60    |   420   |   0.919692   |     -      |     -     |   1.28   \n",
            "  60    |   436   |   0.710630   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  60    |    -    |   0.831020   |  0.986678  |   69.84   |   31.90  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  61    |   20    |   0.896101   |     -      |     -     |   1.34   \n",
            "  61    |   40    |   0.861353   |     -      |     -     |   1.28   \n",
            "  61    |   60    |   0.890932   |     -      |     -     |   1.28   \n",
            "  61    |   80    |   0.866079   |     -      |     -     |   1.29   \n",
            "  61    |   100   |   0.831293   |     -      |     -     |   1.28   \n",
            "  61    |   120   |   0.753200   |     -      |     -     |   1.26   \n",
            "  61    |   140   |   0.801302   |     -      |     -     |   1.28   \n",
            "  61    |   160   |   0.820641   |     -      |     -     |   1.28   \n",
            "  61    |   180   |   0.849477   |     -      |     -     |   1.28   \n",
            "  61    |   200   |   0.766781   |     -      |     -     |   1.28   \n",
            "  61    |   220   |   0.735616   |     -      |     -     |   1.28   \n",
            "  61    |   240   |   0.886396   |     -      |     -     |   1.28   \n",
            "  61    |   260   |   0.837694   |     -      |     -     |   1.28   \n",
            "  61    |   280   |   0.797446   |     -      |     -     |   1.29   \n",
            "  61    |   300   |   0.827119   |     -      |     -     |   1.28   \n",
            "  61    |   320   |   0.870458   |     -      |     -     |   1.29   \n",
            "  61    |   340   |   0.760067   |     -      |     -     |   1.27   \n",
            "  61    |   360   |   0.787577   |     -      |     -     |   1.27   \n",
            "  61    |   380   |   0.747868   |     -      |     -     |   1.27   \n",
            "  61    |   400   |   0.780953   |     -      |     -     |   1.28   \n",
            "  61    |   420   |   0.820333   |     -      |     -     |   1.27   \n",
            "  61    |   436   |   0.721797   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  61    |    -    |   0.815146   |  0.992453  |   70.54   |   31.88  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  62    |   20    |   0.857616   |     -      |     -     |   1.35   \n",
            "  62    |   40    |   0.853248   |     -      |     -     |   1.28   \n",
            "  62    |   60    |   0.972846   |     -      |     -     |   1.28   \n",
            "  62    |   80    |   0.889650   |     -      |     -     |   1.27   \n",
            "  62    |   100   |   0.869611   |     -      |     -     |   1.28   \n",
            "  62    |   120   |   0.815326   |     -      |     -     |   1.27   \n",
            "  62    |   140   |   0.793423   |     -      |     -     |   1.29   \n",
            "  62    |   160   |   0.847318   |     -      |     -     |   1.28   \n",
            "  62    |   180   |   0.843571   |     -      |     -     |   1.28   \n",
            "  62    |   200   |   0.819951   |     -      |     -     |   1.28   \n",
            "  62    |   220   |   0.753061   |     -      |     -     |   1.29   \n",
            "  62    |   240   |   0.969885   |     -      |     -     |   1.28   \n",
            "  62    |   260   |   0.866736   |     -      |     -     |   1.28   \n",
            "  62    |   280   |   0.799354   |     -      |     -     |   1.28   \n",
            "  62    |   300   |   0.948303   |     -      |     -     |   1.28   \n",
            "  62    |   320   |   0.853882   |     -      |     -     |   1.29   \n",
            "  62    |   340   |   0.727177   |     -      |     -     |   1.28   \n",
            "  62    |   360   |   0.775980   |     -      |     -     |   1.28   \n",
            "  62    |   380   |   0.784522   |     -      |     -     |   1.28   \n",
            "  62    |   400   |   0.803783   |     -      |     -     |   1.27   \n",
            "  62    |   420   |   0.842681   |     -      |     -     |   1.29   \n",
            "  62    |   436   |   0.668948   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  62    |    -    |   0.835971   |  0.984856  |   70.54   |   31.92  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  63    |   20    |   0.932008   |     -      |     -     |   1.35   \n",
            "  63    |   40    |   0.840036   |     -      |     -     |   1.28   \n",
            "  63    |   60    |   0.936700   |     -      |     -     |   1.28   \n",
            "  63    |   80    |   0.894892   |     -      |     -     |   1.28   \n",
            "  63    |   100   |   0.783721   |     -      |     -     |   1.28   \n",
            "  63    |   120   |   0.743944   |     -      |     -     |   1.28   \n",
            "  63    |   140   |   0.829891   |     -      |     -     |   1.28   \n",
            "  63    |   160   |   0.783746   |     -      |     -     |   1.28   \n",
            "  63    |   180   |   0.878353   |     -      |     -     |   1.26   \n",
            "  63    |   200   |   0.802776   |     -      |     -     |   1.28   \n",
            "  63    |   220   |   0.713115   |     -      |     -     |   1.28   \n",
            "  63    |   240   |   0.929845   |     -      |     -     |   1.27   \n",
            "  63    |   260   |   0.872248   |     -      |     -     |   1.29   \n",
            "  63    |   280   |   0.793574   |     -      |     -     |   1.28   \n",
            "  63    |   300   |   0.884073   |     -      |     -     |   1.28   \n",
            "  63    |   320   |   0.846669   |     -      |     -     |   1.27   \n",
            "  63    |   340   |   0.744688   |     -      |     -     |   1.28   \n",
            "  63    |   360   |   0.769371   |     -      |     -     |   1.27   \n",
            "  63    |   380   |   0.778236   |     -      |     -     |   1.27   \n",
            "  63    |   400   |   0.764119   |     -      |     -     |   1.28   \n",
            "  63    |   420   |   0.814370   |     -      |     -     |   1.28   \n",
            "  63    |   436   |   0.693225   |     -      |     -     |   1.01   \n",
            "----------------------------------------------------------------------\n",
            "  63    |    -    |   0.820941   |  0.992497  |   70.93   |   31.86  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  64    |   20    |   0.913220   |     -      |     -     |   1.33   \n",
            "  64    |   40    |   0.837898   |     -      |     -     |   1.29   \n",
            "  64    |   60    |   0.891753   |     -      |     -     |   1.27   \n",
            "  64    |   80    |   0.879071   |     -      |     -     |   1.27   \n",
            "  64    |   100   |   0.779283   |     -      |     -     |   1.27   \n",
            "  64    |   120   |   0.763232   |     -      |     -     |   1.28   \n",
            "  64    |   140   |   0.836345   |     -      |     -     |   1.28   \n",
            "  64    |   160   |   0.831308   |     -      |     -     |   1.28   \n",
            "  64    |   180   |   0.852840   |     -      |     -     |   1.26   \n",
            "  64    |   200   |   0.798110   |     -      |     -     |   1.27   \n",
            "  64    |   220   |   0.788786   |     -      |     -     |   1.28   \n",
            "  64    |   240   |   0.897712   |     -      |     -     |   1.28   \n",
            "  64    |   260   |   0.836847   |     -      |     -     |   1.28   \n",
            "  64    |   280   |   0.752059   |     -      |     -     |   1.28   \n",
            "  64    |   300   |   0.883607   |     -      |     -     |   1.28   \n",
            "  64    |   320   |   0.869029   |     -      |     -     |   1.28   \n",
            "  64    |   340   |   0.763971   |     -      |     -     |   1.27   \n",
            "  64    |   360   |   0.769626   |     -      |     -     |   1.28   \n",
            "  64    |   380   |   0.763937   |     -      |     -     |   1.28   \n",
            "  64    |   400   |   0.732645   |     -      |     -     |   1.27   \n",
            "  64    |   420   |   0.832887   |     -      |     -     |   1.26   \n",
            "  64    |   436   |   0.704592   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  64    |    -    |   0.818467   |  0.995444  |   70.73   |   31.78  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  65    |   20    |   0.859389   |     -      |     -     |   1.34   \n",
            "  65    |   40    |   0.887912   |     -      |     -     |   1.27   \n",
            "  65    |   60    |   0.963131   |     -      |     -     |   1.28   \n",
            "  65    |   80    |   0.845628   |     -      |     -     |   1.27   \n",
            "  65    |   100   |   0.793178   |     -      |     -     |   1.28   \n",
            "  65    |   120   |   0.801714   |     -      |     -     |   1.28   \n",
            "  65    |   140   |   0.835898   |     -      |     -     |   1.27   \n",
            "  65    |   160   |   0.836436   |     -      |     -     |   1.27   \n",
            "  65    |   180   |   0.840036   |     -      |     -     |   1.28   \n",
            "  65    |   200   |   0.784459   |     -      |     -     |   1.28   \n",
            "  65    |   220   |   0.762856   |     -      |     -     |   1.28   \n",
            "  65    |   240   |   0.911606   |     -      |     -     |   1.27   \n",
            "  65    |   260   |   0.837809   |     -      |     -     |   1.26   \n",
            "  65    |   280   |   0.771895   |     -      |     -     |   1.26   \n",
            "  65    |   300   |   0.890864   |     -      |     -     |   1.26   \n",
            "  65    |   320   |   0.859496   |     -      |     -     |   1.26   \n",
            "  65    |   340   |   0.734740   |     -      |     -     |   1.26   \n",
            "  65    |   360   |   0.813373   |     -      |     -     |   1.27   \n",
            "  65    |   380   |   0.700714   |     -      |     -     |   1.27   \n",
            "  65    |   400   |   0.761131   |     -      |     -     |   1.27   \n",
            "  65    |   420   |   0.752478   |     -      |     -     |   1.27   \n",
            "  65    |   436   |   0.715756   |     -      |     -     |   1.00   \n",
            "----------------------------------------------------------------------\n",
            "  65    |    -    |   0.817406   |  0.997385  |   70.24   |   31.71  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  66    |   20    |   0.872821   |     -      |     -     |   1.34   \n",
            "  66    |   40    |   0.880553   |     -      |     -     |   1.27   \n",
            "  66    |   60    |   0.975655   |     -      |     -     |   1.26   \n",
            "  66    |   80    |   0.828397   |     -      |     -     |   1.27   \n",
            "  66    |   100   |   0.784021   |     -      |     -     |   1.26   \n",
            "  66    |   120   |   0.747874   |     -      |     -     |   1.28   \n",
            "  66    |   140   |   0.786312   |     -      |     -     |   1.26   \n",
            "  66    |   160   |   0.869159   |     -      |     -     |   1.27   \n",
            "  66    |   180   |   0.797239   |     -      |     -     |   1.28   \n",
            "  66    |   200   |   0.747391   |     -      |     -     |   1.28   \n",
            "  66    |   220   |   0.748797   |     -      |     -     |   1.28   \n",
            "  66    |   240   |   0.927957   |     -      |     -     |   1.28   \n",
            "  66    |   260   |   0.823876   |     -      |     -     |   1.27   \n",
            "  66    |   280   |   0.812171   |     -      |     -     |   1.27   \n",
            "  66    |   300   |   0.915259   |     -      |     -     |   1.28   \n",
            "  66    |   320   |   0.881192   |     -      |     -     |   1.27   \n",
            "  66    |   340   |   0.802581   |     -      |     -     |   1.28   \n",
            "  66    |   360   |   0.809809   |     -      |     -     |   1.27   \n",
            "  66    |   380   |   0.751225   |     -      |     -     |   1.26   \n",
            "  66    |   400   |   0.753633   |     -      |     -     |   1.26   \n",
            "  66    |   420   |   0.828794   |     -      |     -     |   1.27   \n",
            "  66    |   436   |   0.748490   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  66    |    -    |   0.823211   |  0.985731  |   70.54   |   31.71  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  67    |   20    |   0.860996   |     -      |     -     |   1.34   \n",
            "  67    |   40    |   0.815405   |     -      |     -     |   1.26   \n",
            "  67    |   60    |   0.912538   |     -      |     -     |   1.27   \n",
            "  67    |   80    |   0.821081   |     -      |     -     |   1.27   \n",
            "  67    |   100   |   0.798208   |     -      |     -     |   1.28   \n",
            "  67    |   120   |   0.792213   |     -      |     -     |   1.27   \n",
            "  67    |   140   |   0.806187   |     -      |     -     |   1.27   \n",
            "  67    |   160   |   0.797456   |     -      |     -     |   1.28   \n",
            "  67    |   180   |   0.785766   |     -      |     -     |   1.29   \n",
            "  67    |   200   |   0.834838   |     -      |     -     |   1.27   \n",
            "  67    |   220   |   0.738769   |     -      |     -     |   1.28   \n",
            "  67    |   240   |   0.861959   |     -      |     -     |   1.26   \n",
            "  67    |   260   |   0.853526   |     -      |     -     |   1.27   \n",
            "  67    |   280   |   0.779907   |     -      |     -     |   1.27   \n",
            "  67    |   300   |   0.889925   |     -      |     -     |   1.28   \n",
            "  67    |   320   |   0.836589   |     -      |     -     |   1.28   \n",
            "  67    |   340   |   0.744588   |     -      |     -     |   1.27   \n",
            "  67    |   360   |   0.836809   |     -      |     -     |   1.28   \n",
            "  67    |   380   |   0.767776   |     -      |     -     |   1.26   \n",
            "  67    |   400   |   0.772608   |     -      |     -     |   1.27   \n",
            "  67    |   420   |   0.839713   |     -      |     -     |   1.27   \n",
            "  67    |   436   |   0.745713   |     -      |     -     |   0.98   \n",
            "----------------------------------------------------------------------\n",
            "  67    |    -    |   0.814026   |  0.989289  |   70.44   |   31.70  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  68    |   20    |   0.859838   |     -      |     -     |   1.34   \n",
            "  68    |   40    |   0.801596   |     -      |     -     |   1.28   \n",
            "  68    |   60    |   0.908103   |     -      |     -     |   1.26   \n",
            "  68    |   80    |   0.884850   |     -      |     -     |   1.26   \n",
            "  68    |   100   |   0.750731   |     -      |     -     |   1.26   \n",
            "  68    |   120   |   0.727597   |     -      |     -     |   1.27   \n",
            "  68    |   140   |   0.819021   |     -      |     -     |   1.27   \n",
            "  68    |   160   |   0.821582   |     -      |     -     |   1.28   \n",
            "  68    |   180   |   0.829848   |     -      |     -     |   1.27   \n",
            "  68    |   200   |   0.825099   |     -      |     -     |   1.27   \n",
            "  68    |   220   |   0.737970   |     -      |     -     |   1.27   \n",
            "  68    |   240   |   0.938464   |     -      |     -     |   1.27   \n",
            "  68    |   260   |   0.849455   |     -      |     -     |   1.26   \n",
            "  68    |   280   |   0.822785   |     -      |     -     |   1.27   \n",
            "  68    |   300   |   0.839366   |     -      |     -     |   1.27   \n",
            "  68    |   320   |   0.890435   |     -      |     -     |   1.26   \n",
            "  68    |   340   |   0.722163   |     -      |     -     |   1.26   \n",
            "  68    |   360   |   0.830227   |     -      |     -     |   1.26   \n",
            "  68    |   380   |   0.748745   |     -      |     -     |   1.26   \n",
            "  68    |   400   |   0.800407   |     -      |     -     |   1.26   \n",
            "  68    |   420   |   0.810506   |     -      |     -     |   1.26   \n",
            "  68    |   436   |   0.713916   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "  68    |    -    |   0.816152   |  0.986884  |   70.44   |   31.56  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  69    |   20    |   0.881886   |     -      |     -     |   1.33   \n",
            "  69    |   40    |   0.867349   |     -      |     -     |   1.26   \n",
            "  69    |   60    |   0.914781   |     -      |     -     |   1.27   \n",
            "  69    |   80    |   0.818546   |     -      |     -     |   1.26   \n",
            "  69    |   100   |   0.747657   |     -      |     -     |   1.26   \n",
            "  69    |   120   |   0.728590   |     -      |     -     |   1.24   \n",
            "  69    |   140   |   0.789871   |     -      |     -     |   1.26   \n",
            "  69    |   160   |   0.771806   |     -      |     -     |   1.26   \n",
            "  69    |   180   |   0.816671   |     -      |     -     |   1.26   \n",
            "  69    |   200   |   0.794291   |     -      |     -     |   1.26   \n",
            "  69    |   220   |   0.727203   |     -      |     -     |   1.27   \n",
            "  69    |   240   |   0.861440   |     -      |     -     |   1.27   \n",
            "  69    |   260   |   0.888902   |     -      |     -     |   1.26   \n",
            "  69    |   280   |   0.753067   |     -      |     -     |   1.27   \n",
            "  69    |   300   |   0.877478   |     -      |     -     |   1.28   \n",
            "  69    |   320   |   0.883691   |     -      |     -     |   1.27   \n",
            "  69    |   340   |   0.749116   |     -      |     -     |   1.26   \n",
            "  69    |   360   |   0.794857   |     -      |     -     |   1.27   \n",
            "  69    |   380   |   0.753029   |     -      |     -     |   1.27   \n",
            "  69    |   400   |   0.816346   |     -      |     -     |   1.25   \n",
            "  69    |   420   |   0.817126   |     -      |     -     |   1.26   \n",
            "  69    |   436   |   0.761161   |     -      |     -     |   0.98   \n",
            "----------------------------------------------------------------------\n",
            "  69    |    -    |   0.810376   |  0.987641  |   70.63   |   31.51  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  70    |   20    |   0.861652   |     -      |     -     |   1.34   \n",
            "  70    |   40    |   0.886323   |     -      |     -     |   1.26   \n",
            "  70    |   60    |   0.906546   |     -      |     -     |   1.24   \n",
            "  70    |   80    |   0.865131   |     -      |     -     |   1.26   \n",
            "  70    |   100   |   0.825909   |     -      |     -     |   1.27   \n",
            "  70    |   120   |   0.810729   |     -      |     -     |   1.26   \n",
            "  70    |   140   |   0.793976   |     -      |     -     |   1.27   \n",
            "  70    |   160   |   0.808543   |     -      |     -     |   1.27   \n",
            "  70    |   180   |   0.820787   |     -      |     -     |   1.27   \n",
            "  70    |   200   |   0.744564   |     -      |     -     |   1.28   \n",
            "  70    |   220   |   0.734024   |     -      |     -     |   1.25   \n",
            "  70    |   240   |   0.893617   |     -      |     -     |   1.24   \n",
            "  70    |   260   |   0.860683   |     -      |     -     |   1.25   \n",
            "  70    |   280   |   0.773048   |     -      |     -     |   1.27   \n",
            "  70    |   300   |   0.911377   |     -      |     -     |   1.26   \n",
            "  70    |   320   |   0.849484   |     -      |     -     |   1.27   \n",
            "  70    |   340   |   0.739658   |     -      |     -     |   1.26   \n",
            "  70    |   360   |   0.748306   |     -      |     -     |   1.26   \n",
            "  70    |   380   |   0.709692   |     -      |     -     |   1.25   \n",
            "  70    |   400   |   0.766663   |     -      |     -     |   1.26   \n",
            "  70    |   420   |   0.772413   |     -      |     -     |   1.28   \n",
            "  70    |   436   |   0.727550   |     -      |     -     |   0.98   \n",
            "----------------------------------------------------------------------\n",
            "  70    |    -    |   0.810446   |  0.986781  |   70.63   |   31.49  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "set_seed(42) \n",
        "bert_classifier, optimizer ,scheduler= initialize_model(epochs=70)\n",
        "train(bert_classifier,optimizer,scheduler, train_dataloader, val_dataloader, epochs=70, evaluation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "0etVinYuwlXO"
      },
      "outputs": [],
      "source": [
        "# store the model in pickle file\n",
        "import pickle\n",
        "filename = 'arabert_model.sav'\n",
        "pickle.dump(bert_classifier, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qetcpFTFzWvX"
      },
      "outputs": [],
      "source": [
        "# # Loading the model (to avoid retraining in reruns)\n",
        "\n",
        "# import pickle\n",
        "# filename = 'trained_model_mini_with_emojis.sav'\n",
        "# f = open(filename, 'rb')\n",
        "# bert_classifier = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "i6aOUOyjzb1S"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
        "    on the test set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
        "    # the test time.\n",
        "    #model.eval()\n",
        "\n",
        "    all_logits = []\n",
        "\n",
        "    # For each batch in our test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "        \n",
        "        all_logits.append(logits)\n",
        "         # Concatenate logits from each batch\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    # print(all_logits.shape)\n",
        "    # print(all_logits)\n",
        "    pred_labels=[]\n",
        "    for log in all_logits:\n",
        "      #print(len(log))\n",
        "      highest_score=torch.argmax(log)\n",
        "      #print(highest_score.item())\n",
        "       \n",
        "      pred_labels.append(highest_score)\n",
        "      \n",
        "      \n",
        "    # Apply softmax to calculate probabilities\n",
        "    #probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "\n",
        "    return pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "RJCiqEzSD04X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c373fa0-a1f8-4a33-a0ce-dbf3ce914269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 4 0 1 1 1 4 1 1 1 1 1 2 2 0 1 0 2 0 4 1 1 0 1 1 0 1 1 2 1 0 1 4 3 1 7 0\n",
            " 0 4 1 0 0 1 4 1 0 1 3 4 0 1 1 1 0 1 4 0 1 4 1 2 1 2 1 1 2 1 1 1 1 0 1 1 7\n",
            " 1 4 1 1 3 1 5 2 2 7 1 1 1 0 0 1 2 4 1 2 4 2 2 1 1 0 1 3 1 1 0 0 2 1 1 1 0\n",
            " 1 1 2 1 1 0 1 2 3 1 1 1 1 2 1 1 1 1 1 1 0 1 1 1 1 1 5 1 1 0 1 2 2 4 0 1 2\n",
            " 1 1 6 2 1 1 1 6 1 1 0 3 3 1 1 1 1 1 1 3 3 0 5 0 1 1 0 1 1 1 4 1 1 1 6 2 1\n",
            " 1 4 0 1 1 5 1 1 1 0 4 4 1 8 2 4 1 1 1 1 1 0 1 1 2 1 1 0 1 1 1 1 1 3 5 2 1\n",
            " 1 1 1 0 2 1 8 3 1 1 7 4 1 2 1 0 2 2 1 1 1 1 2 2 1 0 0 1 2 8 1 4 1 1 1 4 1\n",
            " 4 1 1 1 1 4 3 2 1 1 8 6 1 2 1 0 1 5 5 1 1 2 1 0 1 0 4 2 1 0 4 1 1 1 5 5 1\n",
            " 1 2 4 1 2 1 1 2 1 0 2 1 1 1 2 1 2 1 5 1 1 1 1 1 0 0 1 1 1 1 0 1 2 2 6 1 1\n",
            " 1 1 1 0 4 1 1 1 2 1 2 2 1 1 1 3 0 1 8 1 1 1 4 3 1 4 0 1 1 1 2 2 4 1 4 4 1\n",
            " 4 1 1 1 1 1 2 1 1 0 1 8 1 1 1 1 2 1 1 1 4 0 1 1 0 4 1 1 1 4 3 1 0 0 0 1 1\n",
            " 0 1 1 1 1 0 1 1 0 2 2 0 2 2 0 1 1 1 1 1 4 0 1 0 1 7 1 4 4 1 2 1 0 2 1 1 1\n",
            " 0 3 1 6 1 5 1 0 4 1 0 1 1 1 1 0 1 3 0 2 6 0 1 1 3 0 1 2 2 1 1 2 1 6 1 1 1\n",
            " 1 1 1 2 2 1 1 1 1 0 2 2 4 1 6 2 1 0 3 1 1 2 1 0 2 1 3 1 5 1 1 1 1 1 1 2 1\n",
            " 0 6 7 1 1 2 4 1 7 1 0 1 0 1 0 0 6 1 2 4 0 1 1 0 1 1 1 1 0 2 1 7 6 1 0 3 1\n",
            " 2 1 1 1 1 0 9 7 0 0 2 2 1 1 1 8 1 0 1 1 1 1 0 1 1 1 6 0 1 0 2 1 1 2 1 1 4\n",
            " 1 3 1 1 1 4 1 4 0 2 1 1 3 2 1 0 2 2 2 1 1 2 1 4 7 0 0 2 1 3 4 1 0 9 2 1 1\n",
            " 4 1 0 1 2 1 1 1 4 1 1 1 1 1 1 1 1 1 0 6 1 1 1 0 4 1 4 2 1 1 0 1 4 1 1 1 2\n",
            " 1 1 1 1 2 1 1 1 1 1 0 2 1 5 1 1 1 1 1 1 0 0 1 4 1 4 1 2 0 4 2 1 0 4 2 1 2\n",
            " 1 0 0 1 0 2 3 1 4 0 1 0 1 2 1 1 1 4 1 1 1 1 0 1 1 2 1 2 1 1 1 0 1 1 3 1 4\n",
            " 1 1 0 0 1 1 1 0 1 1 1 2 1 1 1 1 1 1 6 5 1 1 4 1 0 0 1 0 2 1 1 3 1 1 2 0 1\n",
            " 1 1 0 0 0 1 4 1 0 1 1 0 1 3 1 4 1 1 1 1 1 1 4 1 1 0 1 1 2 1 1 1 4 1 1 1 2\n",
            " 4 1 1 0 0 4 4 5 1 5 0 1 1 1 8 4 1 0 4 2 2 1 4 2 2 1 0 2 3 1 1 3 1 1 2 0 1\n",
            " 1 2 2 1 0 1 1 1 1 1 0 2 3 2 0 8 0 1 1 1 2 5 1 1 4 0 0 1 2 1 1 1 0 2 1 1 1\n",
            " 1 2 7 4 1 1 1 1 1 1 4 1 1 1 1 4 4 1 0 0 1 1 0 0 5 1 1 1 1 1 4 1 1 1 0 4 1\n",
            " 1 2 1 1 1 1 1 2 1 1 5 1 4 1 2 1 2 1 7 7 1 1 1 4 2 1 1 6 1 1 4 0 1 1 1 1 2\n",
            " 1 3 0 1 1 2 3 2 7 0 2 1 1 1 8 6 1 2 2 1 3 1 3 7 0 1 1 1 1 1 4 1 1 5 1 1 3\n",
            " 1]\n"
          ]
        }
      ],
      "source": [
        "print(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owCd6ZlZzsQn",
        "outputId": "f7bab2a4-4461-4d17-db18-b697bb002c8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       145\n",
            "           1       0.71      0.90      0.80       545\n",
            "           2       0.57      0.59      0.58       128\n",
            "           3       0.47      0.44      0.46        36\n",
            "           4       0.00      0.00      0.00        82\n",
            "           5       1.00      0.05      0.10        20\n",
            "           6       0.00      0.00      0.00        17\n",
            "           7       0.00      0.00      0.00        15\n",
            "           8       1.00      0.20      0.33        10\n",
            "           9       0.00      0.00      0.00         2\n",
            "\n",
            "    accuracy                           0.71      1000\n",
            "   macro avg       0.46      0.30      0.31      1000\n",
            "weighted avg       0.63      0.71      0.65      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Compute predicted probabilities on the validation set\n",
        "y_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "print(len(y_val))\n",
        "print(len(y_pred))\n",
        "print(classification_report(y_val, torch.tensor(y_pred)))\n",
        "# Evaluate the Bert classifier\n",
        "#evaluate_roc(probs, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test tweets\n"
      ],
      "metadata": {
        "id": "Z5nF1KSq-xPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "f2FP4jlU-2DG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['text']=df_test['text'].apply(arabert_prep.preprocess)"
      ],
      "metadata": {
        "id": "BQHbAcx3Fupm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=df_test.text.values"
      ],
      "metadata": {
        "id": "o83u8hglFv2g"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs, test_masks = getIDs_attention(x_test)\n"
      ],
      "metadata": {
        "id": "3bmhBFD0FyDq"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the DataLoader for our test data\n",
        "test_data = TensorDataset(test_inputs, test_masks)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "PuugUZxyFzxp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels_cat = bert_predict(bert_classifier, test_dataloader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "xDUJ_dRFFyHi",
        "outputId": "421f6ddf-32e7-409a-e549-5ccdce83f58e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-5a04e6b4ccdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_labels_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels_cat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels=[]\n",
        "for label in test_labels_cat:\n",
        "  test_labels.append(label.item())\n"
      ],
      "metadata": {
        "id": "FYmASaY4IBuW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgMl7Y4hIbfp",
        "outputId": "34115091-b869-4cd0-eced-d688e0e107a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write the predicted data to a csv file\n",
        "d = {'category': test_labels}\n",
        "test_csv = pd.DataFrame(data=d, columns=['category'])\n",
        "test_csv.to_csv('result.csv')"
      ],
      "metadata": {
        "id": "MmC2SFY0JPxC"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "9faa27367d8809f17efa01381c296b23b33e7966403c8c5a88e68f02f779827d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f079b9aabfc54a2d9da91cbd6678361a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd4bbadd09e344bf90dc4567cc5f946b",
              "IPY_MODEL_fb48ef6671c74f67a34fcb3da094e1ce",
              "IPY_MODEL_2a09fc26549b4da6aa5b899e85d3826a"
            ],
            "layout": "IPY_MODEL_ee54ab8e42544feea77a8db4cd37109b"
          }
        },
        "bd4bbadd09e344bf90dc4567cc5f946b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a717385613f45f68abfd025c415f260",
            "placeholder": "​",
            "style": "IPY_MODEL_971c04d3f41049f38b5246fe86e31685",
            "value": "Downloading: 100%"
          }
        },
        "fb48ef6671c74f67a34fcb3da094e1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96cbd10ccc4a4bcdb4310a8b4cd6358e",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2310e92832a479ca6b5260fc4effb64",
            "value": 476
          }
        },
        "2a09fc26549b4da6aa5b899e85d3826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c4a73a02994a2d9084ce5fc14f4cb5",
            "placeholder": "​",
            "style": "IPY_MODEL_bb3b861b86b149c19c8c008115c80dcb",
            "value": " 476/476 [00:00&lt;00:00, 28.0kB/s]"
          }
        },
        "ee54ab8e42544feea77a8db4cd37109b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a717385613f45f68abfd025c415f260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971c04d3f41049f38b5246fe86e31685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96cbd10ccc4a4bcdb4310a8b4cd6358e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2310e92832a479ca6b5260fc4effb64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14c4a73a02994a2d9084ce5fc14f4cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3b861b86b149c19c8c008115c80dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a2cdf7da7e4cfdb15a075652ec9c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3267213023a473db8eff1828d75d7f4",
              "IPY_MODEL_2e19d525ee46449a86e2b1aa3675fd1e",
              "IPY_MODEL_80e9356ce9564699b08fc480006943a0"
            ],
            "layout": "IPY_MODEL_bd3695ad5bb8415d84b17a8edfe58972"
          }
        },
        "d3267213023a473db8eff1828d75d7f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92519dd8da544ba69746bb67419a9e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_e22af4577f0a4765908c8a49cf903941",
            "value": "Downloading: 100%"
          }
        },
        "2e19d525ee46449a86e2b1aa3675fd1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_526de3fc8c7746be8550b621593bafb5",
            "max": 750551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50784f07b76a442fa9cb1dba4b4bd38a",
            "value": 750551
          }
        },
        "80e9356ce9564699b08fc480006943a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c13c8f30ff804c1bbde787f3cf535ea9",
            "placeholder": "​",
            "style": "IPY_MODEL_2f8cc8213cf14d1db8f4505f11a59f13",
            "value": " 751k/751k [00:00&lt;00:00, 1.69MB/s]"
          }
        },
        "bd3695ad5bb8415d84b17a8edfe58972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92519dd8da544ba69746bb67419a9e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22af4577f0a4765908c8a49cf903941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "526de3fc8c7746be8550b621593bafb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50784f07b76a442fa9cb1dba4b4bd38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c13c8f30ff804c1bbde787f3cf535ea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f8cc8213cf14d1db8f4505f11a59f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36bc91f2005743d69a80e6157a4c99ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6958b56a1a74bb695bc7f110418345e",
              "IPY_MODEL_6c1925ede8d048f187a6f47a838cc1c1",
              "IPY_MODEL_1514e16d2ca641e1beb7c9aa65f1704e"
            ],
            "layout": "IPY_MODEL_8e23ff7692444784a3ddef5cecfa4e0c"
          }
        },
        "c6958b56a1a74bb695bc7f110418345e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_762eaf394f204e16a2c7df74cffba6e0",
            "placeholder": "​",
            "style": "IPY_MODEL_1d102db3656d4e19bbb8e3c8c4fabcc6",
            "value": "Downloading: 100%"
          }
        },
        "6c1925ede8d048f187a6f47a838cc1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_548b0dc0b8a948febd15dd7090a5223d",
            "max": 1252935,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2493dbb29eb46ef936c51b17670a038",
            "value": 1252935
          }
        },
        "1514e16d2ca641e1beb7c9aa65f1704e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c92ca1fdbc524c67b0240be94323b1bc",
            "placeholder": "​",
            "style": "IPY_MODEL_a041cfc0ab314db69628ec516d37c2f9",
            "value": " 1.25M/1.25M [00:00&lt;00:00, 1.73MB/s]"
          }
        },
        "8e23ff7692444784a3ddef5cecfa4e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762eaf394f204e16a2c7df74cffba6e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d102db3656d4e19bbb8e3c8c4fabcc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "548b0dc0b8a948febd15dd7090a5223d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2493dbb29eb46ef936c51b17670a038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c92ca1fdbc524c67b0240be94323b1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a041cfc0ab314db69628ec516d37c2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7deaed33b7cb48898579f1437f4a0b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3af3d0dc88b4fdd90a4c526f0ce5c3f",
              "IPY_MODEL_5e52bda9804b4b09bf5fed09d8569e6d",
              "IPY_MODEL_cf3844b6013046c7b0d60e7776d772d0"
            ],
            "layout": "IPY_MODEL_90e315649767403399a119010787f535"
          }
        },
        "d3af3d0dc88b4fdd90a4c526f0ce5c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8aa708713f94de0bf1d851b071693fa",
            "placeholder": "​",
            "style": "IPY_MODEL_590713f9bd6c438188fc683e4a5f102e",
            "value": "Downloading: 100%"
          }
        },
        "5e52bda9804b4b09bf5fed09d8569e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e07d2f64d5044c32bdc169e2446ecc56",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0d4e8b4672c4517ade72882d01ec701",
            "value": 112
          }
        },
        "cf3844b6013046c7b0d60e7776d772d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49fb78add5384e2d97c145e4ae108a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_6c183756eba64b64a998fc7642512199",
            "value": " 112/112 [00:00&lt;00:00, 3.70kB/s]"
          }
        },
        "90e315649767403399a119010787f535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8aa708713f94de0bf1d851b071693fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "590713f9bd6c438188fc683e4a5f102e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e07d2f64d5044c32bdc169e2446ecc56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d4e8b4672c4517ade72882d01ec701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49fb78add5384e2d97c145e4ae108a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c183756eba64b64a998fc7642512199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41613c3775c14759afda77ea40a6a49f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_348ee06b7fd04c61bf7795369bb321a5",
              "IPY_MODEL_49efc39a1c174bbcab499c4e16b641b0",
              "IPY_MODEL_2f8d65b5f46c42f2aeb8987433ad31f9"
            ],
            "layout": "IPY_MODEL_9180ff03abda4e6abd23a5bb86871558"
          }
        },
        "348ee06b7fd04c61bf7795369bb321a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25caea55340c438c80f5e11d1045ff22",
            "placeholder": "​",
            "style": "IPY_MODEL_fd8829e2ca6c4be191b585b112aa1d95",
            "value": "Downloading: 100%"
          }
        },
        "49efc39a1c174bbcab499c4e16b641b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd81c092c344c87b21b68772652be78",
            "max": 667,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc84ade92d7a4af1b3fa8e560126ba60",
            "value": 667
          }
        },
        "2f8d65b5f46c42f2aeb8987433ad31f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ec49ae08e945809ced977251eb11f8",
            "placeholder": "​",
            "style": "IPY_MODEL_c212e6bc07124fe18ffc681bb0bb983f",
            "value": " 667/667 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "9180ff03abda4e6abd23a5bb86871558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25caea55340c438c80f5e11d1045ff22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8829e2ca6c4be191b585b112aa1d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dd81c092c344c87b21b68772652be78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc84ade92d7a4af1b3fa8e560126ba60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77ec49ae08e945809ced977251eb11f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c212e6bc07124fe18ffc681bb0bb983f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f7ea3cbfe341be8ed5b0d72cae84bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9b5734445824bcc90022d271612101e",
              "IPY_MODEL_f1dc5989a1144ad19cdc217f6a222d0d",
              "IPY_MODEL_7291306e5462484ea96d0ced311d956e"
            ],
            "layout": "IPY_MODEL_143e04876dd8421c83b77a4166cf4061"
          }
        },
        "e9b5734445824bcc90022d271612101e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42e19a5ad21f47e4883c87f57f1d5615",
            "placeholder": "​",
            "style": "IPY_MODEL_162b1a48f8874230babd3e535e4592e2",
            "value": "Downloading: 100%"
          }
        },
        "f1dc5989a1144ad19cdc217f6a222d0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b70a53009a646768b9e0439093c0e17",
            "max": 541120363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d658798003b49969d2413e39be48ddb",
            "value": 541120363
          }
        },
        "7291306e5462484ea96d0ced311d956e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1cb80395f8c46f4951f04acbaefc041",
            "placeholder": "​",
            "style": "IPY_MODEL_59860533e65d4c48beb7ef06a8314393",
            "value": " 541M/541M [00:13&lt;00:00, 66.4MB/s]"
          }
        },
        "143e04876dd8421c83b77a4166cf4061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42e19a5ad21f47e4883c87f57f1d5615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "162b1a48f8874230babd3e535e4592e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b70a53009a646768b9e0439093c0e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d658798003b49969d2413e39be48ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d1cb80395f8c46f4951f04acbaefc041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59860533e65d4c48beb7ef06a8314393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}