{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTdhD3kWthvg",
        "outputId": "9545bcc2-7b85-40e3-bc3c-2d299834cc03"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/dell/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install farasapy\n",
        "!pip install pyarabic\n",
        "!pip install arabert\n",
        "!git clone https://github.com/aub-mind/arabert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T_XUVZViLLr",
        "outputId": "7a69a1de-e47a-4691-bd91-4e1ca1786935"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/dell/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "!pip install emoji "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00tImzUPcdAQ"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/dell/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O3gA8JUWGPw",
        "outputId": "d9518bd6-1eb2-4a62-ca8b-f86e6d66f5e3"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/dell/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrfhcS-cWGTH"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38\\python.exe' requires ipykernel package.\n",
            "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/dell/AppData/Local/Programs/Python/Python38/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
        "hidden_state_size=50 # size of hidden layer in the classification layer above bert\n",
        "n_classes= 3 # 3 for stance,make it 10 for cat\n",
        "class_name=\"stance\" # change to \"category\" for category classification"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# loading and preprocessing train and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ocy6RcQQbpwY"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_TmsWIbdrC4f"
      },
      "outputs": [],
      "source": [
        "# preprocess the train data using bert preprocessor\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name, keep_emojis=True)\n",
        "df_train['text']=df_train['text'].apply(arabert_prep.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5-qZJtQXrC4h"
      },
      "outputs": [],
      "source": [
        "#extract unique labels\n",
        "possible_labels = df_train.stance.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FfRa2NcErC4j"
      },
      "outputs": [],
      "source": [
        "# map possible labels to +ve numbers from 0 to n_classes-1\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JRnHapMvrC4l"
      },
      "outputs": [],
      "source": [
        "# update with the new labels\n",
        "df_train.stance = df_train['stance'].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HF1Y4rwtc7UR",
        "outputId": "6675c400-177b-44f6-ada8-00a1fc05fbf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6988\n",
            "6988\n"
          ]
        }
      ],
      "source": [
        "#store train tweets and labels in lists\n",
        "y_train=df_train.stance.values\n",
        "x_train=df_train.text.values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " # Repeat the previous steps for the validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "30hKqG6_bpyv"
      },
      "outputs": [],
      "source": [
        "df_val = pd.read_csv(\"dev.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B7ZI1BsOrC4n"
      },
      "outputs": [],
      "source": [
        "arabert_prep = ArabertPreprocessor(model_name=model_name, keep_emojis=True)\n",
        "df_val['text']=df_val['text'].apply(arabert_prep.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1h7jqt3RrC4p"
      },
      "outputs": [],
      "source": [
        "df_val.stance = df_val['stance'].map(label_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpr6gqOJdKau",
        "outputId": "2eb7469f-3959-4848-e72a-0440a605caf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "y_val=df_val.stance.values\n",
        "x_val=df_val.text.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yxtfcoo0fqOk"
      },
      "source": [
        "# BERT CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFA0bbFfeVd7",
        "outputId": "b681528a-9650-4d13-8f49-c749de263810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 32.6 ms, sys: 5.55 ms, total: 38.2 ms\n",
            "Wall time: 38.8 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "# Create the BertClassfier class\n",
        "class BertClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self, freeze_bert=False):\n",
        "        \"\"\"\n",
        "        input parameters\n",
        "        bert: a BertModel object\n",
        "        classifier: NN classifier layer above bert\n",
        "        freeze_bert: boolean we make it false for bert fine tunig\n",
        "        \"\"\"\n",
        "        super(BertClassifier, self).__init__()\n",
        "        \n",
        "        # Instantiate BERT model\n",
        "        self.bert = AutoModel.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\n",
        "        # Instantiate an one-layer feed-forward classifier\n",
        "        #----------- classifier ---------\n",
        "        \"\"\" \n",
        "        this layer make it more complex to be able to behave better inshallah\n",
        "        first NN linear layer take 768 bert's output and outs hidden state with size 50\n",
        "        we can change this size but it was recommended to use it as 50,\n",
        "        the 2 layers RELU AND dropout \n",
        "        then another linear layer take the hidden and out the classes \n",
        "        \"\"\"\n",
        "        self.classifier = nn.Sequential(\n",
        "\n",
        "            nn.Linear(768,hidden_state_size),    \n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_state_size, n_classes) # no of classes\n",
        "        )\n",
        "\n",
        "        # Freeze bert model to enable fine tuning and let the model train on our own data\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        \"\"\"\n",
        "        Feed input to BERT and the classifier to compute predicted probabilities.\n",
        "        input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
        "                      max_length)\n",
        "        attention_mask (torch.Tensor):\n",
        "         a tensor that hold attention mask(pay attention to the most important part in the input)\n",
        "                      information with shape (batch_size, max_length)\n",
        "        \n",
        "        \"\"\"\n",
        "          # Feed input to BERT\n",
        "        outputs = self.bert(input_ids=input_ids,attention_mask=attention_mask)\n",
        "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "        # feed el hidden layer embedding to the classifier layer\n",
        "        probs = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkYqh_rjCyR"
      },
      "source": [
        "# get input IDs and attention masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "803e0980e3cf48019a33524ab04ce72d",
            "0f2fd11677724521bfae79841b0cd5a8",
            "ad5d5a05d25748858ff82c095e57a366",
            "d9b8a1b95e0b4c548c66aa75a7a58e57",
            "0560405ca5bb4571a0e7e508ceb60496",
            "f4ea8f437a554a08b7afd377fb39854e",
            "59ca243745434cd2a24485e7e18266e3",
            "982480b2b99245a5a15f2c26a7455fc7",
            "90edcd2e5e04455ba222bb8b77846349",
            "21646e539e8841deb4b21631b247bbea",
            "9900668ed88447f083b9a1ccb933e66c",
            "4b0bd402226b4bc7b6a51324517d33f3",
            "ed3c0fa17f65471ca182870f710e7811",
            "6ecc434cd0604f7986dae5f43c1da376",
            "0de5730fdcb04a2c962abf24e92cb4fa",
            "25c50b8223bf4fbe93f453f259f730d8",
            "3085d3424f844e3194bc100d81feefc7",
            "e89c49aec343420aa1bdff1b7065a1fb",
            "8ecbd51eb8304976af184e8ac8ef3697",
            "a85fcbbe287440919b8834f9c77a732b",
            "8330857c282e4bbbb6a11b8b1e8590ee",
            "4c4a64b2784e4423aa995d6a0185d2b9",
            "06afe73454a04b87be068657a0067749",
            "62206b68273d4eef95c2774f7bd63fda",
            "bdfbfe35081f41abb5caa2e994b3cce3",
            "234d3ff337454c90bb7e9742b2b72acc",
            "632696886b84470385573eb30968fc1d",
            "78b32fbb52064f18b0bbeaa679db938d",
            "73ec13590f074ae195f0b07a731599c4",
            "72ac41a26c4b4610b59a5249c58d4acd",
            "83f3aa85266447ea913e5fa96841e41c",
            "7f57d98d6ee840f39c59ba761da241c0",
            "66d06402a9bd413eac6c8a96e283a273",
            "a26dc14bebc54314b8933ea711912e7a",
            "c94555a6ffa64c438d7f3d4a4344800e",
            "ef105f1a3fb7470ea12919354069187d",
            "8a1f37347f0c47dd922f551b7d788023",
            "fe4be541ae1a49d1bd32fbe5a7861008",
            "930492ac97c34d05b69fe2800dc147c6",
            "9bb3dacbff7349ec922bdcac165461e1",
            "37a1720c0c32405c9e88ed6c822eeb94",
            "89257b2f51f4422e857c830d99c02c89",
            "e03ba9dfb0534c379b1088a4c6a8090b",
            "c5eda33b3fed46d394871d5942eb1c43"
          ]
        },
        "id": "yaC23SBDjP5_",
        "outputId": "1a097f79-407f-4124-9592-bc7ff6d6b67b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "803e0980e3cf48019a33524ab04ce72d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/476 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b0bd402226b4bc7b6a51324517d33f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/751k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06afe73454a04b87be068657a0067749",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.25M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a26dc14bebc54314b8933ea711912e7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# download tokenizer of the model to use it to extarct ids and attention masks of data\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "VtYaJAnOjGeN"
      },
      "outputs": [],
      "source": [
        "def getIDs_attention(data):\n",
        " \n",
        "  IDs = [] #store ids here\n",
        "  attenMasks = [] # store attention masks here\n",
        "  #tokenizer = AutoTokenizer.from_pretrained(model_name) if version == \"mini\" else AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "\n",
        "  # loop on all tweets\n",
        "  for i,sent in enumerate(data):\n",
        "      # `encode_plus` will do the follwoing:\n",
        "      #    Tokenize the sentence\n",
        "      #    Pad sentence to max length\n",
        "      #    Map tokens to their IDs\n",
        "      #    Create attention mask\n",
        "      #    Return a dictionary of outputs\n",
        "      encoded_sent = tokenizer.encode_plus(\n",
        "          text=sent,  # Preprocess sentence\n",
        "          add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
        "          max_length=64,                  # Max length to truncate/pad\n",
        "          padding='max_length',        # Pad sentence to max length  ( recommended 64)\n",
        "          return_attention_mask=True,     # Return attention mask\n",
        "          truncation = True \n",
        "          )\n",
        "      \n",
        "      # add ids of the tweet in the IDs list\n",
        "      IDs.append(encoded_sent.get('input_ids'))\n",
        "      # add attention masks of the tweet in the IDs list\n",
        "      attenMasks.append(encoded_sent.get('attention_mask'))\n",
        "    # make the lists tensors\n",
        "  IDs = torch.tensor(IDs)\n",
        "  attenMasks = torch.tensor(attenMasks)\n",
        "\n",
        "  return IDs, attenMasks\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "7_er5ccMk8Dy"
      },
      "outputs": [],
      "source": [
        "# get ids and mask attentions for train and val data to feed them to the model\n",
        "train_inputs, train_masks = getIDs_attention(x_train)\n",
        "val_inputs, val_masks = getIDs_attention(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbrlme8otxFX",
        "outputId": "88fb803c-635c-4580-ee50-c5b0606c358d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6988\n",
            "6988\n",
            "6988\n",
            "6988\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#convert labels to torch.Tensor\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "\"\"\"\n",
        "use ids and attention masks to create dataLoader for training \n",
        "and validation sets\n",
        "\"\"\"\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sldCHNGLn03M"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QdLWTC-cnxLH"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.optim import SparseAdam, Adam\n",
        "def initialize_model(epochs=4, version=\"mini\"):\n",
        "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "    \"\"\"\n",
        "    # Instantiate Bert Classifier\n",
        "    bert_classifier = BertClassifier(freeze_bert=True)\n",
        "    # Tell PyTorch to run the model on GPU\n",
        "    bert_classifier.to(device)\n",
        "\n",
        "    # optimizer that will perform back propagation and compute loss\n",
        "    optimizer = AdamW(params=list(bert_classifier.parameters()),\n",
        "                      lr=0.001,    # learning rate\n",
        "                      eps=1e-8    # Default epsilon value\n",
        "                      )\n",
        "\n",
        "    # Total number of training steps\n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    #Set up the learning rate scheduler\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps=0, # Default value\n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer ,scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6sAt0AZKnxND"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "# use loss entropy as our loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(model, optimizer,scheduler,train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "   \n",
        "    # training loop\n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "        # Print the header of the result table\n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        # Measure the elapsed time of each epoch\n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        # Reset tracking variables at the beginning of each epoch\n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        # For each batch of training data...\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)            \n",
        "\n",
        "            # feed ids and attention mash to the model\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.zero_grad()\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            # Update parameters and the learning rate\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            \n",
        "            # Print the loss values and time elapsed for every 20 batches\n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "                # Calculate time elapsed for 20 batches\n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                # Print training results\n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                # Reset batch tracking variables\n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "      \n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "       \n",
        "    print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv7jR_kqogkx"
      },
      "source": [
        "# Initialize and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqLTHlKVuBMr",
        "outputId": "b878d6bc-d363-4e22-dd25-d1775684c8c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at aubmindlab/bert-base-arabertv02-twitter were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at aubmindlab/bert-base-arabertv02-twitter and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.739872   |     -      |     -     |   1.26   \n",
            "   1    |   40    |   0.582242   |     -      |     -     |   1.17   \n",
            "   1    |   60    |   0.567579   |     -      |     -     |   1.19   \n",
            "   1    |   80    |   0.490767   |     -      |     -     |   1.19   \n",
            "   1    |   100   |   0.529208   |     -      |     -     |   1.19   \n",
            "   1    |   120   |   0.454230   |     -      |     -     |   1.20   \n",
            "   1    |   140   |   0.491373   |     -      |     -     |   1.22   \n",
            "   1    |   160   |   0.544625   |     -      |     -     |   1.22   \n",
            "   1    |   180   |   0.534463   |     -      |     -     |   1.22   \n",
            "   1    |   200   |   0.533159   |     -      |     -     |   1.22   \n",
            "   1    |   220   |   0.509320   |     -      |     -     |   1.22   \n",
            "   1    |   240   |   0.431907   |     -      |     -     |   1.22   \n",
            "   1    |   260   |   0.461056   |     -      |     -     |   1.22   \n",
            "   1    |   280   |   0.466899   |     -      |     -     |   1.22   \n",
            "   1    |   300   |   0.499152   |     -      |     -     |   1.22   \n",
            "   1    |   320   |   0.479123   |     -      |     -     |   1.22   \n",
            "   1    |   340   |   0.474264   |     -      |     -     |   1.22   \n",
            "   1    |   360   |   0.411530   |     -      |     -     |   1.23   \n",
            "   1    |   380   |   0.511557   |     -      |     -     |   1.23   \n",
            "   1    |   400   |   0.463198   |     -      |     -     |   1.24   \n",
            "   1    |   420   |   0.509430   |     -      |     -     |   1.25   \n",
            "   1    |   436   |   0.464604   |     -      |     -     |   0.99   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.507718   |  0.444746  |   81.65   |   30.51  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.507595   |     -      |     -     |   1.33   \n",
            "   2    |   40    |   0.500711   |     -      |     -     |   1.27   \n",
            "   2    |   60    |   0.527425   |     -      |     -     |   1.29   \n",
            "   2    |   80    |   0.437899   |     -      |     -     |   1.28   \n",
            "   2    |   100   |   0.456504   |     -      |     -     |   1.28   \n",
            "   2    |   120   |   0.449744   |     -      |     -     |   1.26   \n",
            "   2    |   140   |   0.437209   |     -      |     -     |   1.26   \n",
            "   2    |   160   |   0.509796   |     -      |     -     |   1.25   \n",
            "   2    |   180   |   0.490032   |     -      |     -     |   1.22   \n",
            "   2    |   200   |   0.496428   |     -      |     -     |   1.22   \n",
            "   2    |   220   |   0.485409   |     -      |     -     |   1.22   \n",
            "   2    |   240   |   0.404353   |     -      |     -     |   1.22   \n",
            "   2    |   260   |   0.434632   |     -      |     -     |   1.22   \n",
            "   2    |   280   |   0.486535   |     -      |     -     |   1.22   \n",
            "   2    |   300   |   0.492171   |     -      |     -     |   1.22   \n",
            "   2    |   320   |   0.476425   |     -      |     -     |   1.22   \n",
            "   2    |   340   |   0.454085   |     -      |     -     |   1.22   \n",
            "   2    |   360   |   0.388395   |     -      |     -     |   1.22   \n",
            "   2    |   380   |   0.480715   |     -      |     -     |   1.22   \n",
            "   2    |   400   |   0.396692   |     -      |     -     |   1.22   \n",
            "   2    |   420   |   0.528393   |     -      |     -     |   1.22   \n",
            "   2    |   436   |   0.395772   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.466048   |  0.474921  |   81.05   |   30.72  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   3    |   20    |   0.524168   |     -      |     -     |   1.27   \n",
            "   3    |   40    |   0.489519   |     -      |     -     |   1.22   \n",
            "   3    |   60    |   0.509646   |     -      |     -     |   1.20   \n",
            "   3    |   80    |   0.434886   |     -      |     -     |   1.21   \n",
            "   3    |   100   |   0.461192   |     -      |     -     |   1.20   \n",
            "   3    |   120   |   0.402267   |     -      |     -     |   1.20   \n",
            "   3    |   140   |   0.405118   |     -      |     -     |   1.18   \n",
            "   3    |   160   |   0.512665   |     -      |     -     |   1.20   \n",
            "   3    |   180   |   0.489165   |     -      |     -     |   1.20   \n",
            "   3    |   200   |   0.454417   |     -      |     -     |   1.18   \n",
            "   3    |   220   |   0.455126   |     -      |     -     |   1.19   \n",
            "   3    |   240   |   0.410043   |     -      |     -     |   1.20   \n",
            "   3    |   260   |   0.431466   |     -      |     -     |   1.18   \n",
            "   3    |   280   |   0.432077   |     -      |     -     |   1.19   \n",
            "   3    |   300   |   0.503517   |     -      |     -     |   1.18   \n",
            "   3    |   320   |   0.453370   |     -      |     -     |   1.19   \n",
            "   3    |   340   |   0.451401   |     -      |     -     |   1.19   \n",
            "   3    |   360   |   0.377932   |     -      |     -     |   1.19   \n",
            "   3    |   380   |   0.476234   |     -      |     -     |   1.21   \n",
            "   3    |   400   |   0.418773   |     -      |     -     |   1.20   \n",
            "   3    |   420   |   0.509974   |     -      |     -     |   1.20   \n",
            "   3    |   436   |   0.433775   |     -      |     -     |   0.95   \n",
            "----------------------------------------------------------------------\n",
            "   3    |    -    |   0.456576   |  0.430582  |   82.04   |   29.81  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   4    |   20    |   0.496618   |     -      |     -     |   1.27   \n",
            "   4    |   40    |   0.465525   |     -      |     -     |   1.22   \n",
            "   4    |   60    |   0.508844   |     -      |     -     |   1.22   \n",
            "   4    |   80    |   0.436938   |     -      |     -     |   1.22   \n",
            "   4    |   100   |   0.450048   |     -      |     -     |   1.22   \n",
            "   4    |   120   |   0.407071   |     -      |     -     |   1.22   \n",
            "   4    |   140   |   0.407175   |     -      |     -     |   1.22   \n",
            "   4    |   160   |   0.483644   |     -      |     -     |   1.22   \n",
            "   4    |   180   |   0.496576   |     -      |     -     |   1.22   \n",
            "   4    |   200   |   0.471106   |     -      |     -     |   1.22   \n",
            "   4    |   220   |   0.435150   |     -      |     -     |   1.22   \n",
            "   4    |   240   |   0.402272   |     -      |     -     |   1.22   \n",
            "   4    |   260   |   0.406778   |     -      |     -     |   1.22   \n",
            "   4    |   280   |   0.448584   |     -      |     -     |   1.22   \n",
            "   4    |   300   |   0.467069   |     -      |     -     |   1.22   \n",
            "   4    |   320   |   0.424948   |     -      |     -     |   1.22   \n",
            "   4    |   340   |   0.444457   |     -      |     -     |   1.22   \n",
            "   4    |   360   |   0.363685   |     -      |     -     |   1.22   \n",
            "   4    |   380   |   0.490736   |     -      |     -     |   1.22   \n",
            "   4    |   400   |   0.402024   |     -      |     -     |   1.22   \n",
            "   4    |   420   |   0.503577   |     -      |     -     |   1.22   \n",
            "   4    |   436   |   0.396429   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   4    |    -    |   0.446444   |  0.432720  |   81.94   |   30.43  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   5    |   20    |   0.464578   |     -      |     -     |   1.27   \n",
            "   5    |   40    |   0.454596   |     -      |     -     |   1.22   \n",
            "   5    |   60    |   0.515043   |     -      |     -     |   1.22   \n",
            "   5    |   80    |   0.428418   |     -      |     -     |   1.22   \n",
            "   5    |   100   |   0.455638   |     -      |     -     |   1.22   \n",
            "   5    |   120   |   0.381754   |     -      |     -     |   1.22   \n",
            "   5    |   140   |   0.391193   |     -      |     -     |   1.22   \n",
            "   5    |   160   |   0.476068   |     -      |     -     |   1.22   \n",
            "   5    |   180   |   0.453434   |     -      |     -     |   1.22   \n",
            "   5    |   200   |   0.447066   |     -      |     -     |   1.22   \n",
            "   5    |   220   |   0.420478   |     -      |     -     |   1.22   \n",
            "   5    |   240   |   0.364773   |     -      |     -     |   1.22   \n",
            "   5    |   260   |   0.384452   |     -      |     -     |   1.22   \n",
            "   5    |   280   |   0.426541   |     -      |     -     |   1.22   \n",
            "   5    |   300   |   0.441185   |     -      |     -     |   1.22   \n",
            "   5    |   320   |   0.485586   |     -      |     -     |   1.22   \n",
            "   5    |   340   |   0.427758   |     -      |     -     |   1.22   \n",
            "   5    |   360   |   0.358816   |     -      |     -     |   1.22   \n",
            "   5    |   380   |   0.445583   |     -      |     -     |   1.22   \n",
            "   5    |   400   |   0.384363   |     -      |     -     |   1.22   \n",
            "   5    |   420   |   0.500736   |     -      |     -     |   1.22   \n",
            "   5    |   436   |   0.411817   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   5    |    -    |   0.432986   |  0.427896  |   82.44   |   30.35  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   6    |   20    |   0.459083   |     -      |     -     |   1.28   \n",
            "   6    |   40    |   0.451317   |     -      |     -     |   1.22   \n",
            "   6    |   60    |   0.486532   |     -      |     -     |   1.22   \n",
            "   6    |   80    |   0.410184   |     -      |     -     |   1.22   \n",
            "   6    |   100   |   0.431472   |     -      |     -     |   1.22   \n",
            "   6    |   120   |   0.405263   |     -      |     -     |   1.22   \n",
            "   6    |   140   |   0.370072   |     -      |     -     |   1.22   \n",
            "   6    |   160   |   0.466791   |     -      |     -     |   1.22   \n",
            "   6    |   180   |   0.440955   |     -      |     -     |   1.22   \n",
            "   6    |   200   |   0.467861   |     -      |     -     |   1.22   \n",
            "   6    |   220   |   0.428585   |     -      |     -     |   1.22   \n",
            "   6    |   240   |   0.375669   |     -      |     -     |   1.22   \n",
            "   6    |   260   |   0.385246   |     -      |     -     |   1.22   \n",
            "   6    |   280   |   0.440152   |     -      |     -     |   1.22   \n",
            "   6    |   300   |   0.453841   |     -      |     -     |   1.22   \n",
            "   6    |   320   |   0.432133   |     -      |     -     |   1.22   \n",
            "   6    |   340   |   0.409428   |     -      |     -     |   1.22   \n",
            "   6    |   360   |   0.344550   |     -      |     -     |   1.22   \n",
            "   6    |   380   |   0.465216   |     -      |     -     |   1.22   \n",
            "   6    |   400   |   0.373476   |     -      |     -     |   1.22   \n",
            "   6    |   420   |   0.480418   |     -      |     -     |   1.22   \n",
            "   6    |   436   |   0.378913   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   6    |    -    |   0.425827   |  0.433577  |   82.34   |   30.39  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   7    |   20    |   0.403270   |     -      |     -     |   1.28   \n",
            "   7    |   40    |   0.463436   |     -      |     -     |   1.22   \n",
            "   7    |   60    |   0.475652   |     -      |     -     |   1.22   \n",
            "   7    |   80    |   0.445780   |     -      |     -     |   1.22   \n",
            "   7    |   100   |   0.464055   |     -      |     -     |   1.22   \n",
            "   7    |   120   |   0.366342   |     -      |     -     |   1.22   \n",
            "   7    |   140   |   0.364634   |     -      |     -     |   1.22   \n",
            "   7    |   160   |   0.444697   |     -      |     -     |   1.22   \n",
            "   7    |   180   |   0.454456   |     -      |     -     |   1.22   \n",
            "   7    |   200   |   0.417310   |     -      |     -     |   1.22   \n",
            "   7    |   220   |   0.400662   |     -      |     -     |   1.22   \n",
            "   7    |   240   |   0.387103   |     -      |     -     |   1.22   \n",
            "   7    |   260   |   0.366451   |     -      |     -     |   1.22   \n",
            "   7    |   280   |   0.450302   |     -      |     -     |   1.22   \n",
            "   7    |   300   |   0.424061   |     -      |     -     |   1.22   \n",
            "   7    |   320   |   0.410383   |     -      |     -     |   1.22   \n",
            "   7    |   340   |   0.407152   |     -      |     -     |   1.22   \n",
            "   7    |   360   |   0.347551   |     -      |     -     |   1.22   \n",
            "   7    |   380   |   0.444210   |     -      |     -     |   1.22   \n",
            "   7    |   400   |   0.351134   |     -      |     -     |   1.22   \n",
            "   7    |   420   |   0.476058   |     -      |     -     |   1.22   \n",
            "   7    |   436   |   0.396019   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   7    |    -    |   0.416553   |  0.433917  |   82.64   |   30.39  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   8    |   20    |   0.417813   |     -      |     -     |   1.29   \n",
            "   8    |   40    |   0.441757   |     -      |     -     |   1.22   \n",
            "   8    |   60    |   0.517435   |     -      |     -     |   1.22   \n",
            "   8    |   80    |   0.445521   |     -      |     -     |   1.22   \n",
            "   8    |   100   |   0.419587   |     -      |     -     |   1.22   \n",
            "   8    |   120   |   0.390146   |     -      |     -     |   1.22   \n",
            "   8    |   140   |   0.358620   |     -      |     -     |   1.22   \n",
            "   8    |   160   |   0.466189   |     -      |     -     |   1.22   \n",
            "   8    |   180   |   0.452371   |     -      |     -     |   1.22   \n",
            "   8    |   200   |   0.485536   |     -      |     -     |   1.22   \n",
            "   8    |   220   |   0.402534   |     -      |     -     |   1.22   \n",
            "   8    |   240   |   0.344331   |     -      |     -     |   1.22   \n",
            "   8    |   260   |   0.394792   |     -      |     -     |   1.22   \n",
            "   8    |   280   |   0.437081   |     -      |     -     |   1.22   \n",
            "   8    |   300   |   0.412824   |     -      |     -     |   1.22   \n",
            "   8    |   320   |   0.430909   |     -      |     -     |   1.22   \n",
            "   8    |   340   |   0.439606   |     -      |     -     |   1.22   \n",
            "   8    |   360   |   0.343582   |     -      |     -     |   1.23   \n",
            "   8    |   380   |   0.422884   |     -      |     -     |   1.22   \n",
            "   8    |   400   |   0.351849   |     -      |     -     |   1.22   \n",
            "   8    |   420   |   0.481841   |     -      |     -     |   1.22   \n",
            "   8    |   436   |   0.412035   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   8    |    -    |   0.421406   |  0.431278  |   82.64   |   30.40  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   9    |   20    |   0.423122   |     -      |     -     |   1.27   \n",
            "   9    |   40    |   0.458184   |     -      |     -     |   1.22   \n",
            "   9    |   60    |   0.503151   |     -      |     -     |   1.22   \n",
            "   9    |   80    |   0.421057   |     -      |     -     |   1.22   \n",
            "   9    |   100   |   0.435354   |     -      |     -     |   1.22   \n",
            "   9    |   120   |   0.373755   |     -      |     -     |   1.22   \n",
            "   9    |   140   |   0.362610   |     -      |     -     |   1.22   \n",
            "   9    |   160   |   0.456425   |     -      |     -     |   1.22   \n",
            "   9    |   180   |   0.447635   |     -      |     -     |   1.22   \n",
            "   9    |   200   |   0.449322   |     -      |     -     |   1.22   \n",
            "   9    |   220   |   0.409621   |     -      |     -     |   1.22   \n",
            "   9    |   240   |   0.378493   |     -      |     -     |   1.22   \n",
            "   9    |   260   |   0.397499   |     -      |     -     |   1.22   \n",
            "   9    |   280   |   0.426591   |     -      |     -     |   1.22   \n",
            "   9    |   300   |   0.449382   |     -      |     -     |   1.22   \n",
            "   9    |   320   |   0.415257   |     -      |     -     |   1.22   \n",
            "   9    |   340   |   0.386116   |     -      |     -     |   1.22   \n",
            "   9    |   360   |   0.310419   |     -      |     -     |   1.22   \n",
            "   9    |   380   |   0.443834   |     -      |     -     |   1.22   \n",
            "   9    |   400   |   0.329852   |     -      |     -     |   1.22   \n",
            "   9    |   420   |   0.437953   |     -      |     -     |   1.22   \n",
            "   9    |   436   |   0.365292   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "   9    |    -    |   0.413228   |  0.437717  |   82.44   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  10    |   20    |   0.419862   |     -      |     -     |   1.28   \n",
            "  10    |   40    |   0.405089   |     -      |     -     |   1.22   \n",
            "  10    |   60    |   0.490435   |     -      |     -     |   1.22   \n",
            "  10    |   80    |   0.401125   |     -      |     -     |   1.22   \n",
            "  10    |   100   |   0.402043   |     -      |     -     |   1.22   \n",
            "  10    |   120   |   0.391232   |     -      |     -     |   1.22   \n",
            "  10    |   140   |   0.347177   |     -      |     -     |   1.22   \n",
            "  10    |   160   |   0.466986   |     -      |     -     |   1.22   \n",
            "  10    |   180   |   0.436648   |     -      |     -     |   1.22   \n",
            "  10    |   200   |   0.468175   |     -      |     -     |   1.22   \n",
            "  10    |   220   |   0.387350   |     -      |     -     |   1.22   \n",
            "  10    |   240   |   0.325357   |     -      |     -     |   1.22   \n",
            "  10    |   260   |   0.383707   |     -      |     -     |   1.22   \n",
            "  10    |   280   |   0.514425   |     -      |     -     |   1.22   \n",
            "  10    |   300   |   0.402113   |     -      |     -     |   1.22   \n",
            "  10    |   320   |   0.415425   |     -      |     -     |   1.22   \n",
            "  10    |   340   |   0.391417   |     -      |     -     |   1.22   \n",
            "  10    |   360   |   0.320577   |     -      |     -     |   1.22   \n",
            "  10    |   380   |   0.375082   |     -      |     -     |   1.22   \n",
            "  10    |   400   |   0.389608   |     -      |     -     |   1.22   \n",
            "  10    |   420   |   0.480825   |     -      |     -     |   1.22   \n",
            "  10    |   436   |   0.396504   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  10    |    -    |   0.409742   |  0.427502  |   82.34   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  11    |   20    |   0.411376   |     -      |     -     |   1.28   \n",
            "  11    |   40    |   0.426697   |     -      |     -     |   1.22   \n",
            "  11    |   60    |   0.476623   |     -      |     -     |   1.22   \n",
            "  11    |   80    |   0.378795   |     -      |     -     |   1.22   \n",
            "  11    |   100   |   0.431632   |     -      |     -     |   1.22   \n",
            "  11    |   120   |   0.372204   |     -      |     -     |   1.22   \n",
            "  11    |   140   |   0.328729   |     -      |     -     |   1.22   \n",
            "  11    |   160   |   0.491475   |     -      |     -     |   1.22   \n",
            "  11    |   180   |   0.433735   |     -      |     -     |   1.22   \n",
            "  11    |   200   |   0.440816   |     -      |     -     |   1.22   \n",
            "  11    |   220   |   0.410945   |     -      |     -     |   1.22   \n",
            "  11    |   240   |   0.359024   |     -      |     -     |   1.22   \n",
            "  11    |   260   |   0.378830   |     -      |     -     |   1.22   \n",
            "  11    |   280   |   0.438410   |     -      |     -     |   1.22   \n",
            "  11    |   300   |   0.436883   |     -      |     -     |   1.22   \n",
            "  11    |   320   |   0.411434   |     -      |     -     |   1.22   \n",
            "  11    |   340   |   0.387153   |     -      |     -     |   1.22   \n",
            "  11    |   360   |   0.342892   |     -      |     -     |   1.22   \n",
            "  11    |   380   |   0.404290   |     -      |     -     |   1.22   \n",
            "  11    |   400   |   0.358699   |     -      |     -     |   1.22   \n",
            "  11    |   420   |   0.469914   |     -      |     -     |   1.22   \n",
            "  11    |   436   |   0.389923   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  11    |    -    |   0.408378   |  0.422902  |   83.04   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  12    |   20    |   0.389254   |     -      |     -     |   1.28   \n",
            "  12    |   40    |   0.451929   |     -      |     -     |   1.22   \n",
            "  12    |   60    |   0.460709   |     -      |     -     |   1.22   \n",
            "  12    |   80    |   0.407381   |     -      |     -     |   1.22   \n",
            "  12    |   100   |   0.423546   |     -      |     -     |   1.22   \n",
            "  12    |   120   |   0.355298   |     -      |     -     |   1.22   \n",
            "  12    |   140   |   0.350066   |     -      |     -     |   1.22   \n",
            "  12    |   160   |   0.440720   |     -      |     -     |   1.22   \n",
            "  12    |   180   |   0.397377   |     -      |     -     |   1.22   \n",
            "  12    |   200   |   0.392926   |     -      |     -     |   1.22   \n",
            "  12    |   220   |   0.374715   |     -      |     -     |   1.22   \n",
            "  12    |   240   |   0.383069   |     -      |     -     |   1.22   \n",
            "  12    |   260   |   0.333162   |     -      |     -     |   1.22   \n",
            "  12    |   280   |   0.476650   |     -      |     -     |   1.22   \n",
            "  12    |   300   |   0.423862   |     -      |     -     |   1.22   \n",
            "  12    |   320   |   0.402207   |     -      |     -     |   1.22   \n",
            "  12    |   340   |   0.393921   |     -      |     -     |   1.22   \n",
            "  12    |   360   |   0.332946   |     -      |     -     |   1.22   \n",
            "  12    |   380   |   0.398519   |     -      |     -     |   1.22   \n",
            "  12    |   400   |   0.375579   |     -      |     -     |   1.22   \n",
            "  12    |   420   |   0.464311   |     -      |     -     |   1.22   \n",
            "  12    |   436   |   0.368460   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  12    |    -    |   0.400109   |  0.434888  |   82.94   |   30.35  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  13    |   20    |   0.390165   |     -      |     -     |   1.27   \n",
            "  13    |   40    |   0.415177   |     -      |     -     |   1.22   \n",
            "  13    |   60    |   0.451958   |     -      |     -     |   1.22   \n",
            "  13    |   80    |   0.413433   |     -      |     -     |   1.22   \n",
            "  13    |   100   |   0.401268   |     -      |     -     |   1.22   \n",
            "  13    |   120   |   0.370396   |     -      |     -     |   1.22   \n",
            "  13    |   140   |   0.338406   |     -      |     -     |   1.22   \n",
            "  13    |   160   |   0.467409   |     -      |     -     |   1.22   \n",
            "  13    |   180   |   0.424278   |     -      |     -     |   1.22   \n",
            "  13    |   200   |   0.389148   |     -      |     -     |   1.22   \n",
            "  13    |   220   |   0.385028   |     -      |     -     |   1.22   \n",
            "  13    |   240   |   0.360464   |     -      |     -     |   1.22   \n",
            "  13    |   260   |   0.368962   |     -      |     -     |   1.22   \n",
            "  13    |   280   |   0.409168   |     -      |     -     |   1.22   \n",
            "  13    |   300   |   0.444551   |     -      |     -     |   1.22   \n",
            "  13    |   320   |   0.413614   |     -      |     -     |   1.22   \n",
            "  13    |   340   |   0.389968   |     -      |     -     |   1.22   \n",
            "  13    |   360   |   0.338573   |     -      |     -     |   1.22   \n",
            "  13    |   380   |   0.376589   |     -      |     -     |   1.22   \n",
            "  13    |   400   |   0.364939   |     -      |     -     |   1.22   \n",
            "  13    |   420   |   0.479136   |     -      |     -     |   1.22   \n",
            "  13    |   436   |   0.360355   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  13    |    -    |   0.398189   |  0.447428  |   82.54   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  14    |   20    |   0.418675   |     -      |     -     |   1.29   \n",
            "  14    |   40    |   0.416046   |     -      |     -     |   1.22   \n",
            "  14    |   60    |   0.500441   |     -      |     -     |   1.22   \n",
            "  14    |   80    |   0.423451   |     -      |     -     |   1.22   \n",
            "  14    |   100   |   0.402170   |     -      |     -     |   1.22   \n",
            "  14    |   120   |   0.375802   |     -      |     -     |   1.22   \n",
            "  14    |   140   |   0.327570   |     -      |     -     |   1.22   \n",
            "  14    |   160   |   0.459322   |     -      |     -     |   1.22   \n",
            "  14    |   180   |   0.409463   |     -      |     -     |   1.22   \n",
            "  14    |   200   |   0.425659   |     -      |     -     |   1.22   \n",
            "  14    |   220   |   0.428197   |     -      |     -     |   1.22   \n",
            "  14    |   240   |   0.358168   |     -      |     -     |   1.22   \n",
            "  14    |   260   |   0.349683   |     -      |     -     |   1.22   \n",
            "  14    |   280   |   0.425412   |     -      |     -     |   1.22   \n",
            "  14    |   300   |   0.426009   |     -      |     -     |   1.22   \n",
            "  14    |   320   |   0.421810   |     -      |     -     |   1.22   \n",
            "  14    |   340   |   0.364025   |     -      |     -     |   1.22   \n",
            "  14    |   360   |   0.319728   |     -      |     -     |   1.22   \n",
            "  14    |   380   |   0.397245   |     -      |     -     |   1.22   \n",
            "  14    |   400   |   0.340676   |     -      |     -     |   1.22   \n",
            "  14    |   420   |   0.461874   |     -      |     -     |   1.22   \n",
            "  14    |   436   |   0.354501   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  14    |    -    |   0.400731   |  0.448649  |   82.64   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  15    |   20    |   0.417107   |     -      |     -     |   1.29   \n",
            "  15    |   40    |   0.397586   |     -      |     -     |   1.22   \n",
            "  15    |   60    |   0.457481   |     -      |     -     |   1.22   \n",
            "  15    |   80    |   0.386457   |     -      |     -     |   1.22   \n",
            "  15    |   100   |   0.386388   |     -      |     -     |   1.22   \n",
            "  15    |   120   |   0.356285   |     -      |     -     |   1.22   \n",
            "  15    |   140   |   0.347266   |     -      |     -     |   1.22   \n",
            "  15    |   160   |   0.447505   |     -      |     -     |   1.22   \n",
            "  15    |   180   |   0.404481   |     -      |     -     |   1.22   \n",
            "  15    |   200   |   0.430018   |     -      |     -     |   1.22   \n",
            "  15    |   220   |   0.411820   |     -      |     -     |   1.22   \n",
            "  15    |   240   |   0.343726   |     -      |     -     |   1.22   \n",
            "  15    |   260   |   0.365048   |     -      |     -     |   1.22   \n",
            "  15    |   280   |   0.408266   |     -      |     -     |   1.22   \n",
            "  15    |   300   |   0.423490   |     -      |     -     |   1.22   \n",
            "  15    |   320   |   0.399025   |     -      |     -     |   1.22   \n",
            "  15    |   340   |   0.399350   |     -      |     -     |   1.22   \n",
            "  15    |   360   |   0.299580   |     -      |     -     |   1.22   \n",
            "  15    |   380   |   0.379072   |     -      |     -     |   1.22   \n",
            "  15    |   400   |   0.336258   |     -      |     -     |   1.22   \n",
            "  15    |   420   |   0.471011   |     -      |     -     |   1.22   \n",
            "  15    |   436   |   0.360614   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  15    |    -    |   0.392520   |  0.447290  |   82.74   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  16    |   20    |   0.365691   |     -      |     -     |   1.27   \n",
            "  16    |   40    |   0.411821   |     -      |     -     |   1.22   \n",
            "  16    |   60    |   0.506325   |     -      |     -     |   1.22   \n",
            "  16    |   80    |   0.373457   |     -      |     -     |   1.22   \n",
            "  16    |   100   |   0.407193   |     -      |     -     |   1.22   \n",
            "  16    |   120   |   0.376131   |     -      |     -     |   1.22   \n",
            "  16    |   140   |   0.326549   |     -      |     -     |   1.22   \n",
            "  16    |   160   |   0.445326   |     -      |     -     |   1.22   \n",
            "  16    |   180   |   0.392155   |     -      |     -     |   1.22   \n",
            "  16    |   200   |   0.458865   |     -      |     -     |   1.22   \n",
            "  16    |   220   |   0.408035   |     -      |     -     |   1.22   \n",
            "  16    |   240   |   0.372509   |     -      |     -     |   1.22   \n",
            "  16    |   260   |   0.346018   |     -      |     -     |   1.22   \n",
            "  16    |   280   |   0.434149   |     -      |     -     |   1.22   \n",
            "  16    |   300   |   0.415610   |     -      |     -     |   1.22   \n",
            "  16    |   320   |   0.404081   |     -      |     -     |   1.22   \n",
            "  16    |   340   |   0.383335   |     -      |     -     |   1.22   \n",
            "  16    |   360   |   0.323183   |     -      |     -     |   1.22   \n",
            "  16    |   380   |   0.362132   |     -      |     -     |   1.22   \n",
            "  16    |   400   |   0.340644   |     -      |     -     |   1.22   \n",
            "  16    |   420   |   0.452840   |     -      |     -     |   1.22   \n",
            "  16    |   436   |   0.348768   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  16    |    -    |   0.393746   |  0.444587  |   82.84   |   30.34  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  17    |   20    |   0.367888   |     -      |     -     |   1.27   \n",
            "  17    |   40    |   0.442211   |     -      |     -     |   1.22   \n",
            "  17    |   60    |   0.447361   |     -      |     -     |   1.22   \n",
            "  17    |   80    |   0.412823   |     -      |     -     |   1.22   \n",
            "  17    |   100   |   0.404467   |     -      |     -     |   1.22   \n",
            "  17    |   120   |   0.354617   |     -      |     -     |   1.22   \n",
            "  17    |   140   |   0.338601   |     -      |     -     |   1.22   \n",
            "  17    |   160   |   0.427565   |     -      |     -     |   1.22   \n",
            "  17    |   180   |   0.426372   |     -      |     -     |   1.22   \n",
            "  17    |   200   |   0.390922   |     -      |     -     |   1.22   \n",
            "  17    |   220   |   0.347963   |     -      |     -     |   1.22   \n",
            "  17    |   240   |   0.349403   |     -      |     -     |   1.22   \n",
            "  17    |   260   |   0.346885   |     -      |     -     |   1.22   \n",
            "  17    |   280   |   0.427689   |     -      |     -     |   1.22   \n",
            "  17    |   300   |   0.408628   |     -      |     -     |   1.22   \n",
            "  17    |   320   |   0.440994   |     -      |     -     |   1.22   \n",
            "  17    |   340   |   0.397584   |     -      |     -     |   1.23   \n",
            "  17    |   360   |   0.291816   |     -      |     -     |   1.22   \n",
            "  17    |   380   |   0.375784   |     -      |     -     |   1.22   \n",
            "  17    |   400   |   0.353804   |     -      |     -     |   1.22   \n",
            "  17    |   420   |   0.430190   |     -      |     -     |   1.22   \n",
            "  17    |   436   |   0.367809   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  17    |    -    |   0.388843   |  0.444458  |   82.84   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  18    |   20    |   0.418748   |     -      |     -     |   1.27   \n",
            "  18    |   40    |   0.422389   |     -      |     -     |   1.22   \n",
            "  18    |   60    |   0.473635   |     -      |     -     |   1.22   \n",
            "  18    |   80    |   0.361444   |     -      |     -     |   1.22   \n",
            "  18    |   100   |   0.368157   |     -      |     -     |   1.22   \n",
            "  18    |   120   |   0.353441   |     -      |     -     |   1.22   \n",
            "  18    |   140   |   0.336234   |     -      |     -     |   1.22   \n",
            "  18    |   160   |   0.473355   |     -      |     -     |   1.22   \n",
            "  18    |   180   |   0.410412   |     -      |     -     |   1.22   \n",
            "  18    |   200   |   0.409360   |     -      |     -     |   1.22   \n",
            "  18    |   220   |   0.362156   |     -      |     -     |   1.22   \n",
            "  18    |   240   |   0.338805   |     -      |     -     |   1.22   \n",
            "  18    |   260   |   0.377332   |     -      |     -     |   1.22   \n",
            "  18    |   280   |   0.384195   |     -      |     -     |   1.22   \n",
            "  18    |   300   |   0.412205   |     -      |     -     |   1.22   \n",
            "  18    |   320   |   0.389121   |     -      |     -     |   1.22   \n",
            "  18    |   340   |   0.353977   |     -      |     -     |   1.22   \n",
            "  18    |   360   |   0.334312   |     -      |     -     |   1.22   \n",
            "  18    |   380   |   0.341309   |     -      |     -     |   1.22   \n",
            "  18    |   400   |   0.345814   |     -      |     -     |   1.22   \n",
            "  18    |   420   |   0.478663   |     -      |     -     |   1.22   \n",
            "  18    |   436   |   0.367422   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  18    |    -    |   0.387183   |  0.451227  |   82.44   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  19    |   20    |   0.367238   |     -      |     -     |   1.27   \n",
            "  19    |   40    |   0.411431   |     -      |     -     |   1.22   \n",
            "  19    |   60    |   0.445332   |     -      |     -     |   1.22   \n",
            "  19    |   80    |   0.371047   |     -      |     -     |   1.22   \n",
            "  19    |   100   |   0.394249   |     -      |     -     |   1.22   \n",
            "  19    |   120   |   0.344158   |     -      |     -     |   1.22   \n",
            "  19    |   140   |   0.327281   |     -      |     -     |   1.22   \n",
            "  19    |   160   |   0.405482   |     -      |     -     |   1.22   \n",
            "  19    |   180   |   0.407303   |     -      |     -     |   1.22   \n",
            "  19    |   200   |   0.388684   |     -      |     -     |   1.22   \n",
            "  19    |   220   |   0.373595   |     -      |     -     |   1.22   \n",
            "  19    |   240   |   0.292168   |     -      |     -     |   1.22   \n",
            "  19    |   260   |   0.343062   |     -      |     -     |   1.22   \n",
            "  19    |   280   |   0.395931   |     -      |     -     |   1.22   \n",
            "  19    |   300   |   0.474198   |     -      |     -     |   1.21   \n",
            "  19    |   320   |   0.374734   |     -      |     -     |   1.22   \n",
            "  19    |   340   |   0.350220   |     -      |     -     |   1.22   \n",
            "  19    |   360   |   0.308794   |     -      |     -     |   1.22   \n",
            "  19    |   380   |   0.387900   |     -      |     -     |   1.22   \n",
            "  19    |   400   |   0.339572   |     -      |     -     |   1.22   \n",
            "  19    |   420   |   0.472602   |     -      |     -     |   1.22   \n",
            "  19    |   436   |   0.348342   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  19    |    -    |   0.378582   |  0.454709  |   83.13   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  20    |   20    |   0.369240   |     -      |     -     |   1.29   \n",
            "  20    |   40    |   0.388546   |     -      |     -     |   1.22   \n",
            "  20    |   60    |   0.465092   |     -      |     -     |   1.22   \n",
            "  20    |   80    |   0.385429   |     -      |     -     |   1.22   \n",
            "  20    |   100   |   0.369803   |     -      |     -     |   1.22   \n",
            "  20    |   120   |   0.352993   |     -      |     -     |   1.22   \n",
            "  20    |   140   |   0.306654   |     -      |     -     |   1.22   \n",
            "  20    |   160   |   0.411812   |     -      |     -     |   1.22   \n",
            "  20    |   180   |   0.372783   |     -      |     -     |   1.22   \n",
            "  20    |   200   |   0.424590   |     -      |     -     |   1.22   \n",
            "  20    |   220   |   0.376615   |     -      |     -     |   1.22   \n",
            "  20    |   240   |   0.306766   |     -      |     -     |   1.21   \n",
            "  20    |   260   |   0.361212   |     -      |     -     |   1.22   \n",
            "  20    |   280   |   0.397442   |     -      |     -     |   1.22   \n",
            "  20    |   300   |   0.385645   |     -      |     -     |   1.22   \n",
            "  20    |   320   |   0.350810   |     -      |     -     |   1.22   \n",
            "  20    |   340   |   0.415772   |     -      |     -     |   1.22   \n",
            "  20    |   360   |   0.307116   |     -      |     -     |   1.22   \n",
            "  20    |   380   |   0.370294   |     -      |     -     |   1.22   \n",
            "  20    |   400   |   0.334132   |     -      |     -     |   1.22   \n",
            "  20    |   420   |   0.401633   |     -      |     -     |   1.22   \n",
            "  20    |   436   |   0.348445   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  20    |    -    |   0.373071   |  0.476238  |   82.24   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  21    |   20    |   0.386806   |     -      |     -     |   1.27   \n",
            "  21    |   40    |   0.389401   |     -      |     -     |   1.22   \n",
            "  21    |   60    |   0.448076   |     -      |     -     |   1.22   \n",
            "  21    |   80    |   0.374522   |     -      |     -     |   1.22   \n",
            "  21    |   100   |   0.391453   |     -      |     -     |   1.22   \n",
            "  21    |   120   |   0.374365   |     -      |     -     |   1.22   \n",
            "  21    |   140   |   0.312093   |     -      |     -     |   1.22   \n",
            "  21    |   160   |   0.406535   |     -      |     -     |   1.22   \n",
            "  21    |   180   |   0.403367   |     -      |     -     |   1.22   \n",
            "  21    |   200   |   0.375724   |     -      |     -     |   1.22   \n",
            "  21    |   220   |   0.357683   |     -      |     -     |   1.22   \n",
            "  21    |   240   |   0.336596   |     -      |     -     |   1.22   \n",
            "  21    |   260   |   0.316489   |     -      |     -     |   1.22   \n",
            "  21    |   280   |   0.372598   |     -      |     -     |   1.22   \n",
            "  21    |   300   |   0.432709   |     -      |     -     |   1.22   \n",
            "  21    |   320   |   0.393143   |     -      |     -     |   1.22   \n",
            "  21    |   340   |   0.352993   |     -      |     -     |   1.22   \n",
            "  21    |   360   |   0.307915   |     -      |     -     |   1.22   \n",
            "  21    |   380   |   0.340570   |     -      |     -     |   1.22   \n",
            "  21    |   400   |   0.362189   |     -      |     -     |   1.22   \n",
            "  21    |   420   |   0.439615   |     -      |     -     |   1.22   \n",
            "  21    |   436   |   0.374586   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  21    |    -    |   0.375005   |  0.456158  |   82.84   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  22    |   20    |   0.384949   |     -      |     -     |   1.28   \n",
            "  22    |   40    |   0.420054   |     -      |     -     |   1.22   \n",
            "  22    |   60    |   0.477257   |     -      |     -     |   1.22   \n",
            "  22    |   80    |   0.393054   |     -      |     -     |   1.22   \n",
            "  22    |   100   |   0.346152   |     -      |     -     |   1.22   \n",
            "  22    |   120   |   0.331662   |     -      |     -     |   1.22   \n",
            "  22    |   140   |   0.329170   |     -      |     -     |   1.22   \n",
            "  22    |   160   |   0.437377   |     -      |     -     |   1.22   \n",
            "  22    |   180   |   0.417871   |     -      |     -     |   1.22   \n",
            "  22    |   200   |   0.420028   |     -      |     -     |   1.22   \n",
            "  22    |   220   |   0.373990   |     -      |     -     |   1.22   \n",
            "  22    |   240   |   0.297169   |     -      |     -     |   1.22   \n",
            "  22    |   260   |   0.354941   |     -      |     -     |   1.22   \n",
            "  22    |   280   |   0.418480   |     -      |     -     |   1.22   \n",
            "  22    |   300   |   0.407529   |     -      |     -     |   1.22   \n",
            "  22    |   320   |   0.366117   |     -      |     -     |   1.22   \n",
            "  22    |   340   |   0.361142   |     -      |     -     |   1.22   \n",
            "  22    |   360   |   0.283961   |     -      |     -     |   1.22   \n",
            "  22    |   380   |   0.361116   |     -      |     -     |   1.22   \n",
            "  22    |   400   |   0.322540   |     -      |     -     |   1.22   \n",
            "  22    |   420   |   0.436741   |     -      |     -     |   1.22   \n",
            "  22    |   436   |   0.344964   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  22    |    -    |   0.376957   |  0.453238  |   82.54   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  23    |   20    |   0.366931   |     -      |     -     |   1.27   \n",
            "  23    |   40    |   0.423647   |     -      |     -     |   1.22   \n",
            "  23    |   60    |   0.465117   |     -      |     -     |   1.22   \n",
            "  23    |   80    |   0.382870   |     -      |     -     |   1.22   \n",
            "  23    |   100   |   0.396063   |     -      |     -     |   1.22   \n",
            "  23    |   120   |   0.290059   |     -      |     -     |   1.22   \n",
            "  23    |   140   |   0.308902   |     -      |     -     |   1.22   \n",
            "  23    |   160   |   0.466910   |     -      |     -     |   1.22   \n",
            "  23    |   180   |   0.370426   |     -      |     -     |   1.22   \n",
            "  23    |   200   |   0.400576   |     -      |     -     |   1.21   \n",
            "  23    |   220   |   0.361682   |     -      |     -     |   1.22   \n",
            "  23    |   240   |   0.315685   |     -      |     -     |   1.22   \n",
            "  23    |   260   |   0.361937   |     -      |     -     |   1.22   \n",
            "  23    |   280   |   0.449053   |     -      |     -     |   1.22   \n",
            "  23    |   300   |   0.384242   |     -      |     -     |   1.22   \n",
            "  23    |   320   |   0.391462   |     -      |     -     |   1.22   \n",
            "  23    |   340   |   0.352968   |     -      |     -     |   1.22   \n",
            "  23    |   360   |   0.267287   |     -      |     -     |   1.22   \n",
            "  23    |   380   |   0.335123   |     -      |     -     |   1.22   \n",
            "  23    |   400   |   0.342201   |     -      |     -     |   1.22   \n",
            "  23    |   420   |   0.460375   |     -      |     -     |   1.22   \n",
            "  23    |   436   |   0.327717   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  23    |    -    |   0.374098   |  0.464205  |   82.04   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  24    |   20    |   0.355389   |     -      |     -     |   1.29   \n",
            "  24    |   40    |   0.397283   |     -      |     -     |   1.22   \n",
            "  24    |   60    |   0.439775   |     -      |     -     |   1.22   \n",
            "  24    |   80    |   0.363856   |     -      |     -     |   1.22   \n",
            "  24    |   100   |   0.398348   |     -      |     -     |   1.22   \n",
            "  24    |   120   |   0.306607   |     -      |     -     |   1.22   \n",
            "  24    |   140   |   0.312345   |     -      |     -     |   1.22   \n",
            "  24    |   160   |   0.453512   |     -      |     -     |   1.22   \n",
            "  24    |   180   |   0.358669   |     -      |     -     |   1.22   \n",
            "  24    |   200   |   0.405110   |     -      |     -     |   1.22   \n",
            "  24    |   220   |   0.354569   |     -      |     -     |   1.22   \n",
            "  24    |   240   |   0.322931   |     -      |     -     |   1.22   \n",
            "  24    |   260   |   0.341438   |     -      |     -     |   1.22   \n",
            "  24    |   280   |   0.382558   |     -      |     -     |   1.22   \n",
            "  24    |   300   |   0.388872   |     -      |     -     |   1.22   \n",
            "  24    |   320   |   0.376341   |     -      |     -     |   1.22   \n",
            "  24    |   340   |   0.346948   |     -      |     -     |   1.22   \n",
            "  24    |   360   |   0.286229   |     -      |     -     |   1.22   \n",
            "  24    |   380   |   0.349768   |     -      |     -     |   1.22   \n",
            "  24    |   400   |   0.327186   |     -      |     -     |   1.22   \n",
            "  24    |   420   |   0.449825   |     -      |     -     |   1.22   \n",
            "  24    |   436   |   0.341826   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  24    |    -    |   0.366535   |  0.454000  |   82.44   |   30.41  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  25    |   20    |   0.379912   |     -      |     -     |   1.27   \n",
            "  25    |   40    |   0.422890   |     -      |     -     |   1.22   \n",
            "  25    |   60    |   0.437086   |     -      |     -     |   1.22   \n",
            "  25    |   80    |   0.376317   |     -      |     -     |   1.22   \n",
            "  25    |   100   |   0.394504   |     -      |     -     |   1.22   \n",
            "  25    |   120   |   0.335781   |     -      |     -     |   1.22   \n",
            "  25    |   140   |   0.304482   |     -      |     -     |   1.22   \n",
            "  25    |   160   |   0.419641   |     -      |     -     |   1.22   \n",
            "  25    |   180   |   0.385128   |     -      |     -     |   1.22   \n",
            "  25    |   200   |   0.393926   |     -      |     -     |   1.22   \n",
            "  25    |   220   |   0.355466   |     -      |     -     |   1.22   \n",
            "  25    |   240   |   0.310709   |     -      |     -     |   1.22   \n",
            "  25    |   260   |   0.323584   |     -      |     -     |   1.22   \n",
            "  25    |   280   |   0.400838   |     -      |     -     |   1.22   \n",
            "  25    |   300   |   0.393719   |     -      |     -     |   1.22   \n",
            "  25    |   320   |   0.375850   |     -      |     -     |   1.22   \n",
            "  25    |   340   |   0.363255   |     -      |     -     |   1.22   \n",
            "  25    |   360   |   0.277003   |     -      |     -     |   1.22   \n",
            "  25    |   380   |   0.356499   |     -      |     -     |   1.22   \n",
            "  25    |   400   |   0.297354   |     -      |     -     |   1.22   \n",
            "  25    |   420   |   0.413802   |     -      |     -     |   1.22   \n",
            "  25    |   436   |   0.332325   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  25    |    -    |   0.366252   |  0.467353  |   82.34   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  26    |   20    |   0.369583   |     -      |     -     |   1.27   \n",
            "  26    |   40    |   0.397171   |     -      |     -     |   1.22   \n",
            "  26    |   60    |   0.417941   |     -      |     -     |   1.22   \n",
            "  26    |   80    |   0.374340   |     -      |     -     |   1.22   \n",
            "  26    |   100   |   0.349831   |     -      |     -     |   1.22   \n",
            "  26    |   120   |   0.319332   |     -      |     -     |   1.22   \n",
            "  26    |   140   |   0.314574   |     -      |     -     |   1.21   \n",
            "  26    |   160   |   0.404035   |     -      |     -     |   1.22   \n",
            "  26    |   180   |   0.376735   |     -      |     -     |   1.22   \n",
            "  26    |   200   |   0.392667   |     -      |     -     |   1.22   \n",
            "  26    |   220   |   0.377001   |     -      |     -     |   1.22   \n",
            "  26    |   240   |   0.331011   |     -      |     -     |   1.22   \n",
            "  26    |   260   |   0.335297   |     -      |     -     |   1.22   \n",
            "  26    |   280   |   0.442575   |     -      |     -     |   1.22   \n",
            "  26    |   300   |   0.387642   |     -      |     -     |   1.22   \n",
            "  26    |   320   |   0.362352   |     -      |     -     |   1.22   \n",
            "  26    |   340   |   0.357527   |     -      |     -     |   1.22   \n",
            "  26    |   360   |   0.304564   |     -      |     -     |   1.22   \n",
            "  26    |   380   |   0.340335   |     -      |     -     |   1.22   \n",
            "  26    |   400   |   0.326666   |     -      |     -     |   1.22   \n",
            "  26    |   420   |   0.462159   |     -      |     -     |   1.22   \n",
            "  26    |   436   |   0.334387   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  26    |    -    |   0.367475   |  0.465338  |   82.54   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  27    |   20    |   0.368531   |     -      |     -     |   1.28   \n",
            "  27    |   40    |   0.363882   |     -      |     -     |   1.22   \n",
            "  27    |   60    |   0.472104   |     -      |     -     |   1.22   \n",
            "  27    |   80    |   0.365234   |     -      |     -     |   1.22   \n",
            "  27    |   100   |   0.364701   |     -      |     -     |   1.22   \n",
            "  27    |   120   |   0.340456   |     -      |     -     |   1.22   \n",
            "  27    |   140   |   0.296951   |     -      |     -     |   1.22   \n",
            "  27    |   160   |   0.413727   |     -      |     -     |   1.22   \n",
            "  27    |   180   |   0.376344   |     -      |     -     |   1.22   \n",
            "  27    |   200   |   0.395765   |     -      |     -     |   1.22   \n",
            "  27    |   220   |   0.368519   |     -      |     -     |   1.22   \n",
            "  27    |   240   |   0.314653   |     -      |     -     |   1.22   \n",
            "  27    |   260   |   0.333560   |     -      |     -     |   1.22   \n",
            "  27    |   280   |   0.388498   |     -      |     -     |   1.22   \n",
            "  27    |   300   |   0.406213   |     -      |     -     |   1.22   \n",
            "  27    |   320   |   0.390990   |     -      |     -     |   1.22   \n",
            "  27    |   340   |   0.351789   |     -      |     -     |   1.22   \n",
            "  27    |   360   |   0.273999   |     -      |     -     |   1.22   \n",
            "  27    |   380   |   0.346739   |     -      |     -     |   1.22   \n",
            "  27    |   400   |   0.338197   |     -      |     -     |   1.22   \n",
            "  27    |   420   |   0.416947   |     -      |     -     |   1.22   \n",
            "  27    |   436   |   0.331166   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  27    |    -    |   0.364813   |  0.466209  |   82.24   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  28    |   20    |   0.332437   |     -      |     -     |   1.29   \n",
            "  28    |   40    |   0.404941   |     -      |     -     |   1.22   \n",
            "  28    |   60    |   0.464210   |     -      |     -     |   1.22   \n",
            "  28    |   80    |   0.403376   |     -      |     -     |   1.22   \n",
            "  28    |   100   |   0.365225   |     -      |     -     |   1.22   \n",
            "  28    |   120   |   0.323471   |     -      |     -     |   1.22   \n",
            "  28    |   140   |   0.294801   |     -      |     -     |   1.22   \n",
            "  28    |   160   |   0.433302   |     -      |     -     |   1.22   \n",
            "  28    |   180   |   0.372851   |     -      |     -     |   1.22   \n",
            "  28    |   200   |   0.350810   |     -      |     -     |   1.22   \n",
            "  28    |   220   |   0.356650   |     -      |     -     |   1.22   \n",
            "  28    |   240   |   0.306519   |     -      |     -     |   1.22   \n",
            "  28    |   260   |   0.333740   |     -      |     -     |   1.22   \n",
            "  28    |   280   |   0.382990   |     -      |     -     |   1.22   \n",
            "  28    |   300   |   0.386891   |     -      |     -     |   1.22   \n",
            "  28    |   320   |   0.361699   |     -      |     -     |   1.22   \n",
            "  28    |   340   |   0.330696   |     -      |     -     |   1.22   \n",
            "  28    |   360   |   0.271056   |     -      |     -     |   1.22   \n",
            "  28    |   380   |   0.412694   |     -      |     -     |   1.22   \n",
            "  28    |   400   |   0.281961   |     -      |     -     |   1.22   \n",
            "  28    |   420   |   0.419456   |     -      |     -     |   1.22   \n",
            "  28    |   436   |   0.323160   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  28    |    -    |   0.359951   |  0.476980  |   82.34   |   30.39  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  29    |   20    |   0.361732   |     -      |     -     |   1.28   \n",
            "  29    |   40    |   0.374855   |     -      |     -     |   1.22   \n",
            "  29    |   60    |   0.410860   |     -      |     -     |   1.22   \n",
            "  29    |   80    |   0.413348   |     -      |     -     |   1.22   \n",
            "  29    |   100   |   0.343910   |     -      |     -     |   1.22   \n",
            "  29    |   120   |   0.349557   |     -      |     -     |   1.22   \n",
            "  29    |   140   |   0.303186   |     -      |     -     |   1.22   \n",
            "  29    |   160   |   0.403973   |     -      |     -     |   1.22   \n",
            "  29    |   180   |   0.390817   |     -      |     -     |   1.22   \n",
            "  29    |   200   |   0.378618   |     -      |     -     |   1.22   \n",
            "  29    |   220   |   0.353023   |     -      |     -     |   1.21   \n",
            "  29    |   240   |   0.294564   |     -      |     -     |   1.22   \n",
            "  29    |   260   |   0.327806   |     -      |     -     |   1.22   \n",
            "  29    |   280   |   0.378483   |     -      |     -     |   1.22   \n",
            "  29    |   300   |   0.400274   |     -      |     -     |   1.22   \n",
            "  29    |   320   |   0.367141   |     -      |     -     |   1.22   \n",
            "  29    |   340   |   0.364603   |     -      |     -     |   1.22   \n",
            "  29    |   360   |   0.246219   |     -      |     -     |   1.22   \n",
            "  29    |   380   |   0.343564   |     -      |     -     |   1.22   \n",
            "  29    |   400   |   0.296346   |     -      |     -     |   1.22   \n",
            "  29    |   420   |   0.445932   |     -      |     -     |   1.22   \n",
            "  29    |   436   |   0.336552   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  29    |    -    |   0.358633   |  0.473384  |   82.34   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  30    |   20    |   0.375025   |     -      |     -     |   1.27   \n",
            "  30    |   40    |   0.361224   |     -      |     -     |   1.22   \n",
            "  30    |   60    |   0.477953   |     -      |     -     |   1.22   \n",
            "  30    |   80    |   0.391081   |     -      |     -     |   1.22   \n",
            "  30    |   100   |   0.361768   |     -      |     -     |   1.22   \n",
            "  30    |   120   |   0.317095   |     -      |     -     |   1.21   \n",
            "  30    |   140   |   0.290707   |     -      |     -     |   1.22   \n",
            "  30    |   160   |   0.378828   |     -      |     -     |   1.22   \n",
            "  30    |   180   |   0.349532   |     -      |     -     |   1.22   \n",
            "  30    |   200   |   0.367240   |     -      |     -     |   1.22   \n",
            "  30    |   220   |   0.314976   |     -      |     -     |   1.22   \n",
            "  30    |   240   |   0.306292   |     -      |     -     |   1.22   \n",
            "  30    |   260   |   0.340330   |     -      |     -     |   1.22   \n",
            "  30    |   280   |   0.420520   |     -      |     -     |   1.22   \n",
            "  30    |   300   |   0.366699   |     -      |     -     |   1.22   \n",
            "  30    |   320   |   0.351486   |     -      |     -     |   1.22   \n",
            "  30    |   340   |   0.382564   |     -      |     -     |   1.22   \n",
            "  30    |   360   |   0.270545   |     -      |     -     |   1.22   \n",
            "  30    |   380   |   0.392732   |     -      |     -     |   1.22   \n",
            "  30    |   400   |   0.331132   |     -      |     -     |   1.22   \n",
            "  30    |   420   |   0.426296   |     -      |     -     |   1.22   \n",
            "  30    |   436   |   0.344821   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  30    |    -    |   0.360120   |  0.479131  |   82.44   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  31    |   20    |   0.360849   |     -      |     -     |   1.28   \n",
            "  31    |   40    |   0.396004   |     -      |     -     |   1.22   \n",
            "  31    |   60    |   0.435164   |     -      |     -     |   1.22   \n",
            "  31    |   80    |   0.345206   |     -      |     -     |   1.22   \n",
            "  31    |   100   |   0.334128   |     -      |     -     |   1.22   \n",
            "  31    |   120   |   0.304793   |     -      |     -     |   1.22   \n",
            "  31    |   140   |   0.283170   |     -      |     -     |   1.22   \n",
            "  31    |   160   |   0.435266   |     -      |     -     |   1.22   \n",
            "  31    |   180   |   0.361742   |     -      |     -     |   1.22   \n",
            "  31    |   200   |   0.343527   |     -      |     -     |   1.22   \n",
            "  31    |   220   |   0.364569   |     -      |     -     |   1.22   \n",
            "  31    |   240   |   0.321721   |     -      |     -     |   1.22   \n",
            "  31    |   260   |   0.314430   |     -      |     -     |   1.22   \n",
            "  31    |   280   |   0.401040   |     -      |     -     |   1.22   \n",
            "  31    |   300   |   0.408054   |     -      |     -     |   1.22   \n",
            "  31    |   320   |   0.383376   |     -      |     -     |   1.22   \n",
            "  31    |   340   |   0.357488   |     -      |     -     |   1.22   \n",
            "  31    |   360   |   0.284053   |     -      |     -     |   1.22   \n",
            "  31    |   380   |   0.317796   |     -      |     -     |   1.22   \n",
            "  31    |   400   |   0.313710   |     -      |     -     |   1.22   \n",
            "  31    |   420   |   0.432135   |     -      |     -     |   1.22   \n",
            "  31    |   436   |   0.329302   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  31    |    -    |   0.356051   |  0.480747  |   82.84   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  32    |   20    |   0.368920   |     -      |     -     |   1.29   \n",
            "  32    |   40    |   0.381580   |     -      |     -     |   1.22   \n",
            "  32    |   60    |   0.462378   |     -      |     -     |   1.22   \n",
            "  32    |   80    |   0.408165   |     -      |     -     |   1.22   \n",
            "  32    |   100   |   0.347139   |     -      |     -     |   1.22   \n",
            "  32    |   120   |   0.297835   |     -      |     -     |   1.22   \n",
            "  32    |   140   |   0.301588   |     -      |     -     |   1.22   \n",
            "  32    |   160   |   0.409734   |     -      |     -     |   1.22   \n",
            "  32    |   180   |   0.350027   |     -      |     -     |   1.22   \n",
            "  32    |   200   |   0.418110   |     -      |     -     |   1.22   \n",
            "  32    |   220   |   0.345029   |     -      |     -     |   1.22   \n",
            "  32    |   240   |   0.322505   |     -      |     -     |   1.22   \n",
            "  32    |   260   |   0.331709   |     -      |     -     |   1.22   \n",
            "  32    |   280   |   0.380208   |     -      |     -     |   1.22   \n",
            "  32    |   300   |   0.372910   |     -      |     -     |   1.22   \n",
            "  32    |   320   |   0.342072   |     -      |     -     |   1.22   \n",
            "  32    |   340   |   0.360676   |     -      |     -     |   1.22   \n",
            "  32    |   360   |   0.273139   |     -      |     -     |   1.22   \n",
            "  32    |   380   |   0.355302   |     -      |     -     |   1.22   \n",
            "  32    |   400   |   0.313382   |     -      |     -     |   1.22   \n",
            "  32    |   420   |   0.465119   |     -      |     -     |   1.22   \n",
            "  32    |   436   |   0.305798   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  32    |    -    |   0.360211   |  0.480272  |   82.64   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  33    |   20    |   0.373919   |     -      |     -     |   1.28   \n",
            "  33    |   40    |   0.415885   |     -      |     -     |   1.22   \n",
            "  33    |   60    |   0.432083   |     -      |     -     |   1.22   \n",
            "  33    |   80    |   0.377546   |     -      |     -     |   1.22   \n",
            "  33    |   100   |   0.367415   |     -      |     -     |   1.22   \n",
            "  33    |   120   |   0.337472   |     -      |     -     |   1.22   \n",
            "  33    |   140   |   0.323666   |     -      |     -     |   1.22   \n",
            "  33    |   160   |   0.388052   |     -      |     -     |   1.22   \n",
            "  33    |   180   |   0.382193   |     -      |     -     |   1.22   \n",
            "  33    |   200   |   0.360442   |     -      |     -     |   1.22   \n",
            "  33    |   220   |   0.358747   |     -      |     -     |   1.22   \n",
            "  33    |   240   |   0.273179   |     -      |     -     |   1.22   \n",
            "  33    |   260   |   0.344176   |     -      |     -     |   1.22   \n",
            "  33    |   280   |   0.380933   |     -      |     -     |   1.22   \n",
            "  33    |   300   |   0.372663   |     -      |     -     |   1.22   \n",
            "  33    |   320   |   0.360126   |     -      |     -     |   1.22   \n",
            "  33    |   340   |   0.303700   |     -      |     -     |   1.22   \n",
            "  33    |   360   |   0.258863   |     -      |     -     |   1.22   \n",
            "  33    |   380   |   0.317627   |     -      |     -     |   1.22   \n",
            "  33    |   400   |   0.312950   |     -      |     -     |   1.22   \n",
            "  33    |   420   |   0.405867   |     -      |     -     |   1.23   \n",
            "  33    |   436   |   0.318511   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  33    |    -    |   0.353364   |  0.501118  |   81.94   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  34    |   20    |   0.338554   |     -      |     -     |   1.29   \n",
            "  34    |   40    |   0.391780   |     -      |     -     |   1.22   \n",
            "  34    |   60    |   0.402108   |     -      |     -     |   1.22   \n",
            "  34    |   80    |   0.354815   |     -      |     -     |   1.22   \n",
            "  34    |   100   |   0.355912   |     -      |     -     |   1.22   \n",
            "  34    |   120   |   0.297691   |     -      |     -     |   1.22   \n",
            "  34    |   140   |   0.320319   |     -      |     -     |   1.22   \n",
            "  34    |   160   |   0.391945   |     -      |     -     |   1.22   \n",
            "  34    |   180   |   0.394892   |     -      |     -     |   1.22   \n",
            "  34    |   200   |   0.361837   |     -      |     -     |   1.22   \n",
            "  34    |   220   |   0.364953   |     -      |     -     |   1.22   \n",
            "  34    |   240   |   0.274724   |     -      |     -     |   1.22   \n",
            "  34    |   260   |   0.337664   |     -      |     -     |   1.22   \n",
            "  34    |   280   |   0.426403   |     -      |     -     |   1.22   \n",
            "  34    |   300   |   0.372882   |     -      |     -     |   1.22   \n",
            "  34    |   320   |   0.372684   |     -      |     -     |   1.22   \n",
            "  34    |   340   |   0.332901   |     -      |     -     |   1.22   \n",
            "  34    |   360   |   0.242714   |     -      |     -     |   1.22   \n",
            "  34    |   380   |   0.321091   |     -      |     -     |   1.22   \n",
            "  34    |   400   |   0.303132   |     -      |     -     |   1.22   \n",
            "  34    |   420   |   0.408321   |     -      |     -     |   1.22   \n",
            "  34    |   436   |   0.362999   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  34    |    -    |   0.351242   |  0.480310  |   82.34   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  35    |   20    |   0.322938   |     -      |     -     |   1.28   \n",
            "  35    |   40    |   0.355353   |     -      |     -     |   1.22   \n",
            "  35    |   60    |   0.451163   |     -      |     -     |   1.22   \n",
            "  35    |   80    |   0.335129   |     -      |     -     |   1.22   \n",
            "  35    |   100   |   0.350441   |     -      |     -     |   1.22   \n",
            "  35    |   120   |   0.307041   |     -      |     -     |   1.22   \n",
            "  35    |   140   |   0.301284   |     -      |     -     |   1.22   \n",
            "  35    |   160   |   0.429436   |     -      |     -     |   1.22   \n",
            "  35    |   180   |   0.361273   |     -      |     -     |   1.22   \n",
            "  35    |   200   |   0.392884   |     -      |     -     |   1.22   \n",
            "  35    |   220   |   0.348563   |     -      |     -     |   1.22   \n",
            "  35    |   240   |   0.285577   |     -      |     -     |   1.22   \n",
            "  35    |   260   |   0.313900   |     -      |     -     |   1.22   \n",
            "  35    |   280   |   0.395048   |     -      |     -     |   1.22   \n",
            "  35    |   300   |   0.367290   |     -      |     -     |   1.22   \n",
            "  35    |   320   |   0.349428   |     -      |     -     |   1.22   \n",
            "  35    |   340   |   0.359651   |     -      |     -     |   1.22   \n",
            "  35    |   360   |   0.229335   |     -      |     -     |   1.22   \n",
            "  35    |   380   |   0.351309   |     -      |     -     |   1.22   \n",
            "  35    |   400   |   0.307162   |     -      |     -     |   1.22   \n",
            "  35    |   420   |   0.445152   |     -      |     -     |   1.22   \n",
            "  35    |   436   |   0.342904   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  35    |    -    |   0.350106   |  0.483076  |   82.04   |   30.38  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  36    |   20    |   0.339837   |     -      |     -     |   1.28   \n",
            "  36    |   40    |   0.347523   |     -      |     -     |   1.22   \n",
            "  36    |   60    |   0.426485   |     -      |     -     |   1.22   \n",
            "  36    |   80    |   0.361207   |     -      |     -     |   1.22   \n",
            "  36    |   100   |   0.398978   |     -      |     -     |   1.22   \n",
            "  36    |   120   |   0.324120   |     -      |     -     |   1.22   \n",
            "  36    |   140   |   0.272344   |     -      |     -     |   1.22   \n",
            "  36    |   160   |   0.391225   |     -      |     -     |   1.22   \n",
            "  36    |   180   |   0.356858   |     -      |     -     |   1.22   \n",
            "  36    |   200   |   0.343226   |     -      |     -     |   1.22   \n",
            "  36    |   220   |   0.330735   |     -      |     -     |   1.22   \n",
            "  36    |   240   |   0.283001   |     -      |     -     |   1.22   \n",
            "  36    |   260   |   0.353885   |     -      |     -     |   1.22   \n",
            "  36    |   280   |   0.406915   |     -      |     -     |   1.22   \n",
            "  36    |   300   |   0.358563   |     -      |     -     |   1.22   \n",
            "  36    |   320   |   0.326470   |     -      |     -     |   1.22   \n",
            "  36    |   340   |   0.347565   |     -      |     -     |   1.22   \n",
            "  36    |   360   |   0.249708   |     -      |     -     |   1.22   \n",
            "  36    |   380   |   0.372298   |     -      |     -     |   1.22   \n",
            "  36    |   400   |   0.298168   |     -      |     -     |   1.22   \n",
            "  36    |   420   |   0.439607   |     -      |     -     |   1.22   \n",
            "  36    |   436   |   0.327187   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  36    |    -    |   0.348167   |  0.488676  |   82.54   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  37    |   20    |   0.364680   |     -      |     -     |   1.28   \n",
            "  37    |   40    |   0.363355   |     -      |     -     |   1.22   \n",
            "  37    |   60    |   0.422090   |     -      |     -     |   1.22   \n",
            "  37    |   80    |   0.345328   |     -      |     -     |   1.22   \n",
            "  37    |   100   |   0.323775   |     -      |     -     |   1.22   \n",
            "  37    |   120   |   0.308479   |     -      |     -     |   1.22   \n",
            "  37    |   140   |   0.279407   |     -      |     -     |   1.22   \n",
            "  37    |   160   |   0.416895   |     -      |     -     |   1.22   \n",
            "  37    |   180   |   0.354051   |     -      |     -     |   1.22   \n",
            "  37    |   200   |   0.351617   |     -      |     -     |   1.22   \n",
            "  37    |   220   |   0.381474   |     -      |     -     |   1.22   \n",
            "  37    |   240   |   0.273975   |     -      |     -     |   1.22   \n",
            "  37    |   260   |   0.308571   |     -      |     -     |   1.22   \n",
            "  37    |   280   |   0.428151   |     -      |     -     |   1.22   \n",
            "  37    |   300   |   0.379053   |     -      |     -     |   1.22   \n",
            "  37    |   320   |   0.319020   |     -      |     -     |   1.22   \n",
            "  37    |   340   |   0.344516   |     -      |     -     |   1.22   \n",
            "  37    |   360   |   0.243166   |     -      |     -     |   1.22   \n",
            "  37    |   380   |   0.353348   |     -      |     -     |   1.22   \n",
            "  37    |   400   |   0.336330   |     -      |     -     |   1.22   \n",
            "  37    |   420   |   0.381896   |     -      |     -     |   1.22   \n",
            "  37    |   436   |   0.316037   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  37    |    -    |   0.345549   |  0.494712  |   82.44   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  38    |   20    |   0.348239   |     -      |     -     |   1.29   \n",
            "  38    |   40    |   0.314838   |     -      |     -     |   1.22   \n",
            "  38    |   60    |   0.462962   |     -      |     -     |   1.22   \n",
            "  38    |   80    |   0.353396   |     -      |     -     |   1.22   \n",
            "  38    |   100   |   0.383815   |     -      |     -     |   1.22   \n",
            "  38    |   120   |   0.287035   |     -      |     -     |   1.21   \n",
            "  38    |   140   |   0.266226   |     -      |     -     |   1.22   \n",
            "  38    |   160   |   0.411914   |     -      |     -     |   1.22   \n",
            "  38    |   180   |   0.358438   |     -      |     -     |   1.22   \n",
            "  38    |   200   |   0.385625   |     -      |     -     |   1.22   \n",
            "  38    |   220   |   0.300585   |     -      |     -     |   1.22   \n",
            "  38    |   240   |   0.309268   |     -      |     -     |   1.22   \n",
            "  38    |   260   |   0.318038   |     -      |     -     |   1.22   \n",
            "  38    |   280   |   0.380882   |     -      |     -     |   1.22   \n",
            "  38    |   300   |   0.379576   |     -      |     -     |   1.22   \n",
            "  38    |   320   |   0.374291   |     -      |     -     |   1.22   \n",
            "  38    |   340   |   0.358838   |     -      |     -     |   1.22   \n",
            "  38    |   360   |   0.267162   |     -      |     -     |   1.22   \n",
            "  38    |   380   |   0.284124   |     -      |     -     |   1.22   \n",
            "  38    |   400   |   0.305240   |     -      |     -     |   1.22   \n",
            "  38    |   420   |   0.377598   |     -      |     -     |   1.22   \n",
            "  38    |   436   |   0.305426   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  38    |    -    |   0.342785   |  0.493223  |   82.74   |   30.36  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  39    |   20    |   0.343229   |     -      |     -     |   1.29   \n",
            "  39    |   40    |   0.356680   |     -      |     -     |   1.22   \n",
            "  39    |   60    |   0.409761   |     -      |     -     |   1.22   \n",
            "  39    |   80    |   0.318393   |     -      |     -     |   1.22   \n",
            "  39    |   100   |   0.357640   |     -      |     -     |   1.22   \n",
            "  39    |   120   |   0.349544   |     -      |     -     |   1.22   \n",
            "  39    |   140   |   0.290374   |     -      |     -     |   1.22   \n",
            "  39    |   160   |   0.389431   |     -      |     -     |   1.22   \n",
            "  39    |   180   |   0.363598   |     -      |     -     |   1.22   \n",
            "  39    |   200   |   0.380331   |     -      |     -     |   1.22   \n",
            "  39    |   220   |   0.333103   |     -      |     -     |   1.22   \n",
            "  39    |   240   |   0.270366   |     -      |     -     |   1.22   \n",
            "  39    |   260   |   0.319315   |     -      |     -     |   1.22   \n",
            "  39    |   280   |   0.375379   |     -      |     -     |   1.22   \n",
            "  39    |   300   |   0.350243   |     -      |     -     |   1.22   \n",
            "  39    |   320   |   0.304616   |     -      |     -     |   1.22   \n",
            "  39    |   340   |   0.334769   |     -      |     -     |   1.22   \n",
            "  39    |   360   |   0.271101   |     -      |     -     |   1.22   \n",
            "  39    |   380   |   0.321832   |     -      |     -     |   1.22   \n",
            "  39    |   400   |   0.331145   |     -      |     -     |   1.22   \n",
            "  39    |   420   |   0.408701   |     -      |     -     |   1.22   \n",
            "  39    |   436   |   0.322393   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  39    |    -    |   0.341173   |  0.494493  |   82.64   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "  40    |   20    |   0.339122   |     -      |     -     |   1.28   \n",
            "  40    |   40    |   0.366151   |     -      |     -     |   1.22   \n",
            "  40    |   60    |   0.397998   |     -      |     -     |   1.22   \n",
            "  40    |   80    |   0.322453   |     -      |     -     |   1.22   \n",
            "  40    |   100   |   0.333121   |     -      |     -     |   1.22   \n",
            "  40    |   120   |   0.287730   |     -      |     -     |   1.22   \n",
            "  40    |   140   |   0.325599   |     -      |     -     |   1.22   \n",
            "  40    |   160   |   0.376096   |     -      |     -     |   1.22   \n",
            "  40    |   180   |   0.363911   |     -      |     -     |   1.22   \n",
            "  40    |   200   |   0.428248   |     -      |     -     |   1.22   \n",
            "  40    |   220   |   0.312311   |     -      |     -     |   1.22   \n",
            "  40    |   240   |   0.304226   |     -      |     -     |   1.22   \n",
            "  40    |   260   |   0.320169   |     -      |     -     |   1.22   \n",
            "  40    |   280   |   0.368196   |     -      |     -     |   1.22   \n",
            "  40    |   300   |   0.376577   |     -      |     -     |   1.22   \n",
            "  40    |   320   |   0.323880   |     -      |     -     |   1.22   \n",
            "  40    |   340   |   0.317629   |     -      |     -     |   1.22   \n",
            "  40    |   360   |   0.250054   |     -      |     -     |   1.22   \n",
            "  40    |   380   |   0.323259   |     -      |     -     |   1.22   \n",
            "  40    |   400   |   0.289786   |     -      |     -     |   1.22   \n",
            "  40    |   420   |   0.411293   |     -      |     -     |   1.22   \n",
            "  40    |   436   |   0.317599   |     -      |     -     |   0.96   \n",
            "----------------------------------------------------------------------\n",
            "  40    |    -    |   0.339077   |  0.496960  |   82.64   |   30.37  \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "bert_classifier, optimizer ,scheduler= initialize_model(epochs=40)\n",
        "train(bert_classifier,optimizer,scheduler, train_dataloader, val_dataloader, epochs=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "0etVinYuwlXO"
      },
      "outputs": [],
      "source": [
        "# store the model in pickle file\n",
        "import pickle\n",
        "filename = 'arabert_model.sav'\n",
        "pickle.dump(bert_classifier, open(filename, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "i6aOUOyjzb1S"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def bert_predict(model, test_dataloader):\n",
        "    all_probabilities = []\n",
        "\n",
        "    # loop on batches of test set...\n",
        "    for batch in test_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "        # Compute probabilities\n",
        "        with torch.no_grad():\n",
        "            probabilities = model(b_input_ids, b_attn_mask)\n",
        "        \n",
        "        all_probabilities.append(probabilities)\n",
        "    # Concatenate logits from each batch\n",
        "    all_probabilities = torch.cat(all_probabilities, dim=0)\n",
        "  \n",
        "    # take the class with highest score  \n",
        "    pred_labels=[]\n",
        "    for log in all_probabilities:\n",
        "      highest_score=torch.argmax(log)\n",
        "       \n",
        "      pred_labels.append(highest_score)\n",
        "\n",
        "    return pred_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owCd6ZlZzsQn",
        "outputId": "ed1f8ea4-41be-42c3-8d05-3879aaf3a7e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000\n",
            "1000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.95      0.90       804\n",
            "           1       0.51      0.32      0.39       126\n",
            "           2       0.61      0.27      0.38        70\n",
            "\n",
            "    accuracy                           0.82      1000\n",
            "   macro avg       0.66      0.51      0.56      1000\n",
            "weighted avg       0.80      0.82      0.80      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Compute predicted probabilities on the validation set\n",
        "y_pred = bert_predict(bert_classifier, val_dataloader)\n",
        "print(classification_report(y_val, torch.tensor(y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIxZPF2mNYa6"
      },
      "source": [
        "# TEST TWEETS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NdkiWLTMNakj"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "M_apsfDgNdFy"
      },
      "outputs": [],
      "source": [
        "#preprocess test data\n",
        "df_test['text']=df_test['text'].apply(arabert_prep.preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TiCtcx-8Nevu"
      },
      "outputs": [],
      "source": [
        "x_test=df_test.text.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "WQ1nhSXJNexw"
      },
      "outputs": [],
      "source": [
        "test_inputs, test_masks = getIDs_attention(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "DH2KJxcKNe1J"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader for our test data\n",
        "test_data = TensorDataset(test_inputs, test_masks)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "SYehwGvpNkg3"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_labels_cat = bert_predict(bert_classifier, test_dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_X1Nb1NBNn7G"
      },
      "outputs": [],
      "source": [
        "test_labels=[]\n",
        "for label in test_labels_cat:\n",
        "  test_labels.append(label.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XhRXl4lEOSnc"
      },
      "outputs": [],
      "source": [
        "#map labels\n",
        "for i in range(0,len(test_labels)):\n",
        "  if test_labels[i] == 0:\n",
        "    test_labels[i]=1\n",
        "  elif test_labels[i] == 1:\n",
        "    test_labels[i]=0\n",
        "  elif test_labels[i] ==2:\n",
        "    test_labels[i]=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "a7uFqwJ8Nn-R"
      },
      "outputs": [],
      "source": [
        "# write the predicted data to a csv file\n",
        "d = {'stance': test_labels}\n",
        "test_csv = pd.DataFrame(data=d, columns=['stance'])\n",
        "test_csv.to_csv('test_result.csv')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "9faa27367d8809f17efa01381c296b23b33e7966403c8c5a88e68f02f779827d"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0560405ca5bb4571a0e7e508ceb60496": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06afe73454a04b87be068657a0067749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62206b68273d4eef95c2774f7bd63fda",
              "IPY_MODEL_bdfbfe35081f41abb5caa2e994b3cce3",
              "IPY_MODEL_234d3ff337454c90bb7e9742b2b72acc"
            ],
            "layout": "IPY_MODEL_632696886b84470385573eb30968fc1d"
          }
        },
        "0de5730fdcb04a2c962abf24e92cb4fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8330857c282e4bbbb6a11b8b1e8590ee",
            "placeholder": "",
            "style": "IPY_MODEL_4c4a64b2784e4423aa995d6a0185d2b9",
            "value": " 751k/751k [00:00&lt;00:00, 641kB/s]"
          }
        },
        "0f2fd11677724521bfae79841b0cd5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ea8f437a554a08b7afd377fb39854e",
            "placeholder": "",
            "style": "IPY_MODEL_59ca243745434cd2a24485e7e18266e3",
            "value": "Downloading: 100%"
          }
        },
        "21646e539e8841deb4b21631b247bbea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "234d3ff337454c90bb7e9742b2b72acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f57d98d6ee840f39c59ba761da241c0",
            "placeholder": "",
            "style": "IPY_MODEL_66d06402a9bd413eac6c8a96e283a273",
            "value": " 1.25M/1.25M [00:00&lt;00:00, 2.11MB/s]"
          }
        },
        "25c50b8223bf4fbe93f453f259f730d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3085d3424f844e3194bc100d81feefc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37a1720c0c32405c9e88ed6c822eeb94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0bd402226b4bc7b6a51324517d33f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed3c0fa17f65471ca182870f710e7811",
              "IPY_MODEL_6ecc434cd0604f7986dae5f43c1da376",
              "IPY_MODEL_0de5730fdcb04a2c962abf24e92cb4fa"
            ],
            "layout": "IPY_MODEL_25c50b8223bf4fbe93f453f259f730d8"
          }
        },
        "4c4a64b2784e4423aa995d6a0185d2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ca243745434cd2a24485e7e18266e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62206b68273d4eef95c2774f7bd63fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78b32fbb52064f18b0bbeaa679db938d",
            "placeholder": "",
            "style": "IPY_MODEL_73ec13590f074ae195f0b07a731599c4",
            "value": "Downloading: 100%"
          }
        },
        "632696886b84470385573eb30968fc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66d06402a9bd413eac6c8a96e283a273": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ecc434cd0604f7986dae5f43c1da376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ecbd51eb8304976af184e8ac8ef3697",
            "max": 750551,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a85fcbbe287440919b8834f9c77a732b",
            "value": 750551
          }
        },
        "72ac41a26c4b4610b59a5249c58d4acd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73ec13590f074ae195f0b07a731599c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b32fbb52064f18b0bbeaa679db938d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f57d98d6ee840f39c59ba761da241c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803e0980e3cf48019a33524ab04ce72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f2fd11677724521bfae79841b0cd5a8",
              "IPY_MODEL_ad5d5a05d25748858ff82c095e57a366",
              "IPY_MODEL_d9b8a1b95e0b4c548c66aa75a7a58e57"
            ],
            "layout": "IPY_MODEL_0560405ca5bb4571a0e7e508ceb60496"
          }
        },
        "8330857c282e4bbbb6a11b8b1e8590ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83f3aa85266447ea913e5fa96841e41c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89257b2f51f4422e857c830d99c02c89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a1f37347f0c47dd922f551b7d788023": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e03ba9dfb0534c379b1088a4c6a8090b",
            "placeholder": "",
            "style": "IPY_MODEL_c5eda33b3fed46d394871d5942eb1c43",
            "value": " 112/112 [00:00&lt;00:00, 2.06kB/s]"
          }
        },
        "8ecbd51eb8304976af184e8ac8ef3697": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90edcd2e5e04455ba222bb8b77846349": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "930492ac97c34d05b69fe2800dc147c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982480b2b99245a5a15f2c26a7455fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9900668ed88447f083b9a1ccb933e66c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bb3dacbff7349ec922bdcac165461e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a26dc14bebc54314b8933ea711912e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c94555a6ffa64c438d7f3d4a4344800e",
              "IPY_MODEL_ef105f1a3fb7470ea12919354069187d",
              "IPY_MODEL_8a1f37347f0c47dd922f551b7d788023"
            ],
            "layout": "IPY_MODEL_fe4be541ae1a49d1bd32fbe5a7861008"
          }
        },
        "a85fcbbe287440919b8834f9c77a732b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ad5d5a05d25748858ff82c095e57a366": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982480b2b99245a5a15f2c26a7455fc7",
            "max": 476,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90edcd2e5e04455ba222bb8b77846349",
            "value": 476
          }
        },
        "bdfbfe35081f41abb5caa2e994b3cce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ac41a26c4b4610b59a5249c58d4acd",
            "max": 1252935,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83f3aa85266447ea913e5fa96841e41c",
            "value": 1252935
          }
        },
        "c5eda33b3fed46d394871d5942eb1c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c94555a6ffa64c438d7f3d4a4344800e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_930492ac97c34d05b69fe2800dc147c6",
            "placeholder": "",
            "style": "IPY_MODEL_9bb3dacbff7349ec922bdcac165461e1",
            "value": "Downloading: 100%"
          }
        },
        "d9b8a1b95e0b4c548c66aa75a7a58e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21646e539e8841deb4b21631b247bbea",
            "placeholder": "",
            "style": "IPY_MODEL_9900668ed88447f083b9a1ccb933e66c",
            "value": " 476/476 [00:00&lt;00:00, 23.4kB/s]"
          }
        },
        "e03ba9dfb0534c379b1088a4c6a8090b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89c49aec343420aa1bdff1b7065a1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed3c0fa17f65471ca182870f710e7811": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3085d3424f844e3194bc100d81feefc7",
            "placeholder": "",
            "style": "IPY_MODEL_e89c49aec343420aa1bdff1b7065a1fb",
            "value": "Downloading: 100%"
          }
        },
        "ef105f1a3fb7470ea12919354069187d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a1720c0c32405c9e88ed6c822eeb94",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_89257b2f51f4422e857c830d99c02c89",
            "value": 112
          }
        },
        "f4ea8f437a554a08b7afd377fb39854e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4be541ae1a49d1bd32fbe5a7861008": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
