{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from preprocssing import preprocessDF , get_vocab\n",
    "from TD_IDF import tfidf_transformation\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing on training data set\n",
    "train_tokens = []\n",
    "train_labels = []\n",
    "train_tokens, train_labels =preprocessDF('./dataset/train.csv', 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store tweets after preprocessing in data frame to extract tweets and labels\n",
    "df_train_processed= pd.read_csv(\"train_processed.csv\")\n",
    "train_tweets = df_train_processed['text'].values\n",
    "train_labels= df_train_processed['stance'].values\n",
    "#extract vocabulary from training set\n",
    "vocab =set()\n",
    "vocab=list(get_vocab(train_tokens))\n",
    "N = len(train_tweets)# no of tweets= 6988\n",
    "V = len(vocab) # no of unique words= 26843\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION DATA PREPROCESSING\n",
    "val_tokens = []\n",
    "val_labels = []\n",
    "val_tokens, val_labels =preprocessDF('./dataset/dev.csv','val')\n",
    "df_val_processed= pd.read_csv(\"val_processed.csv\")\n",
    "val_tweets = df_val_processed['text'].values\n",
    "val_labels= df_val_processed['stance'].values\n",
    "print(len(val_tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6988, 27078)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cv=CountVectorizer() \n",
    "# this steps generates word counts for the words in your docs \n",
    "\n",
    "''' \n",
    "The fit method is calculating the mean and variance of each of the features present in our data. \n",
    "The transform method is transforming all the features using the respective mean and variance.\n",
    "\n",
    "Now, we want scaling to be applied to our test data too and at the same time do not want to be \n",
    "biased with our model. We want our test data to be a completely new and a surprise set for our\n",
    " model. The transform method helps us in this case.\n",
    "'''\n",
    "#create tf matrix of size (N*V) \n",
    "word_count_vector=cv.fit_transform(train_tweets)\n",
    "print(word_count_vector.shape)\n",
    "#idf(t) = log [ n / df(t) ] + 1  \n",
    "# smoothed ->, terms that occur in all documents in a training set, will not be entirely ignored.\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "#use count vector to compute IDf\n",
    "tfidf_transformer.fit(word_count_vector) # TODO Fit wla fit transform\n",
    "tfidf_transformer.transform(val_tweets)\n",
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])\n",
    "# compute TF for each tweet that generate Matrix of size (N*V) \n",
    "# each row represent a tweet, each col a word the cell has count of this word in that tweet\n",
    "count_vector=cv.transform(train_tweets) \n",
    "#print(count_vector.shape)\n",
    "# tf-idf scores using TF matrix and IDFs valued that we fit the tfidf_transformer object using it\n",
    "\n",
    "X = cv.transform(val_tweets)\n",
    "tf_idf_val =tfidf_transformer.transform(X, copy=False)\n",
    "tf_idf=tfidf_transformer.transform(count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>انوا</th>\n",
       "      <td>0.344647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>نفاق</th>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>معوا</th>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بمؤتمروا</th>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>عفوا</th>\n",
       "      <td>0.186433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بلغثيان</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بلغت</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بلغ</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>بلعيبه</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ﻹيصال</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27078 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tfidf\n",
       "انوا      0.344647\n",
       "نفاق      0.186433\n",
       "معوا      0.186433\n",
       "بمؤتمروا  0.186433\n",
       "عفوا      0.186433\n",
       "...            ...\n",
       "بلغثيان   0.000000\n",
       "بلغت      0.000000\n",
       "بلغ       0.000000\n",
       "بلعيبه    0.000000\n",
       "ﻹيصال     0.000000\n",
       "\n",
       "[27078 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = cv.get_feature_names() \n",
    "# print(feature_names)\n",
    "#get tfidf vector for first document \n",
    "first_document_vector=tf_idf_train[1] \n",
    "#print the scores \n",
    "df = pd.DataFrame(first_document_vector.T.todense(), index=feature_names, columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "idf vector is not fitted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 19\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# word_count_vector=cv.transform(val_tweets)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# print(word_count_vector.shape)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# #idf(t) = log [ n / df(t) ] + 1  \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m# tf-idf scores using TF matrix and IDFs valued that we fit the tfidf_transformer object using it\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#tf_idf_val=tfidf_transformer.transform(count_vector)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m X \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mtransform(val_tweets)\n\u001b[1;32m---> 19\u001b[0m tf_idf_val \u001b[39m=\u001b[39mtfidf_transformer\u001b[39m.\u001b[39;49mtransform(X, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1674\u001b[0m, in \u001b[0;36mTfidfTransformer.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1668\u001b[0m     X\u001b[39m.\u001b[39mdata \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf:\n\u001b[0;32m   1671\u001b[0m     \u001b[39m# idf_ being a property, the automatic attributes detection\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m     \u001b[39m# does not work as usual and we need to specify the attribute\u001b[39;00m\n\u001b[0;32m   1673\u001b[0m     \u001b[39m# name:\u001b[39;00m\n\u001b[1;32m-> 1674\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m, attributes\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39midf_\u001b[39;49m\u001b[39m\"\u001b[39;49m], msg\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39midf vector is not fitted\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   1676\u001b[0m     \u001b[39m# *= doesn't work\u001b[39;00m\n\u001b[0;32m   1677\u001b[0m     X \u001b[39m=\u001b[39m X \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_idf_diag\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1217\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   1218\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1219\u001b[0m     ]\n\u001b[0;32m   1221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> 1222\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: idf vector is not fitted"
     ]
    }
   ],
   "source": [
    "# word_count_vector=cv.transform(val_tweets)\n",
    "# print(word_count_vector.shape)\n",
    "# #idf(t) = log [ n / df(t) ] + 1  \n",
    "# smoothed ->, terms that occur in all documents in a training set, will not be entirely ignored.\n",
    "# tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "# tfidf_transformer.transform(word_count_vector) # TODO Fit wla fit transform\n",
    "# print idf values \n",
    "# df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    "# sort ascending \n",
    "# df_idf.sort_values(by=['idf_weights'])\n",
    "# compute TF for each tweet that generate Matrix of size (N*V) \n",
    "# each row represent a tweet, each col a word the cell has count of this word in that tweet\n",
    "#count_vector=cv.transform(val_tweets) \n",
    "#print(count_vector.shape)\n",
    "# tf-idf scores using TF matrix and IDFs valued that we fit the tfidf_transformer object using it\n",
    "#tf_idf_val=tfidf_transformer.transform(count_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit(train_tweets)#mode\n",
    "X.transform(train_tweets)\n",
    "X.transform(val_tweets)\n",
    "#-----------------------------------\n",
    "word_count_vector=cv.fit_transform()\n",
    "tfidf_transformer_model=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "#use count vector to compute IDf\n",
    "tfidf_transformer_model.fit(tweets) # TODO Fit wla fit transform\n",
    "tfidf_transformer_model.transform(val_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 7273 features, but LinearSVC is expecting 27078 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m clf\u001b[39m=\u001b[39mLinearSVC(C\u001b[39m=\u001b[39m\u001b[39m50.0\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      2\u001b[0m clf\u001b[39m.\u001b[39mfit(tf_idf_train,train_labels )\n\u001b[1;32m----> 3\u001b[0m Y_Predicted\u001b[39m=\u001b[39mclf\u001b[39m.\u001b[39;49mpredict(tf_idf_val)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m,metrics\u001b[39m.\u001b[39maccuracy_score(val_labels, Y_Predicted)\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\linear_model\\_base.py:425\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    412\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39m    Predict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    414\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39m        Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    426\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    427\u001b[0m         indices \u001b[39m=\u001b[39m (scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\linear_model\\_base.py:407\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mPredict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[39m    this class would be predicted.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    405\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    408\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[0;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m scores\u001b[39m.\u001b[39mravel() \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\base.py:585\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 585\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    587\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\dell\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 7273 features, but LinearSVC is expecting 27078 features as input."
     ]
    }
   ],
   "source": [
    "clf=LinearSVC(C=50.0, random_state=42)\n",
    "clf.fit(tf_idf_train,train_labels )\n",
    "Y_Predicted=clf.predict(tf_idf_val)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(val_labels, Y_Predicted)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 22:45:29) [MSC v.1916 32 bit (Intel)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cad911e89c9cd81e6830ed7e3dceb0d7faa858acac22c42d691ca01e2d61a3cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
